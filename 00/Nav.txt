







Lcc-Win32

A compiler system for windows

Technical Reference



Jacob Navia

based upon

the lcc compiler written by
C.W. Fraser
and
Dave Hanson

Prologue	7
Software	8
Writing software	9
Compiling software.	16
The compilation process	18
A closer look at the compilation process.	19
Overview	19
The pre processor.	22
The compiler	22
Lcc’s intermediate language	23
Following an expression:	25
A bug	26
An overview of the abstract instructions of the virtual machine	28
Allocating register variables	29
Allocating registers for expressions	30
The code generator	33
The assembler.	34
Modifications done to lcc	36
Porting the code	36
Integrating the preprocessor into lcc	36
Supporting Microsoft’s extensions	37
The _stdcall calling convention	37
Problems encountered when implementing _stdcall	38
The “declspec” construct.	39
The different #pragmas	40
Structured exception handling	41
Writing the startup code	41
Writing the stackprobe code	42
The windows.h and the other header files	43
The #ident discussion	47
Other fine points in the preprocessor	50
Generating the debugging information	51
Generating the browsing information	51
Design considerations	52
Browse file format	53
Linking the browsing information.	54
Browsegen and the preprocessor	55
The long long extension	55
Implementing run time debugging support: the shadow stack.	57
Error handling within lcc-win32	59
The information flow in lcc-win32	59
The source files of the compiler proper	60
Building the compiler	62
Lcc’s assembler	62
Overview	62
The format of the x86 instructions	63
Fragments	66
The format of object files	66
Relocations	67
The symbol table	68
Pseudo instructions	69
Further work	69
The debug section	70
The format of the debug information	70
Examples	73
Implementing the “inline” operator (C99)	74
The peephole optimizer	76
1. Motivation	76
2. Implementation	76
3. Patterns	77
4 Eliminate constants if possible.	78
3.5. Use the ‘new’ 486 instructions.	79
3.6. Optimize sequences.	79
3.7. Improving the block move instructions.	80
3.8. Inlining library functions.	80
3.9 Avoiding clobbering when possible.	81
3.10 Avoid unnecessary moves	81
4. Construction of the optimizer.	81
5 Speed considerations	82
6. Results:	82
7. Description of the code	82
8 Further work	83
The high level optimizer	84
Improving the machine description	84
Improving register usage	86
Improving floating point performance	88
Front end modifications	88
Finding variables with disjoint domains	88
Modifications to lburg	89
Constant folding	89
Dividing by a constant.	90
Optimizing ‘const’ variables	91
Optimizing structure arguments	92
Other changes to the front end.	93
Quality control	94
Further work	94
Compiler optimizations. A case study with gcc-2.95.2	95
The intrinsics interface	97
Implementing the operators redefinition in lcc	99
C and C++	100
Function overloading.	100
Default function arguments	103
Namespaces	103
Avoiding complexity	105
The ‘pedump’ utility	107
The linker	108
Motivation	108
The format of the PE Executable.	109
The linking process (overview)	113
The linking process: detail	114
Parsing and processing the .def files	114
Open all files given in the command line	115
Symbols	116
The discussion about the common storage model	117
Relocate all symbols	119
Build the symbol table	119
Performing the relocations	121
Linking the debug information	124
Mapping source files to addresses	125
Building the executable headers	127
The source distribution of lcclnk.	128
Dynamic linking	129
Motivation	129
Implementation	129
Binding the object file	129
The import librarian	131
Import libraries	131
Summary: Building an import library from a dll.	132
The resource compiler	133
The .rc language specifications.	133
Parsing	133
The parser	134
Limitations of the resource compiler	141
The source distribution of the resource compiler	142
The librarian	143
The signature	143
The « first linker member »	143
The second linker member	143
Usage of lcclib	144
Lcclib source files	145
The resource editor	146
The format of the .RES files	146
Building a dialog box dynamically	147
Testing a dialog box interactively	149
Writing the .dlg file	150
Writing the .res file	150
Writing the .rc file.	150
Wedit: the Integrated development environment	152
History	152
How to start an editor.	153
Coping with legacy code	153
Why global variables?	154
How does Wedit work	155
Editor	155
The ‘Autosave’ feature	156
Real time coloring of text	156
Representing text	158
Handling the keyboard	162
Redrawing the screen.	164
Handling the selection and the clipboard	165
Maintaining the status display	166
Handling dialogs	166
Handling the bookmarks: what is important in a user interface?	168
The output window	169
Handling the menu	171
The right button menu	171
Special purpose parsers	172
The software metrics module.	173
The 'TREE' utility	175
Identify an executable or an object file	175
Building the history list	176
The object file cross-referencing utility	177
User interface considerations: an example.	177
The built-in utilities	179
Showing the #ifdefs	181
Showing executable statistics	181
Extracting the character strings from a source file.	181
Searching for a function	182
The project maintenance	183
The “workspace” display	185
The configuration wizard of Wedit.	186
Adding files to the project	187
Building the executable	187
Generating a Makefile	187
Speeding up makefile generation	188
Starting a build and displaying the results	189
Finding out the missing libraries	190
The application wizard	190
Wizard mechanics:	192
The source distribution for the wizard	192
The debugger	193
Starting a program under debugger control.	194
Preparing for debugging	195
Debugger mechanics	197
Finding out where a call is going to go.	198
To trace or not to trace	199
The different debugger displays	200
The different kinds of breakpoints	202
The operation in ‘Trace’ or ‘Step’ mode	202
Implementing the ‘step out’ feature	204
Implementing a fast « breakpoint » in all lines	204
Implementing the error window	205
Implementing the data breakpoints.	206
What to do when a data breakpoint fires.	207
Implementing the ‘ToolTips’ window	208
Recovering after a program crash	208
Debugging a program that just crashed.	209
Evaluating expressions under the debugger	210
An example	211
Implementing conditional breakpoints	212
Getting to the Thread Information Block	213
Stopping a program and cleaning up	214
Starting a debugging session with a given executable	214
Other debug information formats : the ‘stabs ‘ format. (gcc)	215
Organization of the stabs information.	218
Accessing the data base	220
Bibliography about debugging	220
Customizing the editor	220
Adding a new menu item	220
Adding a new key handler	221
The source distribution of Wedit.	222
Bugs	225
Analyzing bugs	228
Correcting bugs	232
How I introduced the bug	232
Correcting the bug	234
Classifying bugs	234
Reporting bugs in lcc-win32	236
Memory management	237
Practical applications of lcc-win32: C as an universal assembler	240
Appendix 1: Summary of the assembler syntax.	241
Pseudo-instructions	241
Syntax	241
Opcode naming	242
Memory references	242
Appendix 2 : The mmx intrinsics	244
Introduction	244
Instruction Syntax	244
Description of the interface	245
The problem with the mmx instructions	255
Appendix 3: Overview of the machine description and the rules	256
Epilogue	262
INDEX	264

Prologue

1

This adventure started in an anodyne way: I went to ‘Le monde en tique’, the data-processing library of Paris. Wandering around, a book caught my attention: ‘A retargetable C compiler: design and implementation by Christopher Fraser and David Hanson’. Mmm interesting.

I took the book, started reading. A whole C compiler neatly explained. There was even a DOS implementation. This is interesting I told myself. I bought the book, went home, read some chapters.

I was working since several years in a compiler environment project. I had written an editor ‘Wedit’ and sold some copies of it to fellow programmers in Paris. But my editor project was stuck: it missed the compiler. Once people bought the compiler with its integrated editor, they wouldn’t think about using any other one. The editor was actually considered as an afterthought. The effort of learning a new editor was considered too big. Besides, the new programming environments were more and more closed. They were more tightly integrated, so Wedit couldn’t easily start a compilation, or call the debugger.

Well, it would be nice to build a whole environment...

But it was a monstrous amount of work! Lcc came with a compiler generating just assembler mnemonics: there was no assembler, no linker, no library, no resource compiler, no resource editor, no debugger, no header files.

But then... this would be an opportunity to write an assembler, a linker and a debugger!

I talked to some friends. Everyone told me I was completely crazy. But this, I knew already. So I started doing it.

This was like beginning 1995 or so. It is 2001 now. The assembler is written, together with the linker, and the import librarian, the resource compiler, the resource editor, and a first version of the debugger is out.

This document, as you can see in the ‘stubs’ (sections containing just a title) is not finished, as this project is not finished. I thought it could be useful to understand what is happening, so I include it in the project documentation.

Books are dangerous. They can change people’s lives. The book of Mr. Fraser and Mr. Hanson changed mine, and I am grateful to them for having published their work. In the process of developing the optimizer, or adjusting it to the windows environment, I have several times destroyed essential data structures of the compiler. But it has never crashed.

Never.

It is a solidly built piece of software, full of useful assertions that will pinpoint exactly where you went wrong. It has a clean design, with a good separation of the front end/back end, and several functions that are really beautiful to read: take a look at ‘listnodes’ in dag.c for instance.

Software
2
Software is the art of illusion. You ‘push’ a button, and you see the button changes its form, as it existed. What really happens, is only that a click in the mouse button (THAT button exists of course), will select a different bitmap for the screen area where the button is drawn. Nothing has moved, there is no button anywhere in the screen, but it looks like.

The whole windows system is based upon illusions about the existence of ‘windows’, and about a ‘desktop’. Graphics are used extensively to reinforce this paradigm, and to present to the user a number of objects (called ‘controls’ in techspeak) like buttons, trees, list boxes etc that exhibit a standard behavior.

A compiler gives you the impression that the machine speaks a high level language. Those languages allow you to give to the machine a more abstract kind of commands, that the commands the machine really understands. This process of translating a standardized language into machine instructions is called compiling.

We have to be aware that all ‘high-level’ languages are just machine ‘languages’. They look similar somewhat to the written languages we use; especially English, but they are in fact completely different.

The input language of lcc-win32 is the C language, as defined by the ANSI committee for standards. This language is fairly close to the machine, and doesn’t have the expressive power of more evolved languages like lisp or smalltalk, for instance. This can be seen as a weakness, or as strength, depending on your point of view, and the application you are writing. 

If you are interested in ignoring most software abstractions and writing programs that are close to the native windows API; C will do this very well. On the other side, if you do not want to be bothered with memory management, obscure machine details, and you would like to use the ‘object oriented programming’ paradigm, C will fail short of your expectations and become an obstacle to expressing your ideas into programs. Java or Eiffel would be better choices.

C is a fairly old programming language, and very stable. The code of wedit, the IDE of lcc-win32 contains code that was taken from the microEmacs editor, a software package written around the beginning of the eighties. That code still works without any problems, in 2001, under Windows 2000. If you write your code in C your code can last for years and years and it will still work, in the unknown environments of the future.

The illusions created by software break down sometimes. These events are called ‘bugs’, in techspeak, and show us suddenly what is really behind all software. We have all seen this, but tend to forget them as soon as possible, becoming again absorbed by the program’s display. For instance, bugs in the Windows operating system destroy the desktop and show us a blue screen full of awe inspiring numbers, that give the user a glimpse into the innards of the machine we are working with. 

Yes, numbers. The only thing the circuit “understands”.

Writing software
3
Humans can design software, you too. There is nothing special about it: just putting one instruction after the other, to make the computer do what you want it to do. Suppose you want to tell your user some information about the data he/she is viewing. Like walking, nothing special, just one step after the other. Yes, I know, learning to walk wasn’t easy, but was doable. So you calculate the information the user needs, or you yourself want to see. You put it in a file, i.e. a certain amount of space in the magnetic surface of a fast spinning hard disk. Then you display it. 

Here is one piece of software, to give you a feeling about it. It opens a data set, does some string processing in it, and puts the result of another part of the system in the screen. The input data is assumed to have a special format. This routine is not especially important, neither it is very well written. It is not an example of ‘the way’ you have to program; it just shows how I did it. It is here to give you a feeling what is behind each symbol in a program, and how it happens in detail. This is a very small routine, but does represent the bulk of software: reading, processing and handling that data. You know all this if you program in C already, but even then, it is instructive to see how much effort and words need to be written to explain a small routine to a certain amount of detail. The purpose here is to show this detail, and some of the things you should have in mind when programming.

static void HandleShowIncludesCommand(void)
This means that here starts a subroutine that will be called ‘HandleShowIncludesCommand’, that doesn’t return a result (void), and is local to the current compilation module (static), i.e. that the significance of this new name will be limited in scope.
{
The brace means that this is the start of a new scope block. I declare here always the most of data the subroutine will use. These variables are called ‘local’ variables, i.e. the iummediate context of this routine’s execution. Normally this data resides in the main processor’s primary cache, running at full speed.
	FILE *f;
One of them will be the symbol that holds the connection to the data spinning in the disk. I do not like much typing so I called it ‘f’, just so.
	HWND hwnd;
This is the symbol that holds the id of the the screen window context that will display the data. Those rectangles are the display area of the application.
	char *p,*tmpfile = tmpnam(NULL),*prjOptions = NULL,*q;
And it goes on, all must be taken care of: The filename symbol, holds the name of a temporary file that will hold the output of the calculation, that is actually the name of the data the user is editing, the main application being a program editor that you may use. Another symbol is prjOptions, that will hold the state of the current project the user is working on, if any, maybe there is no project defined and the editor is just displaying some random file.
	char *filename = CurTxtBuf->BufferName, 
*includePath, 
*sourcesPath,
*pStart;
The includePath symbol is a data list that contains alternative places, where the system looks for information, besides the current directory. Note the quantity of detail that you have to keep track of. This is what makes the complexity of walking. One step after the other yes, but… where are we going?

Ah we do not know. That’s no easy file handling operation.
	int tablevel = 0,i;
I decided to indent the information according to the tabulations the user defines, to make it more readable. The output has a tree-like structure, easily made evident by just indentation. The ‘i’ variable is a counter, I will use later on. I name them always i (or j less often) maybe because a Fortran tradition. 
	PROJECTINFO *prj = GetCurrentProject();
This is a user-defined type (as were actually HWND and FILE, but those are system wide). This one is defined in the include header of the application, and contains a project description. Note that I use a pointer to it, i.e. the number of the RAM location where the project description block starts. RAM locations are numbered consecutively, and those sequential numbers are pointers, i.e. they tell us where in RAM is located the information they represent.

Then I leave always a blank line. These declarations prepare the context for the body of this subroutine: the actual instructions to process the data.
The total size of the above context is small, 13 words of 32 bits each, what fits perfectly in today’s caches.
	if ((CurTxtBuf->BufferFlags & BFIS_C_FILE)==0) {
		sprintf(buf,"%s: not a C file",filename);
		strlwr(buf);
		ShowDbgMsg(buf);
		return;
	}

Is the input data correct? Any subroutine does some error checking, to see if there isn’t incoherence somehow. For instance if this is not data of the kind this subroutine expects, an error message is shown in the screen, and the routine exists. This is clearer to the user (input data incorrect) than silently trying to go on with at best absurde consequences or nonsense results. I test for this condition using a C technique of writing flags (i.e. bits, that are tested with an AND operation if they are on or off).  One of this flags tells if the current active data set is the kind this routine expects, and if this is not the case, the predicate triggers the execution of the sequence.
First, this sequence builds the error message in the buf variable, by using a special notation. We call the formatting routine with a format spec, and the name of the wrong dataset. Then, we put everything in lower case (strlwr call), because I think looks better. I do not support error messages in YOU DID SOMETHING WRONG style…
Then, I show it in the screen, and return from this. Not very complicated isn’t it? Just common sense.
	if (prj) {
		prjOptions = IncludesAndDefines(prj);
	}
We test the global context where this subroutine is working on. If any, we store it in prjOptions. From now on, we shouldn’t forget that prjOptions can contain two values: either void (with Null in it), or pointing to the current global context options. Both values must produce correct results.
	wsprintf(buf,"%s\\bin\\browsegen.exe %s -M1 -Fo%s %s",
		ProgramParams->LccRoot,
prjOptions ? prjOptions : "" ,
tmpfile,filename);
To process the data, we have to call the calculator part, that will figure out from the current data set, a whole set of relationships. We prepare a string with the command that we are going to pass to the OS for starting the calculator. I specified a path, and then an executable name, that is called in a certain configuration (-M1 –Fo) to perform a certain task. There could be user-configured options to pass to the calculator, so we use them, if present. Note that we test for this condition, with the C idiom:
	condition  ?  TRUE part : FALSE part
This returns a result that is passed to the formatting routine. Note that we keep both paths open: NULL and something.
The name of the output file, (the temprary file name stored in tmpfile), is passed to the calculator so that it writes in there.

	ExecuteCommand(buf,SW_HIDE);
OK, we pass the data to the OS. We tell the system not to show any window for the calculator, since anyway, we are going to display the data later. The ExecuteCommand routine makes a small set of system calls, to start a new process, and wait till it finishes.

	SendMessage(ProgramParams->hwndOutput,WM_SHOWLISTBOX,0,0);
The program has a rectangle for displaying messages at the bottom of its display area. If it was closed, we open it, since we are going to display the data. This could be done later actually. This comes about because this part of the subroutine is more ancient, and I haven’t inserted the statements in the most perfect logical order. But anyway, this is going to happen so quickly anyway (the calculations are done in less than a second now) that this instruction can be left here without any big problems.

	hwnd = (HWND)SendMessage( ProgramParams->hwndOutput,
WM_GETWINDOW, 
0, 0);
This is the ID of the display manager at the display rectangle, hwnd. It will be used to send the data there.We ask for this ID to the window procedure of that area, with the usual object oriented idiom of sending a message to the procedure, invoking a method..
	hwnd = GetDlgItem(hwnd,IDLIST);
We use a variable, giving it a new meaning. This is not something that is always bad. Many identifiers confuse the reader, and actually this is an hwnd, whatever the system understands by that. That symbol contains now the list box window’s id. We need it to clean it. We do this by sending to the system a message in the form of eventually a system call to get the ID of the list box window nin the display area’s window list. I assign the result to the same identifier that was stored in the window manager’s, since anyway its no longuer needed.
	SendMessage(hwnd,LB_RESETCONTENT,0,0);
We tell that list box to empty, because we are going to write into a new sheet.
	f = fopen(tmpfile,"r");
We establish a connection between the fast spinning hard disk surface and the subroutine in RAM. How to do that, is something the OS knows about, if not, we wouldn’t be running there!
	includePath = allocatePath();
The alternative searching path is allocated and initialized to zero.
	if (prj)
		sourcesPath = DuplicateString(prj->SourcesDir);
	else
		sourcesPath = DuplicateString(CurrentWorkingDir);
The data location path is either the one in the global context, or just the current directory. We save this information to avoid unnecessary clutter, when the computer displays a lot of redundant information, that doesn’t interest anybody. This path information is redundant, and can be eliminated.
	strlwr(sourcesPath);
Keep lowercase.
	wsprintf(includePath,"%s\\include",
ProgramParams->LccRoot);
The application runs in a established source directory structure. The alternative datapaths are all after the default one.
	while (fgets(buf+tablevel*tabsize,256,f)) {
We read a line of data from disk into RAM. The system routine fgets will fill the RAM space called buf, starting at location (tablevel*tabsize). Normally tabsize is four, so each tree level will be indented by 4 spaces. Note that the characters 0 to tabsize*tablevel do not contain initialized data. 
		strlwr(buf);
Keep lowercase
		p = strchr(buf,'\n');
Search the new line character
		if (p)
If there was a new line character
			*p = 0;
Put a zero in it, terminating the chain. We do not need that character.
		for (i=0; i<tablevel*tabsize;i++)
			buf[i] = ' ';
As I told you above, the first positions of the buffer aren’t initialized. I put spaces in them. I tell the circuit to count the characters in the RAM location called ‘i’,  testing at each character if it is below the integer indicated by the result of the multiplication of tablevel with tabsize.
		if ((p=strstr(buf,"#include")) != NULL) {
The data set contains a structure delimited by special markers we find in the data. The calculator puts that synchronization signals in the data for us, how nice.
			pStart = buf+tabsize*tablevel;
The start of useful data is after the tabulations, of course.
		/* ignore directory information if the file is in the sources directory */
A commentary. Rare, rare. Imagine how long it would take me to write software if I would explain it to the reader as I am doing with you here. I would never had the time to explain everything.
			if (!strncmp(pStart, 
sourcesPath, 
strlen( sourcesPath )) ||

	    !strncmp( pStart,
includePath,
strlen(includePath))) {
We see if any of the initial part of the data is redundant. We compare a certain amount of characters with each other, and deduce from that, if equal, that they can be erased. If that predicate triggers, the following sequence starts, that will erase those characters from the output:
				q = strchr(pStart,' ');
I search the first blank in the input data.
				if (q) {
if there was any
					*q = 0;
we break the character chain there.
				}
Close scope. I tend to use scopes even if this is not always necessary.
				p = strrchr(buf,'\\');
The last backslash represents the last path component in the data.
				if (p && q) {                                         
If there was a backslash and a space in the data
					p++;                                  
skip it,
					*q = ' ';                            
we put a space in there
					memmove(pStart,p,strlen(p)+1);
and we copy that part of the buffer to the start of it. To make this more easy to follow imagine you have the input data:
d:\lcc\wedit\edit5.c: line 14 --> d:\lcc\wedit\edit.h
We copy all characters from ‘edit5.c’ to the start of the path information, (the characters d:\… etc) overwriting what it was in there.
				}
				else if (q) *q = ' ';
If any backlsash wasn’t present… we restore what it was in there. Data from the calculator will not change its output format so easily, but better not to rely on that, and cope with the situation the data isn’t as we expected.
Exercise:
What would happen if the ‘else’ instruction wouldn’t be there?
Answer:
In the case that the predicate of the if was true, the positions of the characters would have moved, and q would overwrite useful data.
Exercise:
How do I know?
Answer
Guess… 
Exercise:
What would happen if the if (q) were left out of the last line?
Answer:
In the case that no space would be present, the program would access a void location. This means that the system would put an unpleasant dialog box in the screen saying that ‘This program has performed an illegal operation and will be terminated’. What a shame to finish like that. All data the user had in RAM would be lost.
How did I find out? I corrected this possible bug when I correected the problem with the space above, and started checking the logic a bit.
			}
We close the scope of the if above that established the predicate about the redundant info. Now we start processing the second part of data.
			q = strchr(p,'<');
We search a marker, stopping at the first occurrence.
			if (q == NULL)
If it wasn’t found
				q = strchr(p,'"');
search an alternative marker.
			if (q) {
If any marker at all was found
				q++;
Skip it
				/* ignore the include path info if it is a global include */
We do the same thing as above
				if (!strncmp(
q,
includePath, strlen(includePath)) || 
This predicate uses two conditions, joined by an OR symbol. This means the first condition OR the next will trigger the predicate. We compare first with includePath, and then with sourcesPath.
		
					!strncmp(
q,
sourcesPath,
strlen(sourcesPath))) {
This sequence will be triggered by that predicate.
					*q++ = 0;
We break the character chain there.
					p = strrchr(q,'\\');
Search the backslash… I confess I just copied this from the first condition with the text editor. I should have done a routine that encapsulates this and takes just two arguments, doing what it takes to do. Cut and paste, however, was much more convenient, and I am sure you will understand this later on. Programming means working with the current time budget, managing your resources, knowing what you can do and you can’t do, as walking. Walk to the Everest mountaintop? Possible but its really necessary?
					q--;
This was pointing to the marker, whatever it was (either ‘<’ or ‘”’). We want to output the marker to the user, so we backup one position.
					if (p) {
If there was a backslash
						p++;
we skip it
						strcat(q,p);
add the data set name info
					}
If there wasn’t a backslash we do nothing.
				}
If there wasn’t any redundat info we do nothing
			}
If there wasn’t a marker, we do nothing.
			AddStringToListBox(hwnd,buf);
We send the output to the list box window, that will take care of displaying it in the screen with the current font, drawing each character line, etc. We just output it. The routine that we call, does just a small set of system calls to put that data in the screen.
			tablevel++;
Increase the level variable using the post increment construct. This adds one to the variable in question.
		}
If this input line didn’t contain the marker, we check any command to decrease the level from the calculator
	else if (!strncmp(buf+tablevel*tabsize,"closing",7)) 
{
If there is one of this commands, decrease that variable by one.
				tablevel--;
			}
Finished processing the input line. If it was a marker we did something, else we did something different only if it was a decrease level command, otherwise we did nothing with the input.
}
We finish the processing of each line. At this point, execution returns to the beginning of the while instruction above, to read more input.
	fclose(f);
We break the binding to the disk. This routine has finished its work, and now it cleans up before returning.
	unlink(tmpfile);
The temporary data file is no longuer needed. Erase it.
	release(prjOptions);
Release the temporary context we allocated.
	release(includePath);
	release(sourcesPath);
}
Finished. No result is necessary, since menu commands are just action the user tells ut to perform. It isn’t necessary to say to the user: COMMAND DID NOT WORK. If there was an error, he will see that it didn’t anyway.

Compiling software.
The instructions above are all high-level instructions. The integrated circuit that executes them, knows nothing about such high level concepts like FILE or HWND. It only knows how to do a much smaller and lower level kind of instructions called ‘instruction set’. These are instructions like add, substract, compare, branch, etc.

To program at that lower level is possible of course, but very tedious. The higher level instructions allow us to write a short hand for those instructions, that are translated into real machine instructions by a piece of software called a compiler, that, hence its name, compiles a set of machine instructions for each high level one. For isntance when we call a procedure, we write in C:
	fclose(f);
it will emit:
	push	f
	call	_fclose
	add	$4, esp
These lower level instructions mean something to the circuit. They tell it to write the value in that pointer into the top of the stack, after decreasing the stack pointer. Then, it tells it to set the program counter at the location where the fclose routine is, and start executing instructions there until it finds a return instruction, that will send it back to where it was. The compiler readjusts the stack to compensate for the push and the call is done.

The high level instructions are part of a standardized input format for a specific computer language. Other languages differ in many ways, in concepts, in ways of doing, etc. But all of them sooner or later, must be translated into a set of those basic instructions anyway. The machine doesn’t understand anything else.

Software development in a compiled environment means then, writing code, compiling it, and then executing the instructions compiled, maybe with the aid of a debugger.
Now, let’s see what the compiler will generate for some of the statements in the function above. The assembler representation used is the one used by lcc-win32, i.e. the source of the operation is written first, the destination second. This is the contrary of the Intel convention.

static void HandleShowIncludesCommand(void)
{
Here the compiler emits the function prologue, i.e. a series of instruction that prepares the execution of the code within the function. This is a typical prologue sequence: establishing a new frame (frames are kept in a linked list), making space for local variables, and saving the registers used.
pushl   %ebp		; Save frame pointer in the stack
movl    %esp,%ebp	; Establish new frame
subl    $52,%esp	; Make space for locals
pushl   %ebx		; Save registers. Save EBX
pushl   %esi		; Save ESI
pushl   %edi		; Save EDI
	FILE *f;			; Note that this declarations generate no code
	HWND hwnd;
	char *p,*tmpfile = tmpnam(NULL),
This is the typical case of a function call. The arguments are pushed from right to left to the stack, then the function call is done, and the stack adjusted. The result of a function call is left by convention in the register EAX.
	pushl   $0		; Push first argument: NULL
call    _tmpnam	; call the tmpnam procedure
addl    $4,%esp	; adjust the stack
movl    %eax,-44(%ebp) ; Save the result in the stack frame of the procedure
*prjOptions = NULL,
	movl    $0,-40(%ebp)   ; Put zero in that variable
*q;
char *filename = CurTxtBuf->BufferName,
Here the compiler emits code to access a structure. First, the compiler emits code to access the start of the structure, then adds the offset till the field we want to access.
movl    _CurTxtBuf,%edi ; Move start address of the global into the register edi
addl    $29,%edi		; Add the offset of the BufferName field
movl    %edi,-52(%ebp)	; save result at the address of the local variable
	int tablevel = 0,i;
	movl    $0,-8(%ebp)		; Set the tablevel to zero
	PROJECTINFO *prj = GetCurrentProject();

	if ((CurTxtBuf->BufferFlags & BFIS_C_FILE)==0) {
Again, we access a field of a structure, to test a certain bit. This is done by reading the value stored there, and ANDing it with a power of two. This sets the machine flags accordingly, and we can use the jump instruction, that reads implicitely the flags.
	movl    _CurTxtBuf,%edi	;read the value of CurTxtBuf into register EDI
testw   $1024,27(%edi)	; compare the contents of  short at edi+27 with 1024
jne     _$358			;If its different, skip the next block

		sprintf(buf,"%s: not a C file",filename);
We make again a function call, this time with three arguments. Note that we push a pointer to an anonymous character string generated by the compiler, not the character string itself.
pushl   -52(%ebp)	;Push the variable filename
pushl   $_$360		;Push a pointer to the anonymous variable _$360, the string
pushl   _buf		;Push the variable buf
call    _sprintf	; Make the function call
addl    $12,%esp	;Adjust the stack: each arg was 4 bytes, there was 3, then 12.

		strlwr(buf);
	pushl   _buf		;Again a function call with one argument. Push it
call    _strlwr	;Make the call
addl    $4,%esp	;Adjust the stack: one argument is 4 bytes.

		ShowDbgMsg(buf);
Here we make a function call to a function that has the _stdcall calling convention. Note how the name of the function is mangled with the size of the expected stack. Note too, that there isn’t any stack adjustement. The _stdcall functions will clean up the stack themselves.
pushl   _buf
call    _ShowDbgMsg@4
.line   469
jmp     _$357		;Jump to the epilogue of the function to prepare for exiting.
		return;

We stop here. The objective is just to show you the two different levels of representation of a program. The high level, where the programmer writes about logical constructs, structures, FILEs, etc etc, and the actual machine level, where there is only moving data into/from the registers, making calls, etc etc. The compiler is then the software that binds this two levels of representation, and makes it possible to pass from the high level into the lower ones, so that the program can be run by a microprocessor.

Note too, that the ‘lower’ level we have shown here is not what the machine sees, of course, but just mnemonics used by lcc-win32’s assembler. The machine sees only the binary representation of the encoding of those mnemonics, i.e. a long sequence of numbers.

The compilation process

To get an executable then you have to 
1. Compile with lcc a source file to obtain an object file
2. Link the object files with the resource files into an executable using the linker lcclnk
3. Find out why the program doesn’t work as expected using the debugger.

Compiling C code into an executable is a fairly involved process to be described below. Before doing that, it is necessary to know exactly what is the ultimate goal of that process: the executable.

When you click in a program icon, or type the name of an executable in a command window, the program that is referenced to, by the icon or the name, starts. This is such a common day experience, that we tend to forget what is really happening behind the scene.

What happens, in any operating system, and Windows is no exception, is that a program called ‘loader’ is invoked by the operating system. Roughly, the loader works as follows:

It finds the disk file that is associated to the command or icon.
It reads and executes the instructions stored in the file concerning the loading process.4
It establishes the memory mappings between the program’s virtual addresses, and the real memory addresses that the program will use. This means allocating a virtual memory space for the program.
It copies from disk into memory, the sequence of numbers (machine instructions) that make the program, and its associated initial data space (static data).
It finds all the dynamic link libraries that are needed by the program, and links them into the process’ address space. The addresses in the program that point to external Dlls are resolved, and patched in memory by the loader. If any one of those references is missing, the program will not be allowed to run, and a message box informs the user that ‘The procedure <such and such> cannot be found in the DLL <such and such>‘.
It determines the starting address of the program.5
It creates a process within the OS, and sets the program counter of that process to point to the starting address, also called ‘Entry point’ in the technical literature.
It starts running the code in the entry point of all Dlls that are used by the program, informing them that a new process has loaded them.
If a debugger started the process, it stops, and gives control to the debugger, to allow it to do its initialization.
And then, at last, passes control to the first instruction at the program’s entry point.

And that is it. All this complex sequence of events takes less than a second.

Executable code is much more than a sequence of numbers that the CPU can interpret. It is a complex interaction between several tools that contribute to the final product: the editor, where you type your program in, the compiler, that translates them into machine instructions, the linker, that assembles the different modules into one executable, the resource compiler, and several others, like, for instance, the loader, that will do the final job.

The objective of lcc-win32 is to produce an executable file, derived from the instructions you write in C, and that will execute exactly those high level instructions in machine language. The process of translating the C instructions into an executable is the compilation process.

A closer look at the compilation process.


Overview
Here is an overview of the different phases of this process in more detail.

Functional Unit
Tasks performed
Compiling a C source file with lcc.exe
Pre-processor

ncpp.c
Macro expansion
#define substitution
#if ... #endif conditional compilation
#include file processing
Front end
lex.c, decl.c, expr.c, simp.c
Lexical analysis
Tree generation
Simplification of expressions
Conversion of trees to DAGs
Common sub expression elimination
First optimization pass
Global register allocation
analysis.c
Determining which variables are going to be stored in which registers for the duration of the function. This is performed only if the user requests the optimization option.
Finds out the block structure of the program
Constant folding
Labeler. Win32.c
Choosing the right instruction sequence to execute
Register allocator gen.c
Choosing which registers will contain which information in the instruction sequence generated by the labeler.
Code generator 
gen.c
Combining instructions with registers to produce ASCII assembler mnemonics
Peep-hole optimization
Optim.c
Improving the instruction sequence
Assembler
Asm.c
Converting the assembler text codes into opcodes
Emitting the relocation information
Emitting the debug information
Building a COFF object file (.obj)
Resource compiling with lrc.exe
Pre-processor
Exactly the same as the preprocessor phase above.
Resource compiler
Analyzes the resource file text, and generates the binary resource format. This is done by :
recognizing tokens from the input stream, and then 
Recognizing predefined token sequences in the token stream. 
Organizing the structures read from the text resource file into a binary resource file (.res).
Its output is a binary resource file (.res).
LINKING with lcclnk.exe
Linker
Convert any binary resource files into COFF
Link the debug information (if any).
Combine all object files into an executable file ready to run
Generate an import library if linking a DLL.
Debugging with wedit.exe
Debugger
Reads the executable and its debug information, and allows the user to single step through the code, or to set breakpoints, etc.

Lcc-win32 supports the separate compilation model; i.e. you translate first one or several modules separately, and then give all this modules to a program called linker, that will assemble them into a single module called executable file. This is then, a two-phase process.
The objective of the first phase is to produce a special file called object file6. The details of this first phase are as follows:
1. The compiler7 will open a file of C instructions, and will make several transformations of it. First, it will pre-process those instructions following the pre-processor directives, and produce a translated set of C instructions. This set contains all the files indicated in the #include directives, has been stripped from all comments, all #defines are replaced by their definitions, and with several other transformations like ## substitution, etc.
2. The result of this pre-processing will be feed into the compiler proper that will output a series of more basic instructions called ‘intermediate language’ instructions. Those instructions form the vocabulary of the virtual machine that lcc assumes as an abstraction of the real machine.
3. Those instructions will be given to the code generator that will select the best sequence of real machine instructions from several possible choices. This is called labeling the intermediate language tree.
4. The labeled tree will be used by the emitter to output a sequence of ASCII assembler mnemonics that corresponds to each intermediate level instruction.
5. If the user specified an optimization pass, those ASCII mnemonics will be go to the peephole optimizer, that will further work on them, mostly with the objective of eliminating instructions and improving the code emitted by the code generator ‘gen’.
6. Then, those text mnemonics will be passed to the assembler, that will translate them into numerical codes, that the CPU can understand. All those numbers will be packed in a special format called ‘COFF’8, and written to a file called ‘object’ file.
7. Those numbers are written according to the specifications published by the company that makes integrated circuits like the Pentium for instance. This company is called ‘intel’ (in lowercase) an acronym for INTegrated ELectronics. That company is not the only one that makes integrated circuits that understand those numbers. There are several others, and those numbers have become very popular. All of them produce circuits that are called ‘lcc-win32’ compatible in the literature...

The second phase is the ‘link-editor’ phase. This program (called lcclnk.exe in the lcc-win32 system) assembles all modules produced in the first phase, together with optional resource files produced by the resource editor, and library code, into a single file, that the operating system knows how to load and run.
Windows uses a set of files called RC files, to describe in a textual form, several resources used by the program like menus dialog boxes, message strings, etc. These files are written in a special language, with a very simple grammar.9 This files can be compiled using the resource compiler lrc.exe’, that transforms a RC file into a binary .res file, in a similar fashion that the C compiler transforms the .c file into a .obj file.
Windows supports an operating system extension called ‘dynamic linking’, i.e. linking a program when it is being loaded rather than in the linking phase described above. If you use this feature, you build an executable that is called DLL10 Lcc-win32 supports dynamic linking, and their associated definition files (.def), and other associated machinery.

The pre processor.

Dennis Ritchie, one of the authors of the C language, wrote the pre processor of lcc. He and Brian Kernighan designed the C language to write the Unix system. 

I asked Dennis Ritchie about this program, and he answered :

« I'm glad you found the preprocessor useful.  Incidentally,this particular program is younger than lcc (it is not one of those things that came from early Unix).It's just an atttempt, more or less for fun, to implement a C89 preprocessor, which we needed for the Plan 9 system »

The pre-processor will input from disk the C source files, and will create an output stream containing the text of that file, without any pre processor instructions like #define, or others. It will concatenate all included files in the output stream, and present to the compiler proper a text without any comments or macro definitions.

The pre processor scans each token in the input, to verify that is not a macro. This lexical scanning repeats somehow the lexical scanning done later by the compiler itself. Many times I have thought about eliminating one of this redundant scanners, but each time I stopped at several difficulties. Basically I have arrived at the conclusion that it is better to have a separate scanner after all in each part of the system, since they are centered towards different things. Lumping them together would mean a hopelessly complicated piece of software.

The compiler

The output of the preprocessor is read by the compiler’s lexical scanner that lives in lex.c. The scanner classifies the input, and returns an integer that encodes the meaning of the current token. Lcc’s technique for parsing is called ‘recursive descent’, and it is better described in the book of Fraser and Hanson, so I will not repeat that book here.

From the input stream, the compiler builds first a tree representation. As each construct of the language is recognized, a parse tree is built containing the information gathered from the input. This sequence of trees is the first abstract representation of the program structure. At the end of each statement, this sequence of trees is passed to the function listnodes, in dag.c, that builds the dags11 containing statements in lcc’s intermediate language. These dags represent simple operations like ADD, MULTIPLY, etc. This is a much simpler vocabulary than the C language, and this is precisely the goal of the whole operation: to arrive at a lower level description of the trees generated by the front end. These operations are common to many microprocessors, not only the x86 series. Lcc is a portable compiler, i.e. it works at a level of abstraction where the common features of all microprocessors are recognized, so that porting the software to a new machine implies only rewriting the lower levels and the machine description. The front end is independent of the machine itself.

The nodes built by listnodes are appended to the code list that is stored to be processed later, when the end of the current function is reached. Code can be generated only inside a function, and lcc generates the code for each function when the front end is done with it, and the last matching brace has been read.

When that happens, and if you specified the optimize option, a quick analysis will be performed with the code list, mainly to optimize certain constructs like:
	a = (b == 8) ? 6 : 3;
for instance. The analysis phases discards unnecessary labels, to increase the size of the basic block that will be seen by the peephole optimizer. This analysis is performed in the file analysis.c.

Then, the code list goes through the function gencode that converts the dags into trees, and in this conversion step, uses the dags to discover the common sub expressions in the source code. These resulting trees go through the labeler.

The labeler is one of the finest pieces of software that make lcc. It consists of a utility called ‘lburg’, that will input a machine description in a special format, to be described later, and outputs a C program that will try to find the best sequence of assembly instructions from the many possible sequences. It uses linear programming to reach this goal.

The labeled trees are then passed to the genasm() function, that converts them into assembler mnemonics. That ASCII assembler mnemonics are eventually passed to the assembler that converts them into actual machine codes, to be stored in the object file.
Lcc’s intermediate language
Lcc is a retargetable compiler. Each back end for each different machine has its own machine description, specifying the rules to convert the trees generated by the front end into actual assembler mnemonics. 12These files have an extension of .md, for machine description.

This machine description is nothing more than a sophisticated table of correspondences between the instructions of the abstract machine, and the instructions of the concrete machine that will execute the program being compiled, in our case an x86 processor. 

Here we have a rule taken from the machine description for the x86:

stmt:									(1)
			ASGNS(						(2)
				addr,
				CVIS(
					ADDI(
						mem16,con1))) 
			"\tincw\t%0\n" 				(3)
			immediateOpShort(a)				(4)

We see here four parts:
1) The ‘stmt:’ part. This means that this rule is executed for side effect and doesn’t return a result. A rule can return a result, for instance in a register.
2) The ASGNS ( ) part. ASGNS means assign short, i.e. 16 bits. This is one of the words of the intermediate language vocabulary. The notation used is lisp like: ASGNS takes two arguments, the first is an address, and the second is the result of the operation CVIS, or ConVert Integer to Short. That operation takes itself only one argument: the result of the ADDI operation. That operation is an integer addition, and takes a 16-bit memory location, and a constant, in this case, the constant one.
3) The assembly language part enclosed in double quotes. This part is the translation of the operation ASGNS(addr(CVIS(ADDI(mem16,con1))): it is very short, because the x86 has many powerful instructions (the CISC concept). The instruction that does all that is the INC instruction decorated with the w suffix, to indicate to the assembler that a 16-bit quantity is being incremented. The conversion to/from 16 bits are not necessary. Note that the incw operation takes one argument denoted here with ‘%0’, i.e. the first argument of the ASGNS instruction: the ‘addr’.
4) Note that 'addr', 'mem16' and 'con1' are non-terminals, i.e. terms that are defined elsewhere in the machine description.

5) This rule is guarded by a C expression, in this case the call to the function ‘immediateOpShort()’. This rule can only work if mem16 equals addr, and it is the task of that C function to verify that this is indeed the case.

Another rule is:

reg:  										(1)
	ADDP(									(2)
		ADDP(
			LSHI(reg,icon),
			reg),
		acon)
	"leal	%3(%2,%0,%1),%c"					(3)
											(4)

1) This rule returns a result in a register.
2) ADDP is a pointer addition operation. The outermost has two arguments: the result of another ADDP operation, and a constant. The innermost ADDP receives the result of a register left shift and adds to it another register.
3) All this operations can be mapped to the x86 instruction lea, for Load Effective Address. This versatile instruction adds can add an arbitrary constant to two registers, where one will be left shifted by 1, 2, or 3. The %n constructs indicate the kids of the rule. %0 is the first kid, (in this case 'reg'), %1 is the 'icon' (integer constant) non-terminal, %2 is the second 'reg', and %3 is the 'acon' (address constant) kid. To better understand this construct, we can read it from its innermost expression, and work our way outwards. We take the left shift expression LSHI(reg,icon). This expression shifts left a register by an integer constant. The result of this, is the first argument to the inner ADDP, so we are actually adding the result of the shift to a register. The resulting value, is used in a pointer addition operation again (the outer ADDP), to yield the access to the table.
4) There is no C expression or constant that assigns a cost to this rule so its cost is zero.

Interesting is to see all this in action in an intermediate language file. Here is an example of the last rule in a .lil file:

ADDP(										(1)
     ADDP(
          LSHI(
               INDIRI(ADDRGP(blocks)),
               CNSTI(2)),
          INDIRP(ADDRGP(first_block))),
     CNSTI(-4))

reg: ADDP(ADDP(LSHI(reg,icon),reg),acon) /      leal	(2)
		 %3(%2,%0,%1),%c
        leal    -4(%ecx,%edx,4),%edx				(3)
1. This is a concrete example where this rule is used. Note that the non-terminals have been replaced by real things and not symbols, i.e. the first ‘reg’ non-terminal above is the result of INDIRI(ADDRGP(blocks)), an operation that yields a register. The ‘icon’ 13non terminal is replaced by the concrete constant 2, and the second ‘reg’ non-terminal is the result of INDIRP(ADDRGP(first_block)), i.e. a pointer indirection (INDIRP) through the global (ADDRGP, address of a global pointer) ‘first_block’.
2. The rule is displayed in another format.
3. The effective assembler code generated is enclosed in quotes.

From that, the assembler will produce: 8d5491fc.

Following an expression:
Consider:
			int c;
			...
			printf("%d\n", (5*c+c/2)/2 );

The intermediate code generated looks like this in the .lil file:
ASGNI(									(1)
     VREGP(3),
     INDIRI(ADDRLP(c)))
ARGI(DIVI(								(2)
          ADDI(
               MULI(
                    CNSTI(5),
                    INDIRI(VREGP(3))),
               DIVI(
                    LOADI(INDIRI(VREGP(3))),
                    CNSTI(2))),
          CNSTI(2)))
ARGP(ADDRGP(2))							(3)
CALLI(ADDRGP(printf))						(4)

1. In the first tree, the value of the local variable ‘c’ is assigned to a register since it will be used several times in the expression. This ‘common sub expression elimination’ is done in the file dag.c, by the function ‘visit’. The value of c then goes to the EDI register. The code for deciding which register is used is in the file gen.c, specifically in the function ralloc(), for register allocation.
2. In the second tree, the first argument to the printf call is calculated and pushed (ARGI). 
3. Then the second argument, the address of the character string "%d\n", is pushed (ARGP).
4. Then the call is done

Now, consider the thick argument (2). This is the result of a calculation that runs as follows:

The first expression to be evaluated is the multiplication. This is:

MULI(
     CNSTI(5),
     INDIRI(VREGP(3)))
The rule that the labeler returns for this is
reg: MULI(con5,reg) /   leal    (%1,%1,4),%c
        leal    (%edi,%edi,4),%esi

You will maybe wonder where the multiplication by five is. Well, leal (we come again to that, I told you is versatile), can be used to multiply by five: You multiply by 4 and add the register to the result. The EDI register here, will be shifted by 2, what’s equivalent to a multiplication by 4, and then its contents will be added to the result. Because 

	5*x == (4*x) + x

The result of this is stored in the ESI register. This is much faster than a multiplication that takes over 40 clocks.
Then, the evaluator goes on with the second argument to the addition, the result of a division.

For the tree 

DIVI(
     LOADI(INDIRI(VREGP(3))),
     CNSTI(2))
the labeler will choose the rule:
reg: DIVI(reg,reg) /    cdq
        idivl   %1
        cdq
        idivl   %ecx
This instruction, DIVI, needs absolutely its argument in the EAX register. The x86 is like that. So, we have to put first in EAX the argument. This is accomplished by the LOADI instruction that moves a register to another.

The rule is then:

LOADI(INDIRI(VREGP(3)))
reg: LOADI(reg) /       movl    %0,%c
        movl    %edi,%eax
Now, we have the first member of the addition in ESI, and the result of the division in EAX.
We can at last, perform the addition.
reg: ADDI(reg,mrc) / ?  movl    %0,%c
        addl    %1,%c
        movl    %esi,%eax
        addl    %eax,%eax
An addition between a register and a constant, a register or a memory location can be done with the ADDL instruction.
A bug
Wait a minute... You didn’t notice something weird above?
We move esi into eax, and then add eax to itself... This is completely nonsense!!!
We are clobbering the input of the addition before the addition is done!

Well, I WAS happy when I finally arrived at this. It was  A. K. Mohanty, that send me a message warning that the following program:

#include <stdio.h>
int main()
{
	int c=4, k;

	c = 4;
	printf("%d\n", (5*c+c/2)/2 );
	k = 5*c+c/2;
	printf("%d\n", k/2 );
	return 0;
}

When compiled by LCC, it prints

20
11

instead of the correct result

11
11

I was completely astounded that such an enormous bug still existed in lcc-win32. But yes, it was true. The problem is, that the operation here ((5*c+c/2)/2) has two nested divisions. This is not so common, but this one uncovered the fact that I should save the results of the division operation, and other operations that force a fixed register. The correct code for the above operation is:
DIVI(
     LOADI(ADDI(
     ^^^^^   MULI(
                    CNSTI(5),
                    INDIRI(VREGP(3))),
               DIVI(
                    LOADI(INDIRI(VREGP(3))),
                    CNSTI(2)))),
     CNSTI(2))

That LOADI instruction is absolutely necessary to save the intermediate result!
I patched rtarget() in gen.c to take into account this fact. The code generated is then:
reg: ADDI(reg,mrc) / ?  movl    %0,%c				(1)
        addl    %1,%c
        movl    %esi,%edi
        addl    %eax,%edi
LOADI(ADDI(
          MULI(
               CNSTI(5),
               INDIRI(VREGP(3))),
          DIVI(
               LOADI(INDIRI(VREGP(3)))
               CNSTI(2))))
reg: LOADI(reg) /       movl    %0,%c				(2)
        movl    %edi,%eax

Here the value of ESI is saved into EDI, where the addition is performed (1), and then, the result of the addition goes into the EAX register, to prepare for the following division.

This is not optimal: it would be much better to add ESI to EAX and be done with it, but at least is correct. Nested divisions aren’t all that common, so a few cycles lost here will not make a big impact in code quality overall.

Programmers do not like to speak about their bugs. I am not masochist, but I think much can be learned from bugs. Personally, I do not like those technical manuals that do not expose the real problems to the user.

Tracking this kind of bugs is very difficult. Actually, most of the work consists in trying to find where the bug is. Once it is found, the solution is in many cases easier to find. In this one, it wasn’t. It costed me a lot of effort to see the problem in rtarget().

The machine description is stored in the win32.md source file. The utility ‘lburg.exe’ translates a machine description into a C language file that can be compiled by the C compiler.

An overview of the abstract instructions of the virtual machine
The types supported by lcc-win32 are described by abbreviations. They are:

Type name
Description
F
Floating point number of 32 bits
D
Floating point number of 64 bits
C
Character type of 8 bits
S
Integer type of 16 bits
I
Integer type of 32 bits
U
Unsigned integer type of 32 bits
P
Pointer type of 32 bits
V
Void
B
Block type (structure)
L
Long long integer type of 64 bits
UL
Unsigned long long type of 32 bits
BOOL
Boolean type of one bit, stored into a character of 8 bits for efficiency.
LONGD
Long double type: 12 bytes


The operations supported by lcc’s abstract machine are few. Here is a description of each of them.

Instruction name
Types supported
Description
CNST
All
Constant value
ARG
All
Argument to a function
ASGN
All
Assignment operation
CVC
I,U,BOOL
Convert from character to some other type
CVD
F,I,L
Convert from double to some other type
CVI
All
Convert from integer to some other type
CVS
I,U
Convert from short to some other type
CVU
All
Convert from unsigned to some other type
CVL
D,I,U,UL
Convert from long long to some other type
CVULL
L
Convert from unsigned long long to some other type
NEG
D,F,I,L,UL
Negate
CALL
All
Call procedure
LOAD
All
Load into register
RET
All
Return from procedure
ADDRG
Pointer
Fetch global pointer
ADDRF
Pointer
Fetch argument from stack
ADDRL
Pointer
Fetch local variable
ADD
All
Add
SUB
All
Substract
DIV
All numeric
Divide
MUL
All numeric
Multiply
LSH
All integer
Left shift
MOD
All integer
Modulo operation
RSH
All integer
Right shift.
BAND
All integer
Boolean AND operation
BCOM
All integer
Negate each bit
BOR
All integer
Boolean OR operation
BXOR
All integer
Boolean XOR operation.
EQ
All numeric
Equals
GE
All numeric
Greater equal
GT
All numeric
Greater than.
LE
All numeric
Less or equal
LT
All numeric
Less than
NE
All numeric
Not equal
JUMP
void
Jump
LABEL
void
Named code position

We see here that the actual operations performed are actually only six/seven.
Arithmetic: ADD SUB MUL DIV MOD
Logical (OR XOR AND BCOM
Shifts (LSH RSH)
Comparison (GE EQ GT LE LT NE)
Goto (JUMP/LABEL)
Calls, return from call and argument passing. (CALL RET, ARG)
Assignment (ASGN).
Allocating register variables
Before the labeller runs, just after the code list has been finished and the text of the function has been completely processed the ‘function’ procedure in file w32incl.c will call the SetupRegisterVariables procedure in analysis.c.

This procedure has the following algorithm :
Decide which registers will be available for register variable allocation. The ‘SetRegistersMasks’ function in w32incl.c decides this using the information about the function gathered by the parser and the front end.
A table is constructed with all local variables of the current function, including function arguments. This table is then sorted by the ref field of each symbol, to put  the most used variables in the function first.
A variable is candidate for being a register variable only if its address is nowhere taken, its size fits in a register (4 bytes at most), and is not an aggregate (structure, union or array). Only variables that have a ref field bigger than 2.0 will be used.
The sorted table is then inspected, and the first three variables are allocated to a register. 
When a register is allocated, the life span of the associated variable is searched, and if another variable in the table has a disjoint domain, i.e. the uses of the two variables never intersect, the other variable will be allocated to the same register. (Register variable aliasing)
A second pass through the list is done after register allocation to see if there are holes in the register usage we can fill with some variable from our table.

To decide which registers will be used for variables the compiler uses the following heuristics:

If the function has no integer divisions or modulo operations and no block-move instruction, EBX, ESI, and EDI are available for register variables.
If the function is not a leaf function, or uses integer division, only ESI and EBX are available
Else, use only EBX for register vars.

Allocating registers for expressions
After the labeller is done, the compiler needs to assign registers to each construct. If the expression needs a register, the register allocator looks in for a free one, and assigns it to the expression. This is done in the function ralloc(), in file gen.c.

In general, lcc-win32 uses two kinds of register allocation strategies :

1. When no optimizations are requested, there are no register variables, and the compiler starts looking for a free register beginning with ESI or EDI, descending until EAX. This means that in most cases ESI or EDI will be selected, unless the expression is a really complicated one that will need 3 registers. In that case the lookup can reach EBX. This is the original strategy used in lcc, that is still in use up to the latest one, lcc 4.1.
2. Optimizations are requested. In this case, lcc-win32 starts by looking if EAX, EDX or ECX are free, and if not, goes on to the expensive registers EBX ESI EDI.

The calling conventions of most systems for the x86 require that EBX ESI and EDI must be maintained across any function call, i.e. the contents of those registers are saved at function entry, and restored at function exit. That is why in an optimization context, it is better to use EAX EDX and ECX, since they do not have to be saved.

This is much more complicated, however, because some operations like division or block-move instructions require their inputs in a specific set of registers that can’t be changed.

The register allocator has to know if it is safe to use the lower numbered registers or not. This is the meaning of the flag ‘unsafe’ in the code of the function ‘askreg()’. This flag will be set by the high level optimizer that is called before ralloc runs. The compiler (in ‘analysis.c’) looks for operations that would make any use of lower numbered registers unsafe, and marks the nodes accordingly.

There are some operations, however, that make all this extremely difficult. Division, for instance, needs the dividend in EAX, and the divisor in another register. Yet another register is usually used to store the result, and EDX is destroyed by this operation. So we have that this operation needs 4 registers out of 6 available.

Since any function call will destroy EAX EDX and ECX, we can’t store any of those values across function calls, and we have to either spill them, or try to find a higher numbered register available.

I have been able to keep in most functions EBX ESI and EDI free for allocating them to register variables. This is done with the help of the pre-scanner, that marks interesting nodes as safe or unsafe. See the code in analysis.c, function ‘BuildBasicBlocks’.14

That function will linearize the linked list of nodes, joining them through the x.next field. The list is parsed by the function ‘FindSymbols’ that tries, essentially to:
Build a count of labels to erase later unneeded ones, and to 
Mark each node as safe or unsafe, depending on the operation being performed.

With this information available, the register allocator has a difficult but doable job. I have been able to drive it through complicated expressions that need a lot of registers without breaking it down.15

The circuit where this software runs is not designed, it just grew and grew, but not in the right direction Intel has modified very little the original 8086 design, just widening ax to eax, but that’s not a really big deal. No new registers have been added to this architecture since the 8086 days, more than 10 years ago. This is a huge time, and I have (as probably many other Intel users before me) often wondered why this is so. I have speculated that it is because compatibility with older software, wishes to keep the software investment that many people have done to drive the circuit.

But a register extension wouldn’t need to be incompatible with older software. Just new opcodes would be needed, and older software would go on running. It is maybe possible that Intel has painted itself in a corner and there are no more opcodes available, but that’s impossible: the escape opcode was always there.

Why didn’t they add a few registers to the circuit then?
Mystery. They have the capability of adding a lot of special code circuitry to do MMX and now SIMD parallelism and I thought for a moment that they would add a 

‘MOVG 	screen, game’ 

instruction, that would read your game from disk and play it for you at high speed.

Is it right to program the graphics card into the CPU? 

I asked that to some Intel researchers but they gave no answer. The circuit that Intel sells is a general-purpose circuit, i.e. one that is designed to do anything. Not only to run games. Actually, most of the PCs today do office-like tasks (word processing, business software development, accounting, mail, and similar tasks). For these tasks, high-speed graphics operation can be left to the graphic card that with its special purpose processors will always do better than Intel. In a specialized graphic display, the algorithms, the way of drawing, and the associated special purpose circuitry can be changed quickly, from one model to the next. True, there are some algorithms that can be better programmed in software for flexibility, and the abstraction of the mmx operations would be a good idea in a context where you have plenty of registers to go fast, but not in the crowed conditions of the x86 architecture.

This is going to end with the arrival of the 64-bit Merced, says Intel. Maybe true, but I do not see why decreasing the register starved condition of the circuit would do any harm… The complicated circuitry to speculate what the next instruction will be looks more complex to me than adding a set of 26 new 32 bit wide general-purpose registers, what would make the processor much more independent from the main memory subsystem.

There is no point in getting a 1 GigaHertz processor if main memory still runs at 15 MHz and the processor needs a lot of memory access because there are no registers to store intermediate results or local variables.

True, there is a cache, but if the cache influence is good, I can readily imagine what the influence of 26 new registers more would mean. Gigabytes of memory accesses would be avoided.

But I am digressing here, we were faced with the task of using the incredibly few registers available, taking into account all quirks. Like the one that forces you to save the floating point flags somewhere, set them to truncation in the ‘C’ language sense, doing the conversion, and then setting the flags as they were again.

The C code is

	double a=7.8;
	int a = (int)a;

But if you want to write a compiler for windows you can’t change the circuit. It is done, and it is better to cope with it rather than lamenting. Conclusion: ESI EDI and possibly EBX are reserved for register variables only. 

Lcc-win32 tries hard to use every possible mode that the machine has to offer. Byte or word specific instructions will be inserted when possible. The register allocator collaborates to this task by avoiding registers ESI or EDI for character operations since they do not have byte wide sub-registers. The registers EAX, EBX, ECX and EDX can be addressed as 16 bit or even 8 bit registers, so for character or short operations it is better to avoid ESI or EDI.

Some operations require their inputs in specific registers. This is done in the function ‘rtarget’ in w32incl.c

In a second pass after register allocation, I look for leaf-functions, i.e. functions that do not have any function calls. In those functions, it is safe to exchange ESI by ECX for instance, if ECX isn’t used. This saves the push and pop instructions for saving and restoring the contents of ESI. The cases where this is done are few, and the register allocation schema of lcc supposes quite a few registers more than the x86 has to offer.

A better strategy would have been to allocate registers in a basic block instead of globally for all the function. But that would have meant a complete rewrite of the code generator and specially the register allocator.

Debugging a register allocator and its corresponding spiller is a task that takes years. The one that Chris Fraser and Dave Hanson wrote has been running for a few years, and is possible to improve it for the x86 situation. Rewriting it completely would have been an impossible task.

The code generator

The function emitasm, in gen.c receives the labeled tree list, and builds a textual output stream with the instructions it finds in the rules. If you specified the optimizer option in the command line, the output stream will be first be redirected through the peephole optimizer that lives in optimize.c. The peephole will be described later, here it is enough to say that it tries to eliminate instructions as much as it can, and to inline certain functions of the C library like memset or strcmp.

The emitasm function will fill the arguments for the rules, as specified in the ‘%0’ constructs or in the %a or %c directives (for symbols).

The escape instructions inserted by the pre-label pass end up here. They call the emit2() escape hatch, to generate special purpose code for implementing predication, for instance, or for implementing the CMOVxx instruction. You will notice in win32.md that all escape instructions start with '#’, that is a signal to emitasm that should call emit2. There, I do the improvements of the conditional statement described later. Constant folding can generate escape instructions too, for instance for transforming tests into NOPs without disturbing the code list.

The pre-labeller will expand constants during the constant-folding optimization phase, and you can end with comparisons like if 6 == 6. Instead of generating code for it, the node’s op field is changed to the escape opcode that I assigned in win32.md. In the ‘oldop’ field, I encode the information that will later be processed in emitasm and eventually emit2 that will just ignore it, transforming the whole comparison into nothing.

The emitasm() function is full of functionality:

If the node is a label, the code that was accumulated in the buffer will be sent to the peephole optimizer.
If the function has no frame pointer, adjust the code to use ESP instead of EBP. This makes in fact EBP available as a general-purpose register.
Make an effort to ensure that an instruction doesn’t destroy its source operands when doing the operation.
Process the ‘%x’ directives in rules
If it is an intrinsic call, call the intrinsics interface with the node to generate special purpose inlined functions.16
If the node represents a function call and the debug level is higher than two, the current line number and context is saved before the call.

Lcc accumulates the assembly mnemonics in a buffer that before17 was simply written to disk. I added an optimizations phase in emitasm() to call a parser of those mnemonics, that synthesizes an abstraction of those instructions to be used to update the State variable in the FindStateChanges() function in optim.c.

The directives followed by emitasm are the following:

Directive
Explanation
%a
Use Node->syms[0]->x.name
%b
Use Node->syms[1]->x.name. Not used
%c
Use Node->syms[2]->x.name. This is usually a register name
%0
Use the first child as indicated by the _kids function
%1
Use the second child
%n
Use the nth child
%l
Generate a temporary label
%L
Use the last generated temporary label
%k0a
Use Node->kids[0]->syms[0]
%k0c
Use Node->kids[0]->syms[2]
%k1c
Use Node->kids[1]->syms[2]

The intrinsics interface is implemented as a several step process:
In the function ’call’ in enode.c, a flag is set if the function name is found in the intrinsics table. To avoid name clashes, the function must be declared as _stdcall.
This flag is copied to the corresponding tree in dag.c
Emitasm() tests this flag, together with the register allocator, that needs to call the interface when handling the arguments of the intrinsic, if any. The actual interface call is done in emitasm.

The assembler.

The output stream will be feed then to the assembler, where it is converted in a sequence of numbers that go in the object file. The assembler is described in detail later. Here it is enough to say that, besides transforming the ASCII mnemonics into numbers, it builds the debug information that will be used by Wedit’s integrated debugger to follow the program execution.

It should be noted here, that lcc-win32 assumes at least a 486 processor. If you have an old machine with a 386, lcc-win32 will NOT run, since sometimes in its code instructions like ‘xadd’ are used, that do not exist in the 386 series.18

You can examine the intermediate result of each step of the compilation process described above with the following directives:
To see the output of the preprocessor, use lcc -E source.c. This will create a file called source.i that will contain the pre-processed source.c file.
To see the output of the front end, and the intermediate language use: lcc -z source.c. This will create a file with the same name as the original .c file, but with a .lil extension for lcc’s intermediate language.
To see the output of the optimizer/input to the assembler phase, use lcc -S source.c. This creates a source.asm file, containing the assembler instructions.
To see a textual description of the binary source.obj file, use the utility ‘pedump’, that comes in the bin directory of lcc-win32 distribution. It will display all information that the object file contains in textual form.

Modifications done to lcc

Lcc-win32 presents some adaptations of the original code of lcc 3.6 to the windows environment. Here I present a rather sketchy account of the process of writing those adaptations and building a windows compiler.
Porting the code
Lcc’s code ported without great difficulties to Win32. It is a code without surprises, well written, and after only a few minor modifications, I had it running under Win32’s command line.
Integrating the preprocessor into lcc
The traditional approach, used by Unix compilers like gcc, is that the preprocessor produces an intermediate file as output that is read from disk by the compiler proper that produces an assembly file. That file is again read from disk by the assembler, that produces an object file. This approach allows a clean separation of each tool, but has an enormous drawback: it is very slow. The amount of disk I/O that the machine is forced to do is considerable.

I decided to avoid any intermediate files. For some time I played with the idea of using the pipe mechanism of Win32 to make all tools communicate, but after a while, I decided for a tight coupling of all three tools. Pipes are bound to be slower than a program specific solution because:
You have to copy the data into an operating system buffer
There, the OS copies the data into another buffer (probably) to pass it to the receiving program
The receiving program has to copy it again into its own buffers
Many context-switches between both programs and the OS happen in between.

Better mechanisms exist of course, like shared files in memory for instance. But then, you have to take into account the synchronization problems and other goodies... And all that for doing what? Just for sharing a buffer full of data between two modules?

The fastest solution that I know of is to link the two modules in a single program and just share the buffers. Period. No context switches, no copy, no synchronization problems since you have only a single thread of execution. And this solution follows a guideline I try always to follow: the KISS19 principle.

The preprocessor does the only I/O operation that is absolutely necessary, and puts at the disposition of the compiler a buffer containing the characters preprocessed so far. The compiler reads this buffer, and generates a second buffer for the assembler, that reads it, and generates the object file, making the second disk I/O.  No copy is needed, since the buffers are just shared and only a pointer to the start of it is passed around.

The modifications to lcc that were necessary to do this were actually very small. The main one was in the code of the preprocessor: instead of reading the file from start to end, it should read more input only when the compiler needs it. This is done in the function ReadFromCpp (), in the ncpp.c file, in the compiler’s sources directory.

Supporting Microsoft’s extensions
A purely ANSI compiler will not compile the standard <windows.h> header files. The main stumbling block is the ‘stdcall’ calling convention. A windows compiler is forced to recognize this keyword (_stdcall or __stdcall). Other problems with special purpose syntax include the __declspec syntax, the unions with anonymous members, and a several similar non-ANSI conforming constructs. All in all we have to see how much progress was accomplished since the days where you had all those “_far” “_near”, “_huge” whatever…

Calling conventions
Calling conventions are a standard for pushing the arguments into the stack, preparing for a function call, and for cleaning it up after the call, removing the arguments pushed into it. The normal calling conversion in C is to push the arguments from right to left, and to generate code after the call for adjusting the stack.
The sequence then, looks like this

	push	arg3
	push	arg2
	push	arg1
	call	_foo
	addl	$12,%esp

This would correspond to the call:

	foo(arg1,arg2,arg3);

The _stdcall calling convention
This calling convention is used in almost all the Win32 system calls. Functions that are _stdcall’ should:
1. Push the arguments from right to left, as in normal C calls
2. Do not adjust the stack after the call since the called function adjusts it when it executes the ‘ret’ instruction.
3. Add the stack size to the function name. For instance for a function like:
	int _stdcall fn(int,int);
	the name of the function should be changed to _fn@8.
The rationale for name decoration is very simple. If you omit a header file, and you call a _stdcall function _foo() without any previous declaration, the compiler will generate a call for _foo. Since the name of the function has been changed internally to _foo@8, the link will fail with a missing symbol. This may be seen as harsh or unnecessary, but imagine the mess that would ensue if this wasn't done! It would suffice to forget one header file/declaration somewhere, to ruin completely the application, that would crash randomly, at different places and at different times, depending on where the faulty call instruction was.

This needed a lot of modifications to lcc’s source code.
I added the _stdcall keyword to the lexer, so that it would recognize it (see lex.c)
I added a flag to the symbol and type structures so that this information would eventually arrive to ‘emitasm’ in gen.c.
I modified many functions in ‘decl.c’ to keep that flag, accept it, pass it around, etc.
In gen.c I planted a test for that flag, when it emits a ‘call’ instruction. If the test succeeds, it will not emit the ‘add $x , %esp’ code. 
In ‘win32.c’ I test for that flag when building an internal symbol name. If it is set, I add the famous ‘@8’ to the name. Besides, in the procedure ‘function’, I emit a ‘ret stacksize’ instead of just ‘ret’. This means that the keyword will not only work for system calls, but also it can be used in user programs too. Now that it is done, I recommend its use, since for each call you save 4 bytes. For a function that is called very often this can make significant space savings.
Since there was in the headers sometimes ‘_stdcall’ or sometimes ‘__stdcall’ I added an internal #define to convert from one to the other.
Problems encountered when implementing _stdcall
A subtle problem appears when you declare a function as _stdcall, and this function returns a structure. Internally, the compiler will pass to that function a supplementary argument, the address of a place where the function should copy its result into. Consider then, the following code :

typedef struct tagS { // define some structure
	int a;
	double b;
} STRUCT;

STRUCT _stdcall function(double a,double b)
{
	STRUCT s;

	s.a = (int)(a+0.5);
	s.b = (int)b;
	return s; // This function returns this structure, not a pointer to it
}

int main(void)
{
	STRUCT s = function(0.7,0.8);
	printf("%d,%d\n",s.a,s.b);
}

If the compiler sees first the function definition, everything works : the function stack definition has been augmented with an extra parameter, and the compiler will name it « function@20 ». But if you write first a prototype for it, and THEN define it later, things will go wrong :

typedef struct tagS {
	int a;
	double b;
} STRUCT;

STRUCT _stdcall function(double,double); // PROTOTYPE ONLY

int main(void)
{
	STRUCT s = function(0.7,0.8); 
// call to function will be generated as function@16
	printf("%d,%d\n",s.a,s.b);
}
// This function will be named function@20
STRUCT _stdcall function(double a,double b)
{
	STRUCT s;

	s.a = (int)(a+0.5);
	s.b = (int)b;
	return s;
}

The compiler will generate in the first call to that function, a call to « function@16 », then, when seeing the function’s definition will generate a function called « function@20 » and linking of the object file will fail because of a missing definition of the  _function@16 symbol.

This example shows only the unexpected ramifications a simple change like this can have in a language system. This bug wasn’t discovered in lcc-win32 after several YEARS of use !20

The “declspec” construct.
Microsoft has introduced this construct to direct code generation for doing specific windows related things like dlls, or export/import tables.
Lcc-win32 implements following constructs:

1. The __declspec(dllimport) construct. This should guide the compiler to generate an indirection when referencing a data item that is imported from a DLL. Use this, when accessing any variable/data that is in a DLL.
2. The __declspec(dllimport) construct. This provokes that the following name is added to the export for a DLL.



Examples:

char * __declspec(dllimport) DllName; 
int __declspec(dllexport) myFunction(int a)
{
	return a;
}

The first example declares that the char * DllName is imported from an external DLL. The second instructs the compiler to add the name ‘myFunction’ to the list of exported names from a DLL, i.e. the names that are visible from outside, and will be included in the import library built by the linker.

Internally, this is accomplished by:
Substituting all occurrences of the symbol by its external21, decorated, representation, and
 Adding a level of indirection to it. 

The declaration:

int __declspec(dllimport) someInt;

is equivalent to:

#define someInt 	(*_imp__someInt)
extern int someint;

This means, take the contents of the memory location pointed to by the symbol __imp__someint. When you write:

	int a = someInt;

you are actually writing:

	int a = (*__imp__someint);

This is implemented using a parser modification in decl.c, and a modification of the routine to generate the external names in w32incl.c. Specifically, look for the constants DLLIMPORTATTRIBUTE and DLLEXPORTATTRIBUTE.

All this machinery is necessary for implementing dynamic linking. The linker will write to the executable file a table of symbols that have to be imported from another dlls before the program can run. The program loader before the program runs will scan this import table. The loader will replace all those addresses in the table with the addresses in memory where the corresponding symbol in the DLL was loaded. That is why we need another level of indirection: we need to access, not the address of the import symbol itself, but use the contents of that address as a pointer to get to the real data contents in the DLL.

The different #pragmas
I added several pragmas to lcc to support some options needed under windows: This pragmas are now case insensitive, and oversight from the earlier versions of lcc-win32.

1. #pragma pack(n)
This will set the alignment within structures to 1 (no alignment) to 4 or 8. Other values will be accepted but are no very useful...
A variation on this is
#pragma pack(push,n)
and the corresponding
#pragma pack(pop)
The first pragma instructs the compiler to pack the structures with the value <n>, but in addition to that, to save the old value of the packing constant in a pushdown stack. At the end of the file, you should use the corresponding pop, to restore the value to whatever it had when the compiler was instructed to change.
2. #pragma optimize(on|off)
This will turn on or off the optimizer for a certain part of the source
3. #pragma section(name)
This will set the current section name in the object code. Only needed for some obscure object code manipulations.
4. #pragma ref <symbol>
      The given symbol will be marked as used.
Structured exception handling
I have tried to implement all constructs that Microsoft defines for the C language. This part has been very difficult, and it is not completely finished, mainly due to a lack of documentation. In any case, __try, __except, work as Microsoft defines.
Writing the startup code
When you click in a program icon, or just type the name of a program at the command line, you invoke implicitly a program that is one of the basic pieces of any operating system: the program loader. This program will search and read for an executable file of the name that corresponds to the name you typed in or to the program the icon points to. It will load that program into RAM, fix it, and then pass control to the program’s entry-point. This is NOT the ‘main’ function (or the WinMain) but a piece of code that prepares the execution of the main line, doing some initializations first.

The startup of lcc comes in two flavors: the normal startup of an executable, called lcccrt0.obj, and the DLL startup called libcrt0.obj. Both object files reside in the ‘lib’ directory.

The task of that piece of code is to perform the initialization of the standard input/output, and call the ‘main’ or ‘WinMain’ function. Actually, the startup will always call the ‘_main’ function. If the program is a windows program, it doesn’t have any ‘main’ function, so the linker will find a ‘main’ function in the ‘libc.lib’ library file, and link it in. That function will call WinMain. This allows the lcc-win32 system to use only one startup for all .exe programs.

After the main function returns, the startup code calls the exit function, that returns control to the operating system.
Here is the code for the main function of the startup.

_mainCRTStartup:
        movl    %fs :0,%eax	  ; save the contents of the exception list
        pushl   %ebp		  ; build a stack frame
        movl    %esp,%ebp
        push    $0xffffffff	  ; build the exception handler structure
        pushl   $_$ExcepData
        pushl   $__except_handler3
        push    %eax
        movl    %esp,fs :0      ; set this structure at the top of the exception list
        subl    $16,%esp        ; space for local variables
        push    %ebx            ; save registers
        push    %esi
        push    %edi
        mov     %esp,-24(%ebp)
        pushl   $__environ     ;call GetMainArgs to get the command arguments 
        pushl   $___argv       ;for the ‘main’ function
        pushl   $___argc
        call    __GetMainArgs
        pushl   __environ       ; now push those for _main()
        pushl   ___argv
        pushl   ___argc
        movl    %esp,__InitialStack ; save the top of stack in a global
        call    _main
        addl    $24,%esp
        xor     %ecx,%ecx    ; invalidate the exception list element above
        movl    %ecx,-4(%ebp)
        push    %eax
        call    _exit        ; finish this process
        ret                  ; this is in case _exit returns, very surprising !
Writing the stackprobe code
In the firsts versions of lcc, this program would generate a trap:

main()
{
	int table[4096];
}

This would generate a fault, even if the program does nothing. After much research, I found the problem: The fault occurred in the procedure’s prologue, when the generated code executed the 
	sub	$16384,%esp
instruction.
As we will see in the linker chapter, Win32 reserves 1 MB of virtual address space for the program. Those pages aren’t committed; they are just reserved by the system. They will be actually committed when the program touches them, as it uses more stack space. 

When the program touches a page other than the guard page, i.e. the 4096 byes just below the last used page, the system will make the program trap: stack pages are supposed to be touched just one after the other. 

Why is this so?

I can only guess of course, but from the system builder’s standpoint, it is better to trap immediately, than trying to allocate several dozens of megabytes when there is an error in user software. The penalty being incurred too, is not very high: a function call, and a couple of memory reads, that’s about all.

The mechanism for detecting this is simple. Normally, only the first page (the first 4096 locations) of that space is committed. The next page is the ‘guard page’. Whenever the program touches it, the system will commit it, and reserve a new stack guard page. When the stack grows by more than 4096 locations in a single jump however, this mechanism would fail. The system detects this, and this explains the fault.

To correct this problem, I modified the code in ‘function’ (file win32.c) to test if the framesize is bigger than 4096. If it is, it will generate the following instructions:
	mov	$size,%eax
	call	__stackprobe
where ‘$size’ is the size of the stackframe.

The function __stackprobe is a complicated one, and there is no possible equivalent for it in the C language. Here it is:

__stackprobe:				; argument: stacksize in eax
        pop     %ecx		; pops return address
_$loop:					; for each page we touch a memory
        sub     $4096,%esp	; location with (%esp)
        sub     $4096,%eax
        test    (%esp),%eax	; access a memory location in the
        cmp     $4096,%eax	; page
        jae     _$loop
        sub     %eax,%esp	; do final stack adjustment
        test    (%esp),%eax	; touch the last page
        jmp     %ecx		; jmp to address popped above

The first instruction pops the return address pushed by the call instruction that called this procedure, saving it in ecx for later use. Then, I subtract 4096 from the stack pointer and from the argument in eax. This done, I just access a memory location pointed by esp with a test instruction, that doesn’t use any register. Here a trap occurs, the OS reserves a new stack page, and returns control to me.

Well, there is only to test if more whole pages are needed. If yes I loop, if not, I subtract the remainder in eax from the stack, do a final memory access and jump to the return address in ecx. This procedure takes only 29 bytes of code.
The windows.h and the other header files
A big problem was the header files. Those files make more than 4MB in modern Win32 compilers, and they are absolutely needed for a compiler system that should run under windows.

I had luck however, since the Free Software Foundation (GNU) started porting their compiler system ‘gcc’ to windows too, and they proposed to Scott Christley, of the net community to rewrite the windows header files. I downloaded with excitement the header files, and continued the work of Scott. I added several files, and above all tried to compress the headers as much as possible.

I have worked in those header files for years, updating them, keeping them current with the newest release of the SDK I could get, and they have now nothing to do with the original files of Scott, that haven’t changed for years, keeping all the bugs I corrected. 

But let’s come back to the header files.

I am convinced that the compilation process now is absolutely I/O bound. With the powerful CPUs around, the disk time access overweighs any other considerations. So, I thought, the best would be that the header files would be as small as possible.

Normally you do not think about it when you write your header files. You write comments into them, and size considerations are far from your mind. And this is good, and should be so. The problem is, that in very big files, this adds up to a very significant portion of the compilations time, since the compiler has to parse that comment over and over again, at each compilation in fact.

I took the following approach when rewriting the headers of Scott:
Eliminate all comments
Eliminate all white space and leave only what is absolutely necessary
Eliminate all redundant identifiers in function calls: for instance the function

BOOL 
WINAPI 
MyWindowsApi(HWND hwnd,
LPSTR name,
HANDLE handleToProcess);

would become:

BOOL WINAPI MyWindowsApi(HWND,LPSTR,HANDLE);

This makes for a significant amount of space savings. It is true that many of the names are useful for giving you an idea of what that function does, but let’s face it: lcc-win32 has no replacement for the documentation of the Win32 system, that you should get elsewhere. Besides I think it would be very risky of deducing what the function does and what its parameters are just by looking at the documentation of it in ... a function prototype!

Every effort was done to reduce the size of windows.h to its actual size, about 430K. This compares significantly better to the 4MB the compiler has to read when compiling with the header files of MSVC, and is smaller even than the characters read when you define the keyword WIN32_LEAN_AND_MEAN, that somehow reduces the size of the headers.

But the space savings, and the consequent acceleration of I/O to/from disk (the machine has less bytes to read), is only one side of the problem. Other, significant savings are in the parsing and storing of all those unnecessary identifiers. A declaration like:

BOOL WINAPI MyWindowsApi(HWND,LPSTR,HANDLE);

adds to the compiler’s symbol table only one identifier, instead of four. This means that the compiler doesn’t have to search for the other three identifiers, and when it doesn’t found them, it doesn’t have to add them to the table. This has as a consequence that searches for a given identifier will be faster, since the symbol table is smaller, that less RAM will be used for storing all those ids, hence less paging, etc.

This makes lcc a fast compiler, even if it doesn’t support the precompiled header files option.

I tried to follow somehow the structure of MSVC, but really, there is no close correspondence here. Just include <windows.h> and any special files you need. Most of them like the property sheets definitions etc are included in Windows.h, so there aren’t a lot of files to include at each compilation. It is true that this contradicts somehow the objective of small size above but the problem is that re-creating that file structure would be too complicated now. Frankly I do not have the energy to do it.

The list of all lcc-win32 header files can be found in the user’s manual.

The header files were reduced to their minimum size, but nevertheless, they make for more than 3MB of code.
The import directive
The objective C preprocessor introduced the #import directive. The purpose of this is only to include a file if the preprocessor hasn’t seen it already. I introduced this into lcc’s preprocessor to easy the development, since there is no need to enclose every header file you write with the usual construct for avoiding multiple inclusion of a file:

#ifndef __SOME_SYMBOL
#define __SOME_SYMBOL
....
#endif

This was discussed in length in the lcc-discussion list. It was an involved discussion, and here I will summarize only the best parts of it:

Nelson wrote:

From: "Nelson H. F. Beebe" <beebe@math.utah.edu>
Date: Sat, 2 May 1998 11:37:20 -0600 (MDT)
Subject: #import and #include

The discussion today on #import and #include mentioned that multiple inclusion by #include could be prevented by a "#pragma once".  A better idea, widely implemented in vendor header files, and GNUware header files, is for
        #include <foobar.h>
to include a file which is wrapped with
#if !defined(_FOOBAR_H)
#define _FOOBAR_H
...old contents...
#endif
This requires no addition of #import to the language, and no use of #pragma support.  The big problem with #pragmas is that their contents are implementation dependent, and there is no guarantee that a #pragma from one system will not cause a fatal compilation error on another system, or else be misinterpreted.  Thus, #pragma is effectively useless in portable C code.  Its only justifiable application is inside system header files that will never be seen by any compilers
from outside that implementation.

The sole advantage of #import over the above #include and check of _FOOBAR_H is that a file open and read is not required.  While file openings used to cost me US$0.50 each on an IBM mainframe, they are a lot cheaper today, so most people don't worry much about them.  Large C programs already require lots of header files anyway, so avoiding a small number of file openings by use of #import instead of #include is of little significance, and likely not enough to justify introduction of a new statement into the preprocessor language.

The only vendor that I've encountered who uses #import is NeXT; they are also the only UNIX vendor that I know of which has shipped an Objective-C compiler (a gcc 1.xx derivative).  I find no use of them in DEC, HP, IBM, SGI, or Sun header files.

I answered:

From: jacob@jacob.remcomp.fr (Jacob Navia)
Date: Sat, 2 May 1998 22:39:25 +0200 (MET DST)
Subject: Re: #import and #include
I do not see it as a better idea Nelson, I have to disagree here. The problem is i/o, as you yourself say later in your message. At the beginning of all windows header files there is a construct like the one you propose. Microsoft has adopted this, since it didn't have #import. So the machine reads:
#ifndef __LCC_WINDOWS_H
#define __LCC_WINDOWS_H
(more than 450K of stuff...)
#endif
All 450K+ are going to be read searching for the #endif... what a waste. And this can happen several times in the same compilation unit!!!

Rinie Kervel, noticed the following:
From: Rinie Kervel <rinie@xs4all.nl>
Date: Sun, 03 May 1998 11:09:21 +0200
Subject: Re: #import and #include
[snip] ...from the GNU C Preprocessor manual (Version  2 1990):
The GNU preprocessor is handled to notice when a header file uses this particular construct and handle it efficiently. If a header file is contained entirely in a '#ifdef' conditional, then it records that fact. If a subsequent '#include' specifies the same file and the macro in the '#ifdef' is already defined, then the file is entirely skipped, without even reading it.
I remembered this paragraph because it indicated once more that there might be smarter ways of solving a problem than adding non standard features. (Although for objective C #import is a standard feature).
He also states that #import is not a well designed feature.
To quote again: It requires the users of a header file - the application programmers - to know that a certain header file should only be included once. It is much better for the header files
implementers to write the file so that users don't need to know this. Using '#ifndef' accomplishes this goal.
To me this seems easy to implement in the preprocessor: tag with an include file, the #ifndef macro and determine in the #include processing that its already defined.

Rinie

So, I discovered that the GNU C preprocessor optimizes this away. But let’s get the facts straight: When should the compiler read a file again in the same compilation unit?

The only reason somebody would want that, is that after reading it for the first time, some symbols are #undefined and/or redefined again with new values, so that the inclusion of the same source file will generate different definitions / code, because it contains conditional preprocessor directives that make the compiler take another path. This would look like:

file weird.h
#ifdef SECONDTIME
#define FOO 67
#else
#define FOO 4387
#endif
...


Then in weird.c you write
#include « weird.h »
#define SECONDTIME
#include « weird.h »

But this makes the file « weird.h » unreadable. You would have to find out in the #ifdef #ifndef conditional jungle what was being actually passed to the compiler proper. That file can be only read by using the preprocessor! This is a really horrible programming practice.

So, in my opinion, there is no need to make the compiler ever read again a file. This is actually a consequence of a design mistake of the C language: the compiler should always read an include file once period. This would make hacks like the above impossible, and would accelerate the preprocessing of C files. 

But instead of going to the root of the problem, people have devised the #ifndef ... #define ... #endif patch, so that they could write includes that are processed only once. And then, to put the final ironic note into that bad design, Gnu’s preprocessor will optimize that construct so that you can write that kind of hacks in C very efficiently... This is absurd, in my opinion.

Besides, as Nelson that investigated this a little bit further, noted, that optimization has bugs in it:
From: "Nelson H. F. Beebe" <beebe@math.utah.edu>
Date: Mon, 4 May 1998 08:55:36 -0600 (MDT)
Subject: GNU C preprocessor and avoidance of redundant #include
[snip]
I also found that if one uses the equivalent, but slightly different, code,
#if !defined(FILE_FOO_SEEN)
#define FILE_FOO_SEEN
THE ENTIRE FILE
#endif /* FILE_FOO_SEEN */
then gcc WILL INCLUDE the file at each #include, instead of suppressing the redundant includes.

Even if I have implemented the #import directive, I decided after the discussion not to put it in the standard header files of lcc-win32. For the time being the issue rested like that.

For a complete list of all the include files see the manual.

The #ident discussion
Wedit’s IDE uses following construct to identify which source files contributed to building which executable:
static char _cmsid []  = ...

Follows an identification string. This will be compiled into the object file, and then linked in the resulting executable, together with similar strings from other modules.

The problem with this approach was that the compiler always emitted a warning at the end, telling me that _cmsid is not used... Annoying. So, when a user asked me why I didn’t implement the #ident preprocessor directive, I was happy to jump into it, and implement it.

But later on, and prompted by a reflection of Norman Ramsey, I started investigating what other compilers would do with #ident, and the results were surprising: there seemed to be absolutely no consensus as to what this directive would do. So I sent a message to the lcc discussion group asking for help.

From jacob Wed Jul 29 08:44:47 1998
Subject: reconsidering #ident
To: lcc@cs.virginia.edu 

After I implemented #ident, and following a conversation with Norman Ramsey,I decided to investigate a little more this question.
I implemented what I considered was the semantics of #ident: put a sequence of bytes in the data segment, so that the executable or the object file can be identified by a corresponding utility.
What I do, is to generate an anonymous data space with the characters contained in the argument string:
I.e.

#ident  "0123456789"

will make lcc generate a label followed by those bytes in the .data section.

But then, I started observing what other compilers do with it, to make sure that I did things right. The results were startling:

MSVC will accept #ident, but will generate a .comment section  to be read by the linker, instead of a data item like I did.
Microsoft's linker doesn't include those bytes in the executable, so the identification is for the object file only. cl's output looks like this:
section 00 (.drectve)  size: 00061  file offs: 00060
00000000: 2D 3F 63 6F 6D 6D 65 6E  74 3A 22 30 31 32 33 34 -comment:"01234
00000016: 35 36 37 38 39 22 20 2D  64 65 66 61 75 6C 74 6C 56789" -defaultl
00000032: 69 62 3A 4C 49 42 43 20  2D 64 65 66 61 75 6C 74 ib:LIBC -default
00000048: 6C 69 62 3A 4F 4C 44 4E  41 4D 45 53 20          lib:OLDNAMES

gcc under Unix, compiles into nothing. The following file:
#ident "0123456789"
will compile into a completely empty file (without any strings in it). No warnings will be issued. The directive is accepted but ignored. (Linux red hat, gcc version 2.7.2.1)

Intel's compiler icl will compile this into a linker Comment, as Microsoft, but with a different format:
section 00 (.comment)  size: 00070  file offs: 00300
00000000: 49 6E 74 65 6C 20 43 20  43 6F 6D 70 69 6C 65 72 Intel C Compiler
00000016: 20 56 65 72 73 69 6F 6E  20 32 2E 34 20 50 39 37  Version 2.4 P97
00000032: 31 37 36 20 2D 44 5F 4D  53 43 5F 56 45 52 3D 31 176 -D_MSC_VER=1
00000048: 30 31 30 20 2D 4D 44 20  2D 63 20 30 31 32 33 34 010 -MD -c 01234
00000064: 35 36 37 38 39 20                                56789

Borland C for windows 3.1 (the only version of borland I have) rejects the #ident statement emitting an error message, as lcc did before.
Conclusion:
I am considering dropping support for #ident actually. This directive seems to be portable what syntax is concerned, but each compiler does a different thing. Emitting a warning would be, in this case, a better alternative to giving the user a false sense of security.
What do you think?

As always, Nelson Beebe answered with a full investigation of #ident in many compilers. His investigation is probably the most exhaustive comparison about #ident done to date. He searched the output of  123 compilers!
From: "Nelson H. F. Beebe" <beebe@math.utah.edu>
To: jacob@jacob.remcomp.fr (Jacob Navia)
Cc: beebe@math.utah.edu
Subject: Results for #ident on many UNIX systems

I made this test file:

% cat i.c
#ident "0123456789"
void foo(){}

and then tested it on 133 UNIX compilers on various systems; only 15 of them put the ident string in the .o file.

The Makefile says

all:
        $(CC) -c i.c
        @strings i.o | grep 0123456789

Here is the typescript of the test runs:

[snip... it would fill this book!]

So, I sent the following message to the lcc discussion group:

From jacob Thu Jul 30 19:19:10 1998
Subject: conclusion
To: lcc@cs.virginia.edu

As Nelson Beebe noted, only a few of the compilers tested did the same as I did, regarding #ident.
That report makes an interesting reading though. Here we have a compiler that emits assembler instructions that its own assembler doesn't understand...
/usr/local/bin/g++  -c i.c
/usr/tmp/cc001011.s:1:Unknown pseudo-op: .ident
/usr/tmp/cc001011.s:1:Rest of line ignored.1st junk character valued 34 (").
The "junk" is the assembler pseudo op .ident. Since my red hat linux has those instructions too, seems that the Next's assembler has a problem... Well, I shouldn't laugh too loud: I had a similar bug a year ago...

To conclude, I will drop #ident, and for the people that want the same functionality you can always do
static char *rcsid = "something";
The IDE of lcc-win32 does this since a few years when you choose the 'identify file', in the 'Search' menu. The only problem (that has no solution as far as I see) is the warning at the end:
warning: static char rcsid is never used
It was this problem that made me accept a user's complaint about my missing #ident support. But I see that the problem is not at all solved. Let's stick to ANSI C.

Other fine points in the preprocessor
The standard defines several macros like __DATE__ or __TIME__, that should be set by the preprocessor to character strings. But as always in language issues, things become complex when you consider the following code :
#if defined(__DATE__)
	...
#endif

Are those symbols really defined or not ? As I found it, the preprocessor did not consider those symbols as defined. A careful reading of the standard however, tells a different story :

6.10.8 Predefined macro names22
1 The following macro names shall be defined by the implementation:
__LINE__ The presumed line number (within the current source file) of the current source line (a decimal constant).
__FILE__ The presumed name of the current source file (a character string literal).
__DATE__ The date of translation of the source file: a character string literal of the form "Mmm dd yyyy", where the names of the months are the same as those generated by the asctime function, and the first character of dd is a space character if the value is less than 10. If the date of translation is not available, an implementation-defined valid date shall be supplied.
__TIME__ The time of translation of the source file: a character string literal of the form "hh:mm:ss" as in the time generated by the asctime function. If the time of translation is not available, an implementation-defined valid time shall be supplied.
2 The values of the predefined macros (except for _ _LINE_ _ and _ _FILE_ _) remain constant throughout the translation unit.
3 None of these macro names, nor the identifier defined, shall be the subject of a #define or a #undef preprocessing directive. Any other predefined macro names shall begin with a leading underscore followed by an uppercase letter or a second underscore.

I presume that the rationale for not defining those names was that if they can’t be #defined or #undefined, they are not really #defines... In any case I decided that they should be defined in lcc-win32, so the above construct 
#if defined(__DATE__)
should evaluate to TRUE.

In the same vein, I implemented the __func__ pseudo-macro that evaluates to the name of the current function, if any. Its definition in the formal language of ANSI looks like :
6.4.2.2 Predefined identifiers23
Semantics
1 The identifier __func__ shall be implicitly declared by the translator as if, immediately following the opening brace of each function definition, the declaration 
static const char __func__[]="function-name";
appeared, where function-name is the name of the lexically-enclosing function.
2 This name is encoded as if the implicit declaration had been written in the source character set and then translated into the execution character set as indicated in translation phase 5.

The last point sent me in a long reflection about its meaning... and then I decided that the execution character set is the same as the source character set, and left the whole at that : I did not translate anything from the name of the function, so, if the function name symbol was accepted by the parser, it will appear without any translation in the output.
Another issue is to know what do I do when you attempt to use that identifier outside a function scope. I just decided to return the string « <none> », and emit a warning. The standard is silent about this, and anyway, since this identifier begins with an underscore, it belongs to reserved name space of the compiler., so you shouldn’t use it.

I added several options to the pre-processor. Specifically, the ‘M’ option, that will print in the standard output the names of the included files. This wasn’t specially difficult to do, just look at the function doinclude() in ncpp.c and you will find the printf that outputs the opened file. A more detailed output can be obtained with the option ‘M1’, that will input all files and the stack trace of the preprocessor. This has proved very useful for debugging the complex includes of the ole automation headers, for instance.
Generating the debugging information
Lcc generates debug information that follows the NB09 standard as defined by Intel and Microsoft in their document about debugging information. This means that the debugging info is compatible with the MSVC debugger that should work better than lcc’s one for a certain time still.

This information will be generated in the file CV.C in the source tree of lcc.

An innovation in lcc-win32, is that I decided to include within the debug information all the #defines that are actually used somewhere in the program. This allows the debugger to give the value of any #define, what can really help when you have statements like:

		strcmp(buf,PATH_TOSEARCH);

for example. Now the debugger can show you what is behind that name.
Since the only use of that debug information is to display a value, I decided to store all ‘defines’ as character strings, so no type information is available. The type information is absent in the source anyway. When you say:
#define NUMBER 8

Is this a char? An integer? A short?
The choice would be arbitrary anyway, so I think is better to leave things as characters?

The debug information is stored in a special area, and accumulated during the compilation  process. Once the compiler is finished, the assembler will output two sections: .debug$S with the symbols information, and a .debug$T with the types defined in the module. More on this later on.

Generating the browsing information
Using the browsegen utility or using the -x command line option in the compiler, generates cross referencing information in .xrf files. These files contain information about all the symbols used by the compilation unit. The name of the .xrf file is derived from the input file, i.e. if you compile foo.c, the .xrf file is named foo.xrf.

The browsegen utility is a modified version of the compiler for doing just this. It will accept two extra command line parameters that aren’t used in the compiler proper:

Command line option
Meaning
-all
Include in the generated cross-reference file all the symbols defined, even if they are not used in the main file. Normally, browsegen outputs a definition only when that definition is used somewhere else.
-q <symbol name>
Query just one symbol. For example the command line:
Browsegen –q WM_COMMAND windows.h
Will output a short .xrf file containing just the definition of the WM_COMMAND symbol.
If the symbol ends in an asterisk (i.e. WM_*, for instance), browsegen will output the definition of all symbols that start with the three letters “WM_”.


Any tool that desires to gather information about the program can use these files. 

Design considerations
The purpose of the browse subsystem is to find quickly answers to questions like :
Where is this symbol defined ?
Where is this symbol used ?
Where is the field <x> of this structure <z> used ?
Where is the address of this symbol taken ? This is important to find where the aliased symbols are.
The browse subsystem doesn’t encode the actual type of each symbol it registers. Just a very large classification is done, encoded in the first letter of each line, just before the identifier. The main purpose is to associate to each symbol of the program, a coordinate with file, line, that allows the browser program or the editor, to position itself at the place where the definition is.

Within this context, it is important to see that the coordonates of a symbol (where it is defined) 
aren’t necessarily within a single line. A typedef can span several pages of program text sometimes. In those cases, it is necessary to give two coordinates to each symbol. Normally however, most definitions need only a source file and a source line, to correctly position the cursor of an editor in the place where the user can read it.

Only symbols that are actually used are included. It is surely not necessary to repeat all the definitions of windows.h within the browse database, that should be kept as small as possible for efficient access. An exception to this rule are the type definitions defined within the main compilation file. Even if those definitions aren’t used anywhere in the program, it is better to add them to the browse index. This poses the problem of name clashes. Suppose  that in a file1.c we define an enumeration with the same name that another structure in file2.c. This is legal C, but it is not handled in the current version. Anyway, this is a horrible programming practice, if done purposedly. But it could be that an accidental name clash appears. The browse linker should warn the user if this happens. This is another thing that is currently in the agenda.

To make the task of the editor easier, subtypes are carried on, for instance when you define :

typedef struct _someTag {
	int a ;
	int b ;
} STRUCT ;

a declaration like :

STRUCT s ;

Will provoke that the browse generator will mark s as being a _someTag, but will mark the STRUCT name at the end of the line, indicating the type definition.
Another problem happens with the defines of the preprocessor. They can be used in the header files, without ever being used by the main program. Currently I add them anyway, but it would be better probably to add them only if they are used in the main file.

The generator ignores all local variable declaration, considering that they are not relevant. The editor (wedit) is able to find the local variables of any function, and show their definitions, but it doesn’t rely on the browse information.
The system uses heavily ASCII plain text files. Each record is generated in a line, separated by the newline characters. This makes sometimes for quite big files, but during this development phae, where the format, and the kind of information that is written is bound to change somewhat, it is better to be able to use a plain text editor to see the output. Other people that would like to use this files will surely find easier to parse a text file than to read a binary description.

Of course, to keep the size of the generated files small,  the information is written using more or less meaningless one letter acronyms. This makes the paring much simpler, even if the generated files look quite ugly to anyone that would care to read it.
Browse file format
Each symbol used/defined in the compilation unit is in a line by itself. The files are in plain text (ASCII). I thought for a while of using a binary, more space-efficient format, but this would put this information out of the reach of others, that could surely use it as well as Wedit does. So, I decided to stay in ASCII.

The file begins with a file table, listing the names of all files opened during the scan. The files are introduced with the letter ‘F’ (main file) or ‘f’ (included file).

The format of each line is as follows:

Field
Meaning
Type
A single letter giving the type of symbol. The letters are explained below
Name
The symbol name
Position
Two numbers, giving the index in the file table for the file, and the line number within that file.


The first letter in the line determines the type of information that follows:

Letter
Meaning
A
Assignments done to this symbol
B
Assignment to a structure field. The name of the field follows
C
Loci where the address of this symbol is taken
E
Exported data symbol This is followed by the name of the export, and the line number in the input file where the export is defined
e
Exported function Same format as ‘E’ above
F
File. A path for the input file follows
f
File A path for an include file follows
I
Loci where this symbols is dereferenced and its value used as pointer
M
Externally defined function. Usually the loci of the prototype.
P
Parameter passed to browsegen in the command line
R
References done to this symbol
S
Static Same format as ‘E’ above.
s
Static function. Same format as ‘S’ above
T
Typedef. File number, line number, start of definition line number. At the end can follow the type this typedef refers to.
t
Structure The name of the type, the index of the file that defines it, and the line number within that file where the definition ends, followed by the line number where the definition starts
@
Member of a structure or union. Name of the member follows.
#
Preprocessor definition. Followed by the name, the file index of its definition file, and the line number within that file

The files generated are relatively small. For an input file of 229,826 bytes for instance, the generated .xrf file makes only  23,447 bytes.

Linking the browsing information.
For each source file then, the compiler generates a corresponding .xrf file, containing the location of the definitions of all source files. It is necessary then, to consolidate this information in a central index that will contain the dictionary of the whole program. A small utility does this called ‘browselink’.

This utility reads all .xrf files, and generates a browse.index file, containing the definition loci for all symbols. External symbols are discarded, and only one definition of a symbol is retained. All locations in the .xrf file are relative to the table of that file. The linker translates this to locations in a single global file table.

The format of that file is as follows:
First comes the file table. The format of each line is just as above, the letter ‘f’, followed by a space, and then the name of the file. All references to files of the identifiers below are indexes to this table. The indexes start with 1, i.e. file 3 is the third line of this table.
Then come the identifiers, sorted alphabetically. The general format is as above: a ‘type’ letter, followed by a space, the identifier, then the file number, and then the line number where the definition of the symbol appears.

I was tempted to use a binary representation that would be more compact, but then decided that the advantages and simplicity of a textual representation outweigh the space considerations. You can use a normal text editor (notepad will work) to see this file, and all other text related utilities like «‘grep’ and ‘diff’ will work with those files. This makes easy to write utilities that read this information.

The size of the index is small. For instance, a huge project consisting of more than 15MB of C source produces an index file of only 213K.

The name of the index defaults to browse.index, and is stored together with the object files in the lcc make directory.

Browsegen and the preprocessor
The utility can be used to show information about the preprocessor. The option
–showifdeflines
will make the utility print in standard output all the line numbers of the lines in the source file that do NOT contribute to the compilation, i.e. is a list of inactive lines.
This option can be combined with the /Fo option, to produce that list in a file that can be further processed. With the command :
	browsegen –showifdeflines /Foinactive.txt myfile.c
you will obtain a list of inactive lines in the file called inactive.txt.
The long long extension
The long long extension makes for several dozen rules in win32.md. All instructions are implemented as several assembly instructions, since they do not exist natively in the x86 series.

I defined first a mem64 target that represents all 64 bit memory references.

mem64: INDIRL(addr) "%0"
mem64: INDIRL(ADDRGP) "%0"

Another new target is the EAX:EDX register pair. This holds a 64 bit quantity in those registers:

rpair: mem64 
		movl	%0,%eax		(1)
		leal	%0,%edx		(2)
		movl	4(%%edx),%edx	(3)

Note that I use the edx register as a pointer. First, I load the lower 32 bits into EAX, then use EDX as a pointer to the upper 32 bits. This is not very efficient, especially when the 64 bit memory being accessed is in the local stack frame. But I found very difficult to express an address addition within the framework of the intermediate language, so I used this.

Then I implemented assignment:

stmt:ASGNL(mem64,rpair) 	
	movl	%eax,%0
	leal	%0,%eax
	movl	%edx,4(%eax)
This will assign to a mem64 operand, the values contained in the EAX:EDX register pair. The same technique as above is used, this time with EAX as a pointer.

I needed somehow to store temporaries in memory. The x86 with its 6 available registers could hold only two of those numbers anyway, because we have to leave some registers free so that the machine can perform useful work. This led me to the need to represent a stack allocated intermediate as a « argl » goal.

argl:mem64 	
	leal		%0,%eax
	pushl	4(%%eax)
	pushl	(%%eax)

This leaves in the stack the contents of the 64 bit memory location.

Obviously, it is fundamental that nothing is left in the stack. All rules that left their results in the stack are followed by other rules that take a stack location, eventually generating an assignment or a function result.

Using those primitives, I implemented the rest of the operations. Here is an example for  addition:

rpair:ADDL(mem64,rpair) 			(1)
	leal		%0,%ecx			(2)
	addl		(%ecx),%eax		(3)
	adc		4(%ecx),%edx		(4)
This instruction results in a rpair, i.e. the EAX:EDX register pair (1). It takes a mem64 and a register pair, and adds it the contents of the memory location. It uses ECX as a pointer to the memory operand (2), and then performs two 32 bit additions (3) and (4).

Not all operations have been implemented in line as this example. Division and multiplication are too complicated to inline, because their length. The rules for those operations generate a function call.

The cost of a function call (1 cycle if the procedure is in the cache) doesn’t justify the code bloat that would be the consequence of inlining all those operations.
Here is one of the rules for multiplication:

rpair:MULL(mem64,mem64) 
	leal		%0,%eax	(1)
	pushl	4(%%eax)
	pushl	(%%eax)
	leal		%1,%%eax	(2)
	pushl	4(%%eax)
	pushl	(%%eax)
	.extern	__allmul	(3)
	call		__allmul
This rule is straightforward: using EAX as a pointer, I push the first argument to the rule (1), then using the same register I push the second argument (2), then I make the call. No stack cleanup is needed because __allmul will cleanup the stack when exiting (this is the _stdcall calling convention).

Implementing run time debugging support: the shadow stack.
The motivation for this was that terrible ‘dialog box’ with the registers dump that appeared every time an application that was compiled with lcc crashed. It was completely meaningless, displaying to the user an impressing display of hexadecimal numbers, containing the values in all registers.

I decided that a better display would really help people find out where the bugs in their programs were. So I decided to maintain in a fixed point in the stack, an internal program counter that would hold always the current source line. In the same way, each function would hold in its stack frame, an ASCII string with the name of the source module that was used to compile, and the function name.

I modified the compiler then, augmenting the debug levels from -g2 to -g3 and -g4. The two new levels would:
In level -g3, the function stack would be available, but not the source line. This mode is really fast, almost as fast as normal code.
In level g4, the compiler generates code to maintain at all times a pointer to the currently executing source line. This can reduce the speed of the program at most by a factor of two.

The implementation uses a proposition described in an article of Dave Hanson that was kind enough to point me to it.

I maintain a shadow stack, using only one global variable, called just ShadowStack, to make things clear. Actually, that variable contains the last value of the register EBP, the frame pointer.

The function prologue is modified to record the function that is currently active, building the following structure in the stack:

struct ShadowStackList {
	char *ModuleName;
	int CurrentCoordinate;
	char *FunctionName;
};

The members are:
The name of the module where the function is defined. This points to an automatically generated character string.
The current coordinate. This is a 4-byte integer that contains in the upper 16 bits the coordinate of the starting line of the function within the module, and in the lower 16 bits the line number of the current executing line.
The name of the function. This is an automatically generated character string.

At each line, the compiler generates code to update the current line number in this structure. This is the equivalent of what would happen if at each line of your program you would write:

	dosomething();LOWORD(ShadowStack.CurrentCoordinate) = 365;

At each function call, the compiler generates code to restore the shadow stack to the current value after the call.

The entry point of the main() function (or the WinMain() function for windows programs) is augmented with code that assigns the exception handling code using the signal() system function.

When a trap occurs, the code in the startup detects it, and calls the _lccShadowStack() function, that walks the stack frames showing all the functions that are in the stack at the moment of the fault.

This is all very good if the stack is not corrupted of course. To make a recovery possible when there is a problem with the stack, at the level 5 (-g5), the compiler will emit code at the function epilogue to save EBP before doing the actual return. Since EBP is never used in any code  (at least not in any code generated by lcc), and it is saved immediately upon procedure entry, this value should allow the stack walking code to detect this situation, and at least show in which function the stack fault occurs.

Another feature with the –g4 option, is that I test at the function’s epilogue if the stack has been corrupted. I test specifically that the pointer to the function name is still there, so that any stack overwrites get cached earlier.

The generated code for a function’s prologue then, looks like this :
_foo:
        pushl   %ebp
        movl    %esp,%ebp	; establish stack frame
        pushl   $_$Module	; push the name of the file
        pushl   $2359296		; push the starting line number
; shifted left 16 bits (36<<16)
        pushl   $_$Ffoo		; push the function name
        movl    %ebp,__ShadowStack ; save frame pointer
        pushl   %esi		; save registers
        pushl   %edi
        .line   37
        movb    $1,-8(%ebp)	; relative line nr goes into the lower 16 bits of the line
						; number field
At function’s exit, the compiler generates code to check that the pointer to the name of the function is still there. This catches a pointer that overwrites stack values.

        cmpl    $_$Ffoo,-12(%ebp); test if pointer still there
        je      _$G4foo		; if it is, nothing is done
        pushl   $0			; call lccStackTrace
        call    __lccStackTrace
        addl    $4,%esp
_$G4foo:
        popl    %edi		; exit function
        popl    %esi
        leave
        ret
Error handling within lcc-win32
The compiler will stop after a fixed number of errors. In general, error recovery is very simple, and in many cases, a missing ‘ ;’ will throw the compiler in a cascade of errors where only the first ones are relevant.

The production versions of the compiler run without checking any of the assertions specified in the code; i.e. with NDEBUG defined. This will in some cases provoke a trap within the parser, especially in cases where a type is not correctly initialized because of an error. All traps are cached by a global error handler established by the main() function at startup. This trap handler looks first at the contents of the nerrors variable, which keeps the count of the hard errors encountered so far. If this is greater than zero, it is likely that this trap is a direct consequence of previous errors, so the message that is shown to the user is:

	Confused by earlier errors. Goodbye.
And the compiler quits.

If the error count is zero, this is a hard compiler error, and this is acknowledged to the user. The exact wording of the message is :
Compiler error (trap). Stopping compilation.
I think this solution is an efficient and quite appropriate solution for this problem. The code is kept small, avoiding the clutter of many tests for ‘obvious’ things like NULL or bad pointers, and passing those tests directly to the hardware that performs them much faster than software.

The information flow in lcc-win32

All input to the compiler enters the system through the preprocessor, (file ncpp.c). Here the files are opened, and read in, preprocessed, and copied into a buffer that the input.c routines pass to it. The central routine that makes the interface between the pre-processor and the rest of lcc is ReadFromCpp(), that fills the buffer passed to it with preprocessed code.

If the -E option is on, the stream from the preprocessor is not further processed, and goes directly to the .i or other file. No code is generated.

In the normal case, the pre-processed ASCII stream passed then to the lexer, specifically to the gettok() function, that classifies the input into tokens, reads char strings or other constants, etc. The lexer emits a token stream, that is then further processed by many functions in the compiler, that transform that token stream into a series of ‘Trees’. 

Those ‘Trees’ are then passed to the function that emits the intermediate language, i.e. in dag.c the function listnodes(). 

The dags are then reconverted into trees in the technical sense, i.e. in hierarchical structures without any cycles in them. Common sub expression elimination is done when doing this conversion, since a node that is referenced more than once is a common sub expression. Those common sub expressions are recorded and assigned to temporary variables or registers.

When the end of each function arrives, the whole code list is passed to the code generator, which labels the trees, to determine the best rule that will execute the given tree with the minimum cost. The labeler is automatically generated by the utility lburg from the machine description in win32.md, and is located in the source file win32.c.

When the labeling operation is done, the resulting labeled tree list is passed to the register allocator, that determines which registers to use to evaluate each expression. All the machinery of the register allocator, the spiller, is located in gen.c. If the user has specified the -z option to see the intermediate language code, the printing is done at this stage.

After the register allocation is done, the code goes through yet another pass: the emitter, which will generate an ASCII stream of assembler instructions. If optimization is turned on, the stream is redirected to the peephole optimizer, if not, it is directly passed to the assembler.

The assembler is the only module that does any output: the final object file. If the -S option is on, i.e. if the user has specified an assembler output, the stream of ASCII machine instructions will be printed before passing it to the assembler.
The source files of the compiler proper
bind.c. This is used in the context of a cross compiler, a feature not supported by lcc-win32. Only one machine description (the x86 machine description) is available.
profio.c. This is used for the profiler, but the lcc-win32 profiler doesn’t use this file.
prof.c. Same as above.
trace.c.Prints function calls trace information. Not used in lcc-win32.
seh.c. The structured exception handling module. The entry point is the function dotry(), that is called directly from the lexer (in lex.c), when a “ __try “ construction is seen. The whole exception handling stuff works underneath the compiler proper and all constructs are invisible to it, being processed within the lexer.
tree.c. The generation of the tree structures. This is the first intermediate representation, and from this one, the dags are later generated. You will find in this file the tree constructors, and the main function ‘root()’, that dispatches according to the type of expression it sees.
string.c. String handling and storing. The compiler always writes a symbol once. In this file is done the hashing of symbols into the hash table.
alloc.c. Memory management routines.
lex.c. The lexer. The main function is ‘gettok()’, that returns the token scanned. Other quite unrelated functions live here, like the ‘assem()’ function, that parses the arguments of the _asm() construct, or most of the functions that do pragma processing.
expr.c. Expression parsing. You will find here the routines for expr0, expr1, expr2, incr, value, expr3, unary, postfix, primary, idtree, rvalue, lvalue, retype, and others, all dealing with trees.
w32incl.c. The x86 back end. This has two main parts: the automatically generated routines produced by the lburg routines, (in the file win32.c) and the file w32incl.c, that contains the ‘function()’ routine that controls code generation for the whole function .
decl.c. Parsing of declarations. Here is the entry point from the front end, called directly from the ‘main()’ function : program(). Parsing of all declarations is started here, with functions to parse argument lists, functions, etc.
gen.c. The code generator. The main function here is the ‘gen()’ function, that generates the code, invoking the labeler in win32.c. Another important function is the ‘emitasm()’ function, that outputs the assembler mnemonics.
dag.c. The generation of the intermediate representation as Directed Acyclic Graphs (DAGs). This dags will be converted to normal trees by the function ‘visit’, in this same file.
analysis.c. First part of the optimizer. Scans the converted dags looking for certain patterns.  The function ‘SetupRegisterVariables’ decides which variables will be assigned to registers.
cv.c. The generation of the NB09 debug information.
enode.c Emits nodes for certain constructs like call, and others.
error.c Displaying errors and warnings.
event.c. Not used by lcc-win32.
simp.c. Simplifies expressions. The main function here is called simplify. It will try to replace costly operations by cheaper ones, like replacing a division by 4 by a right shift; it will ignore unneeded operations like additions of zero or multiplications by one, and many other transformations. The input data of simplify are the trees generated by the parser, before they come into listnodes, that will build the DAGs out of them.
init.c. Handles initialization of tables, structures, or plain variables.
input.c. Handles reading from the preprocessor.
win32.c. The tree labeler. This file is generated automatically from the machine description by the utility lburg.exe. Please do not edit, since it will regenerated at each modification of the machine description.
intrin.c. Intrinsic and MMX functions. These functions will be detected by the function ‘call’ that lives in enode.c. The processing of the intrinsics is done later, at the register allocation phase, and then in the code-emitting phase, where special functions will be called to actually emit the code for the intrinsic.
list.c. List handling utilities.
asm.c. The assembler. All binary opcode generation is done here, together with the construction of the object file and the debug sections. 
ncpp.c. The preprocessor of lcc-win32, written by Dennis Ritchie.
stmt.c. Parsing of statements. The main function in this file is not surprisingly ‘stmt()’, that coordinates the whole statement parsing, calling ‘ifstmt()’, ‘forstmt()’, and all others.
null.c. Not used by lcc-win32
msg.c. All character strings containing all messages of the compiler. It suffices to translate this file into another language for having a compiler that will speak your native tongue.
optim.c. The peephole optimizer. The entry point of the peephole optimizer is the routine  ‘ChangeBlock()’, that processes a pseudo basic bloc. It calls the ‘FindEndBlock()’ function, that inputs each instruction into its corresponding structure. The structure used to describe an instruction is the ‘Instruction’ structure, defined at the beginning of the file. The peephole optimization proper is done in the function ‘FindStateChanges()’, a huge function making most of the file.
sym.c. Handling of symbols, symbol table, scopes, etc.
main.c. The ‘main()’ function. Parsing of command line arguments and flags settings are done here.
output.c. Output routines, and the ‘print’ function.
types.c. Type definition and related code.
win32.md. The machine description for the x86 back end of lcc. This machine description is used by the lburg utility to output the win32.c file, which implements the code labeler.

Building the compiler
The sources of the compiler are located in \lcc\src\lccsrc. They come with a makefile; so, in principle all you need to do is just type ‘make’.

You need to have the ‘lburg’ utility in your path. Besides, the first time, you should copy into that directory the binary from \lcc\bin. The reason is that the makefile is configured to compile the compiler with itself in a loop, so the makefile uses the lcc.exe residing in its own directory rather than the one in \lcc\bin. This way, when you make a change, you can test whether the changes still allows the compiler to compile itself, without touching the compiler that you know is working.

You may want to configure some of the flags in the makefile:

ASM_LIB This flag decides whether the new compiler will include the assembler accelerator functions contained in libasm.asm or not. Note that you should delete the object file from the list of object files if you do NOT define this option.
NDEBUG This flag decides whether the assertions will be included in the generated code.
-O Optimization flag.
If you have a Pentium II or higher, you should add the –p6 option to the compiler flags.

The makefile comes configured with ASM_LIB, with NDEBUG, and with the assembler accelerators, i.e. a maximum speed setting. You may want to change this when you want to change something.

You can use other compilers to build lcc, if you prefer. You should obviously turn OFF the assembler accelerators, and build a project for the compiler of your choice. Please remember to set the packing structures flag. Normally, there shouldn’t be any dependencies from packing considerations in the code, but you never know. You will experience problems if the other compiler doesn’t support 64 bit integers. In that case please turn off any 64-bit int stuff. Obviously, the compiler so generated will be incomplete. The places to watch are:
lex.c : function readatoi64().
w32incl.c : function defconst().
c.h : The union ‘value’ should be modified to eliminate the 64-bit integer member.



Lcc’s assembler
Overview
The tasks that are done in the assembler file asm.c are mainly the following:
1. Obviously, assembler mnemonics generated by ‘genasm’ are translated into machine codes
2. For each compilation unit, an object file is built using the guidelines specified by Microsoft for the construction of Coff object files.
3. The debugging information generated by cv.c is stored in the debug sections of the object file.
The construction of the assembler was one of the first tasks in lcc-win32. Lcc used for its Dos version Borland’s Turbo assembler and a Dos extender to run on 32 bits. Since I wanted to build a self-contained tool, an assembler was inevitable. There are a few public domain assemblers that I looked upon. 

The first choice was obviously Gnu’s GAS (Gnu Assembler). I started looking at it, trying to see how I could take it away from their ‘BFD’ (Binary File Descriptor) stuff, but I found the task so enormous, that I gave up. It was impossible to see how the assembly process was being done in an enormous mass of bloated code. GAS is ‘machine’ independent. What this means for an assembler, is not at all clear to me. In any case, each functionality of the program is redirected through function tables that dispatch to the right machine dependent section of it.
This is maybe very clever, but if you want to follow the actions of the program... well forget it. You are confronted to
	(* TableOfFunctions[TableOfIndirections].fn)(arg1,arg2);
Then I examined different assemblers in the public domain. The best that I found was the version of ‘emx’ for the OS2 system. It was a small (compared to GAS) program; the source seemed clean and usable. The problem was, obviously, that it generated OMF format files for OS2. This wasn’t so bad. I extracted all the section of the program that generated the 386 machine codes from it, and gave an overall ‘simplification’ pass over it. Actually the only things that rest now from the original program are the tables of machine instructions and the algorithm for parsing instructions. Still, I am indebted to Eberhardt Mattes for publishing his program.

In a patient work that lasted a few months, I added the code needed to handle the fixups instructions for Win32; the code needed to build the object file, and the building of the different sections.
The format of the x86 instructions

The x86 integrated circuit is an interpreter. It reads the instruction stream, decodes each instruction, and interprets it, doing what the numbers tell it to do.
Depending on the instruction, the x86 CPU instructions follow the general instruction format shown in the schema below. These instructions vary in length and can start at any byte address.
An instruction consists of one or more bytes that can include:
Prefix byte(s),
At least one opcode byte(s)
Mod r/m byte
s-i-b byte
Address displacement byte(s)
Immediate data byte(s).
An instruction can be as short as one byte and as long as 15 bytes.24

25
Following this schema, the core of the assembler, the function Asm386Instruction first parses the optional instruction prefix, and the mnemonics for the operation (the opcode field).

If the operation is a repeated string operation (movsb, or any such) there are obviously not any arguments to parse since the arguments (the registers ESI, and EDI for source and destination) are implicit in the instruction. If not, the assembler parses the arguments of the instructions. 

Since I started with the machine code tables of lcc for the linux system, I kept their non-compatible assembler syntax. That syntax was introduced by gcc: instead of putting the destination first, and then the source, as all x86 assemblers do, following a convention introduced by Intel, gcc decided to do the inverse: they write the source first, and then the destination. Since in the linux system, gcc is the (only) compiler, the instruction tables followed gcc’s syntax. I decided not to change this, even if that decision provoked later several problems in the disassembler that the debugger uses, where I try to hide from the user that non-standard syntax.

The parsing of the instruction’s arguments is done in the i386Operand routine. There the different forms for addressing are translated into decorations of the global ‘i’, for the current instruction. Those decorations are used later by the calling function ‘Asm386Instruction’ to emit the instruction bits.

When the (optional) arguments are parsed, Asm386Instruction makes several tests for special situations. One of them is, for instance, the test for the INT 3 instruction that is reserved to break into the debugger. We will see in the debugger chapter why this instruction MUST be of only 1 byte length.

This tests over, it continues with the outputting of the instruction: jumps are written first, followed by the other instructions. I left in the code, the tests for all instructions, even if lcc will never emit them. Those instructions (like lcall or ljmp) could be useful in another context later on for others that would like to build another tool.

Here are some examples for instructions, and the binary code generated for them.

1. Move a memory location into a register

	movl	_Global,%esi		8b 35 00 00 00 00
						8b = 10001011		(139 decimal)
						35 = 00 110 101	(53 decimal)

The opcode for the move instruction is 8b. Then we have the mod/rm byte. This byte contains three fields: the mod field, the reg field and the r/m field.
The mod field is the first two bits of the modr/m byte. In this example they are 00.
The reg field is the next three bits. The have the value 110 (binary) specifying register number 6 : esi. 
The r/m field combines with the mod field to form 32 possible values: 8 registers and 24 addressing modes.  In our example the value is 00 101, i.e. a 32 bits displacement, the offset of our ‘_Global’ within the data segment. If we change the value of the register to edi (i.e. we write 
	movl	_Global,%edi			8b 3d 00 00 00 00

the binary sequence changes only slightly: only the modr/m byte changes.
							3d = 00 111 101
Our mod+r/m field rests the same of course, since we are still accessing the same ‘_Global’, only the register number changes to 7 (111 binary) meaning register edi.

And what about those 4 bytes of zeroes?
Well, here the assembler realizes that this is a memory access to a symbol. The linker will only know the real address. The assembler limits itself to emitting the 4 zeroes as a place holder, and emits a ‘relocation record’ in the object file, i.e. in the today fashionable ‘internet’ way:

FROM: lcc
TO: linker
SUBJECT: Relocation at offset 2645

Dear linker:

Would you mind putting here the effective address of the _Global variable? 
The ‘_Global’ symbol is the 354th in the symbol table. Please do a DIR32NB reloc.

Yours truly
lcc

We will see the format of the relocation instructions below.

Emitting correctly those relocations was one of the tough tasks of building that assembler. An incorrect relocation record would destroy the code somewhere else, because the linker would patch the wrong location! This could make the program crash, or just would be invisible, if the program didn’t access that part of the code...

I will explain the relocation records more fully below. Let’s come back to our instruction encoding chores.

A more sophisticated example is:

	movl		%eax,(%esi,%edi,1)		89 04 3e

This means that the contents of eax will be stored at the table where the base is pointed to by edi, at the index indicated by esi, scaled 1.26

Here we are introduced to the ‘sib’ byte mentioned above.

We have:
					89		opcode
					00 000 100	modr/m byte
					00 111 110	sib byte

In this byte we have three bit fields:
1. The SS field or scale field is the two most significant bits of the byte. In this case is zero, meaning a scale of  2 ^ 0= 1.
2. Then (bits 5 4 and 3) we have the index field (111) meaning register esi for the index.
3. Then we have 110, the base field, meaning the edi register for the base.

To get a detailed description of how each instruction is disassembled you should look in the pedump source tree, specifically the file disasm.c. There you will find the disassembler that is an adaptation of several files from gnu’s as program.  The entry point of the disassembler is called  ‘DoDisassemble’, and outputs the disassembled instruction into a buffer.
Fragments
Since the assembler makes only one pass over its input, we are confronted with the problem that the exact size of some instructions is not known. For instance when it sees:
	jmp	_$L2
	.
	.
	.
_$L2:

The position of the ‘_$L2’ label is not known. Now, we do not know if we can generate a jmp instruction with a byte displacement or with a 4 byte displacement, until we find the _$L2 label. We could solve this by just generating always a 4-byte displacement with it, but this would be really wasteful of RAM. The solution Eberhard Mattes had in its program is to use a ‘Fragment’ data structure that can grow if needed. I maintained that of course, even if the code is very difficult to follow due to a ‘macrology’ a bit confusing.

The format of object files

Object files contain not only code bytes. They contain the initialized data of the module, the size of the non-initialized data (bss), information for debugger, and maybe some other stuff. This has to be organized in a standard way so that utilities are interoperable. 

In a radical departure from the Windows 3.1 days, Microsoft decides to follow the already existing COFF standard. Before Win32, Microsoft used the OMF (Object Module Format) file format that was developed by them and IBM for the MS-DOS system. IBM stayed within the OMF format for OS2, and extended it for accommodating larger fields since OS2 is a 32 bit OS too. Microsoft decided otherwise, and introduced for their new system the Unix COFF standard. Actually, this is not a forced decision. In the first versions of the Borland compilers, the object format produced was still OMF, and only the linker was changed to produce a COFF executable.

Since I hadn’t written the linker anyway, I needed, to test my code, a linker so I hadn’t any choice but to use COFF from the start.

Object files, within the Coff27 system, have the following structure:

1. A ‘section’ header, indicating where in the file is stored each section, its length and other stuff like its characteristics.
2. The different sections generated by lcc-win32 are:
The .text section that doesn’t contain any text as you would suspect, but contains the machine codes for the compilation unit that is stored in this object file.
A .data section containing the initialized data for the file. In this section go all the statements like:
int startingPos = 45987;
A .bss section, containing the non-initialized data. In this section go statements like
int Table[645];
A .debug section containing the debugging information
Other special sections
3. A Symbol Table, describing the symbols contained in the compilation unit.
1. The contents of the different sections.

To look at all the details of the sections in object files look at the pedump sources in the file ‘common.c’.

Relocations

Each section can have ‘relocations’ instructions. This instruction appears only in object files. They specify how the section data should be modified when placed in the image file and subsequently loaded into memory. They are fixed-length records and each element of the array has the following format:

Position and size
Meaning
0, 4 bytes
The address of the item to which the relocation should be applied. This is an offset from the beginning of the section, plus the starting address of the section. 
4, 4 bytes
The index in the symbol table of the object file that refers to the symbol that is being relocated. In our example the symbol ‘MyTable’
8 2
The type of relocation being performed. There are several relocation types possible. I describe later which ones lcc-win32 uses.

Basically, the linker should build the executable from the different modules. When it does this, it will mix all the .text sections in a single .text section in the executable file. This would be impossible, if all references to offsets weren’t described in each object file in a relative fashion.
For each symbolic reference that ‘genasm’ emits the assembler generates the code for the instruction and leaves a zero in the object file. This position is recorded by the assembler for building the relocations at the end of each object file.

We have then records of this type:

Offset
Symbol table index
Type of relocation
2978
576
7

The offset is the start of the instruction plus the start of the address part of the instruction, 2 bytes further up than the start of the instruction itself.
There is nothing special with the symbol table index. It is just what it name says: an index. The type of relocation in this case is 7, i.e. a direct 32-bit relocation relative to the base of the section.

Other type of relocation arises when there is an instruction like:
	Mnemonic			Code
	call _strcpy		e8 00 00 00 00

The address of the ‘strcpy’ function is not known at assembly time. It will be known to the linker only. The assembler just generates the code and the following relocation instruction:

Offset
Symbol table index
Type of relocation
4987
The offset of the first zero within this section
978
Where in the symbol table is the _strcpy symbol
16
PC relative relocation

All calls instruction generated by lcc are program counter relative offsets. This relocation instructs the linker to calculate how far away is the ‘strcpy’ function from that position in the section, and put that difference into the 4 bytes filled in with zeroes.

An optimization here is obviously possible: When the function being called is in the same module, the offset to that function is fully known to the assembler, and we can just put it in there and erase any relocation instructions, since both addresses are known.28

The symbol table
Each object file has a symbol table specifying the names and addresses of the symbols in it.
The structure of a symbol is defined as follows:29

typedef struct _IMAGE_SYMBOL {
    union {
        BYTE    ShortName[8];
        struct {
            DWORD   Short;     // if 0, use LongName
            DWORD   Long;      // offset into string table
        } Name;
        DWORD   LongName[2];    // PBYTE [2]
    } N;
    DWORD   Value;
    SHORT   SectionNumber;
    WORD    Type;
    BYTE    StorageClass;
    BYTE    NumberOfAuxSymbols;
} IMAGE_SYMBOL;

Symbol names can be up to 8 characters long. If they are equal or shorter, the union member ‘ShortName’ will be used, if not, the member ‘LongName’ contains the index of the name in the string table.
The value corresponds in an object file to the address of this symbol relative to the beginning of the file. In an executable, it corresponds to the addresss when loaded.
The section number indicates which section this symbol belongs to. For instance one would be the text section, etc. The numbers aren’t fixed, but are actually indices into the section table.
The type field describes the type of the symbol. Lcc-win32 doesn’t generate this kind of information because it generates already debug type information in the .debug section. 
The storage class field can contain many other properties for the symbol, but lcc-win32 uses only the following ones :

1. EXTERNAL (2). This symbol has public scope.
2. STATIC (3)	This symbol has local scope.
3. FILE (103)	This is a file name type of information.
4. LABEL (6)	This is a code label.

The code that generates the symbol table is located in asm.c.
Pseudo instructions
The assembler receives directives from the compiler for reserving space (.space directive) for changing the current section or other chores: setting the name of the current file, building initialized data tables (.long or .byte instructions) This instructions are fairly straightforward, and they present no special difficulty.

Further work
The assembler uses up more than 13-15% of the total compilation time with no optimizations. This could be greatly reduced if lburg generated a table of opcodes instead of just ASCII mnemonics.

Another big problem is the assembler syntax, inherited from the machine description for the LINUX system. It is utterly incompatible with all other assembler syntax, and it should be eliminated, in my opinion. But rewriting the assembler’s parser is a work that would eat me months of development...

The debug section
If your compiler system foresees any use of a debugger, (and I wouldn’t call a system a compiler system if it doesn’t), you have to solve the problem of the debug information. This means:
Encoding all the type, symbol and line information in each object file.
Link all this information at the link stage.
Read all the information in, from within the debugger.
When I started this project, several alternatives for debug information format were available: 
1. Using the ‘stabs’ format of gcc, 
2. Using the CodeView (Microsoft’s debugger) format. 
3. Using dwarf.
4. Using a new debug information standard.

After reading the specifications of several formats I decided to use Microsoft’s one. This decision was almost forced, because at that time, gcc (and gdb) did not run very well in the Win32 environment. The big advantage of using Microsoft’s one is that the code generated would be compatible with all Microsoft’s tools, including their debugger. I could test if I was generating the right thing by using debugged tools like Microsoft’s linker, and I could debug the first programs using their debugger. If I had used another format, I would have been confronted to the problem of not being able to see if I was generating correctly the code until the debugger was finished!

The Coff system has defined very primitive type/symbol information. Lcc’s debugger uses some of this information, but it has only a marginal role.

To implement Microsoft’s debug information I wrote ‘cv.c’, that is called by lcc when generating code if the ‘debug’ global flag is set, the variable ‘glevel’. In the file ‘dag.c’ I added at each block’s begin, a call to ‘GenBlockInfo’ to generate debug information for all variables that are used within the current block.

Besides this, I modified the functions ‘stabsym’ and ‘stabtype’ to generate debug information in the new format in the file ‘w32incl.c’.

The format of the debug information
This format is described in the Microsoft’s documents ’CodeView Symbolic Debug information Specification 3.1’. Besides, in an effort to promote standards for its X86 architecture, Intel Corp. has started a project where the information concerning the debug specification can be found.

Within lcc, I generate symbolic (.debug$S) and type (.debug$T) information. This will allow the debugger to make sense of the addresses and instructions found during program execution and allow it to present the information in a meaningful way to the user. Basically it will allow interpreting the data, to know the symbolic names that were used in the user’s program, and to position itself in the source code files.

Symbols
The ‘Symbols’ records are variable length records that contain the following fields:
1. Length (2 bytes). Specifies the length of the record, excluding the 2 bytes of the length field.
2. Type of the symbol (2 bytes)
3. Data specific to each symbol.

The Type field is either a user defined type (with a value bigger than 4096) or a primitive type (like ‘integer’ for instance) that is predefined by Microsoft. The predefined types are very rich, and lcc uses only a small subset of them: The ‘Cobol’ parts of the specifications are obviously ignored, as are the symbolic information for Pascal or C++ types.

Value
Data
Description
0x200 BP Relative
The offset of the symbol with the stack frame (4 bytes), the type (2 bytes), and its name.
All local variables, of a procedure.
0x201 Local Data
Offset within the section, the section number, and the name of the symbol
Static variables of the module
0x202 Global Data
Offset within the section, the section number and the name of the symbol
Global public symbols of the module
0x204 Local Procedure start
Length in bytes of the procedure’s code
Offset in bytes from the procedure start to the point within the procedure where the stack frame has been set up. In a similar fashion, the offset to the last byte before the current stack frame becomes invalid.
Local procedure
0x205 Global procedure start
Format identical to the Local procedure format.
Global procedure description.
0x207 Block start
Length of the scope that this block defines.
Name of the block
Used to define procedure scopes.

All symbol names are written with the length of the name in the first byte, followed by the bytes of the name.

Simple Types
The format for the type information is similar to the symbol information. It consists of a 2-byte length, followed by a ‘Type string’ as described in Microsoft’s terminology. This type string is a series of leaf structures that contain a 2-byte type, followed by additional data

Value
Data
Description
0x2 Pointer
Attributes of the pointer (2 bytes)
Type of the object pointed to (2 bytes)
All pointers in the code generated by lcc are 32 bit flat model pointers
0x3 Simple Array
The type of the object that forms the array. This is a 2-byte type index.
The type of the index that can be used to scan the array. This is always an integer in C.
The length of the array in bytes
The name of the array
This record will be generated for simple tables like:
int Table[345];
0x6 Unions
The count of fields in the union
An index into the list of types for each member, as in the structures
Size
Name

0x5 Structures
The count of fields in the structure
An index into the list of fields
Size
Name
Describes structures. Most fields are not used, since the same record is used to specify classes.
0x7 Enumeration
Number of enumerates (2 bytes)
Type of each.
Name
Lcc always will put ‘integer’ in the type field.

Types referenced from the ‘types’ record
This record encodes for complex lists like the lists of arguments of a procedure or the list of fields in a structure.

Lcc uses only two record types:

0x201 Argument list

0x204 Field list



A field list contains the descriptors of the fields of a structure, class, union, or enumeration. The field list is composed of zero or more subfields. To complicate things further, because of the requirement for natural alignment, there may be padding between elements of the field list. 

As a program walks down the field list, the address of the next subfield is calculated by adding the length of the previous field to the address of the previous field. The byte at the new address is examined and if it is greater than 0xf0, the low four bits are extracted and added to the address to find the address of the next subfield. These padding fields are not included in the count field of the class, structure, union, or enumeration type records. If the field list is broken into two or more pieces by the compiler, then the last field of each piece is an LF_INDEX with the type being the index of the continuation record. The LF_INDEX and LF_PADx fields of the field list are not included in field list count specified in the class, structure, union, or enumeration record. See Section 3.5 for field list elements.

Examples
Suppose the following program:

enum e { F1,F2,F3,F4};
int main()
{
        enum e j=F3;

        printf("%d\n",j);
}
We can display the debug information using the ‘pedump’ utility. We use the command line:
pedump /D program.obj.
In the above example we obtain :

section 03 (.debug$S)  size: 00134  file offs: 00730
[  1] offset 4 length 16 index 9 (0x9H) Obj signature 0, name 'tenum.obj'
[  2] offset 22 length 41 index 517 (0x205H) Global Procedure '_main'
      Parent 0 End 0 Next 0 Length 44 debStart 18 debEnd 39 offset 0
      Segment 0 proc record type index 4099(3) flags 0x0H
[  3] offset 65 length 10 index 512 (0x200H) Automatic 'j'
      EBP offset -4 type: '0x1001 (4097 1)'
[  4] offset 77 length 2 index 6 (0x6H) Block End
[  5] offset 81 length 51 index 1 (0x1H) Compile Info:
      Machine 0x4 Language 0 Flags1 0x0 Flags2 0x0
      'Logiciels/Informatique lcc-win32 version 2.4'

In the .debug$S (symbols) section there are five records. They begin at offsets 4, 22, 65, 77 and 81 relative to the start of the section.and they are presented indexed with square brackets by pedump.
The first record contains the object file name and signature field. Lcc doesn’t fill the signature field.
The second symbol record is the information for the global procedure ‘_main’. Lcc doesn’t fill the ‘Parent’ field, since there are no nested procedures in C. The important fields are the procedure length, and the start/end of the debugging information. The numbers represent the number of bytes from the first byte of code of the procedure. Another field here is the ‘type index’ field, in this case 4099. These tell us that the type description for this procedure, i.e. the types of its argument list is to be found in the type record 4099. Since user defined types start at index 4096, the record containing that information is actually the fourth type record in this file.
The third record contains the description for the local variable ‘j’, in the C code above. It tells us that the value of this variable is to be found at EBP - 4, and the type description for it has an index of 4097, i.e. is the second record in the types section30.
The fourth symbol record is just an indicator that the list of local variable symbols finishes here.
The fifth symbol record is a signature emitted by the compiler describing the translator, the ‘company’ that made it, etc. This record finishes the .debug$S section.

The .debug$T section contains the types defined by this small program. Pedump will display this section like this :
section 04 (.debug$T)  size: 00090  file offs: 00884
[  1] Offset 0 length 50 index 516 (0x204H) Structure member list
      Enumerate. Attribute=0  Value: 0 F1
      Enumerate. Attribute=0  Value: 1 F2
      Enumerate. Attribute=0  Value: 2 F3
      Enumerate. Attribute=0  Value: 3 F4
[  2] Offset 52 length 14 index 7 (0x7H) Enumeration: 'e' 4 members
      Enum type 32 bit signed int,fields 4096 (0)
[  3] Offset 68 length 4 index 513 (0x201H) Argument list. 0 arguments
[  4] Offset 74 length 10 index 8 (0x8H) Procedure:
      return type: 116 call 0 parameters 0 arglist idx 4098 (2)

Here we find four records. The second one was the one indicated by the third symbol record above. It is an enumeration description, telling us the name of the enumeration, and that the field list of the enumeration starts at offset 0 (i.e. with the index 4096) of the .debug$T section.
Looking at the offset zero (the first record) we effectively find a list of enumerates, containing each one a description of each member of the enumeration.

The other type record referenced from the ‘symbols’ section was the fourth, i.e.  the record that describes the ‘_main’ procedure. This record defines the return type of the procedure (116 ;i.e. an integer), and points to the record containing the description of the procedure arguments : the third type record. Since we have declared main with no arguments in the C code, this record is empty.

To get a detailed description of the debug information look in the ‘pedump’ source tree for the ‘DumpExeCodeViewInfo’ function, in the source file common.c. There you will see the start of the debug info dumping functions of pedump. All the available documentation about that format is included in that source file in the form of comments. You can follow pedump under the debugger to see how wit goes unraveling the binary formats.

Implementing the “inline” operator (C99)
The new standard published by ANSI specifies the “inline” function qualifier. This construct should specify that a function will be expanded at each call site, and the compiler should replace the function call with the actual body of the inlined function.

The implementation is as follows:

1. The “inline” keyword was introduced to the lexer (in lex.c)
2. The declaration of inline is detected when parsing the function specifiers. A new type qualifier “inline” was introduced.
3. The body of the inline function is stored for later used in the form of a token list. This is done in the function “InlineTemplate” in the file templates.c31.
4. At each call site, the compiler tests if the function being called is an inline function (see enode.c the “call” function). If this is the case, the compiler will, before any arguments are evaluated, announce this fact to the inline module through the function BuildInlineReturnSymbol.
5. The compiler will then gather the arguments, and will assign each argument to a new local temporary variable using the BindOneInlineArg function.
6. The compiler will make a copy of the token list, and will replace everywhere the arguments by the newly created locals.
7. The token list is transformed into a character string, and feed into the lexer again, as if the user had typed the function body at the call site.
8. All occurrences of the “return” statement will be replaced by an assignment to a specially declared local variable, followed by a jump to the code following the inline call.
9. If the inline function returns a value, the result of the inline call is a id tree of that return variable, if not, the result is just NULL.
10. The first time an inline function is called, the compiler will mark the position of the counter where static variables are stored. The next time a function call to an inlined function appears, the counter of the static data segment will be reset to the value it had in the first call. This guarantees that in all invocations of the inline function the static variables will always point to the same static variable, and not to a new one.
11.  The tree nodes generated by the inline expansion are converted into dags later on, not immediately. 
12. The RIGHT nodes necessary to correctly evaluate function arguments are recreated by the inlining process.
13. The “listnodes” function in dag.c was modified to emit the correct trees, instead of the call tree that is generated by enode.c.

The core idea of this implementation is to use a character string to compile code dynamically within the compiler. This is an idea that will have a wide use in the future of lcc-win32.

The peephole optimizer
1. Motivation
Lcc generates very efficient code for each instruction taken separately. The problem is, as Fraser and Hanson remark at the end of their book, that «lcc’s instruction selection is optimal for each tree in isolation, but the boundaries between the code for adjacent trees may be suboptimal. Lcc would benefit from a final peephole optimization pass to clean up such problems»

2. Implementation

I started working in this, with the idea of a very crude pattern matcher, just to avoid some obvious nonsense instructions. I was worried by the spurious ‘movl %edi%edi’ that sometimes appeared in the generated code. That bug is since a long time corrected, but the design of the optimizer bears still that mark. I haven’t redesigned it since I started it. It just grew and grew and grew... 

In retrospect it could be said that a little more effort in the design of the program would have saved lot of work later, but I do not think that is the case. This ‘keep it simple’ approach, allowed me to start immediately seeing the problems involved in assembly optimization, without having to spend a lot of time building complex data structures (and debugging them...)

The basic idea is to consider a ‘basic block’, i.e. a piece of code that contains jumps out of it, but not into it. Since lcc always generates jumps to labels I decided to use labels as a guide: a basic block then, is all code contained between two labels.

I built a scanner for digesting the flow of assembler instructions emitted by ‘genasm’, and to save the information it gathered in data structures. Here again, I just used a ‘Flags’ field with whatever it seemed important to keep: if it’s a ‘move’ instruction, or if the source is a register, or the addressing mode, etc.

Once all information has been stored in the ‘Instruction’ data structure, the main work could begin. I built a table of the contents of each register, to keep track of the state of the machine as it executes one instruction after the other. In this table I just stored that text representations of the data that was currently in each register. Whenever I see a ‘load’ instruction, I scan that table to see if the data is already in a register, and if it is, this instruction can be deleted.

The main aim of the optimizer is to delete instructions. I keep thinking that there is nothing that executes faster than a deleted instruction. Besides other side-effects that make code-size a big win in optimizations: if your program is smaller, it will fit easier in the cache of the processor, it will take less time to load, and will make for less page faults when executing in a crowded machine.

I followed following rules:
I store the content of a register in the ‘State’ table, when the register is written to memory only, not when it is loaded. This is very conservative, but safer. I miss all the optimizations that could be done if I kept track of the value being ‘moved’ from one register to another.
I update the state of all registers that are invalidated explicitly or implicitly by the instruction. Specifically:
A ‘call’ instruction invalidates EAX, ECX, and EDX. The others, EBX, ESI, and EDI are supposed to be preserved at all times.
A ‘call’ instruction invalidates all registers that contain references to global variables. The function called could modify those variables, so I invalidate all references to global memory.
I keep track of all instructions that implicitly use a register: for instance the ‘rep movsb’ increments ESI and EDI, so their contents are undefined at the end of the instruction.
To avoid the problem of the ‘aliases’, each LEA (load effective address) instruction invalidates all the registers. The problem is that when this instruction is executed, an alias for a memory location is built. If there was a register caching the value contained in that memory location, the register could be wrong after several operations. Rather than take any risk, I just destroy all state stored by the optimizer.

3. Patterns
Besides trying to eliminate redundant loads, the optimizer tries to substitute sequences of long instructions with shorter and faster ones. The list of patterns that I have built in this year is long (more than 30) and very specific to the code generated by lcc. I have never had in mind the idea of building a general-purpose optimizer, which could optimize ANY piece of code. I just built a specific one, tailored to lcc’s output. Because of this, sequences of replacements that could be of interest in a general-purpose peephole optimizer are not taken into consideration because lcc never generates them.

3.1 Cross -loads
mov	src, dst
mov	dst, src
For instance
movl	%edi,-4(%ebp) ; store a local variable
movl	-4(%ebp),%edi	; delete this one!
Preconditions: None. I can’t imagine a situation where this is not valid.

3.2 Eliminate unnecessary moves before a push
Instead of moving a memory location to a register for pushing it later, push that memory location directly.
mov	-8(%ebp),%edi
pushl	%edi

becomes
pushl	-8(%ebp)
Preconditions: The value in %edi shouldn’t be used later on. Sometimes lcc (or the optimizer itself) will use that value in another series of pushes. This optimization should be avoided in those cases.

3.3 Avoiding unnecessary intermediate registers
3.3.1 Especially with byte moves, lcc generates a sequence of instructions like this:
movl %ax,%bx
movb %bl,-1(%ebp)
This can be safely replaced with:
movl %al,-1(%ebp)
Preconditions: The value in bl shouldn’t be used in later instructions. Actually, lcc never uses it.
Other variants of this same problem are sequences like this:
3.3.2
movl -24(%ebp),%esi
movl %si,%bx
movl %bl,-1(%ebp)

That can be safely replaced with
movl -24(%ebp),%ebx
movl %bl,-1(%ebp)
sparing the contents of esi, that could lead to other improvements.
Preconditions: None
3.3.3
This long sequence:
movl -16(%ebp),%esi
movl %si,%bx
movzbl %bl,%eax
movb %al(,%edi)
can be replaced with:
movl -16(%ebp),%ebx
movb %bl(,%edi)
This sequence arises when generating code for the ‘C’ statement:
	p[0] = (unsigned char)c;
Where  the variable ‘c’ is an unsigned long, and p[0] is a ‘unsigned char’ variable.
Preconditions: None.
3.3.4
Still another sequence is:
movl -4(%ebp),%esi
cmpl $45,%esi
That can be safely replaced with:
cmpl $45,-4(%ebp)
Preconditions: The value in %esi shouldn’t be used later.

4 Eliminate constants if possible.
Instead of
movl	$0,%eax			b800000000
generate
xor	%eax,%eax				31c0
which is much shorter: 5 bytes vs. 2 bytes.

The same with some additions/substractions:
addl	$-1,%eax			83c0ff
can be replaced with
decl	%eax				48
3.5. Use the ‘new’ 486 instructions.

These instructions were introduced by Intel for the 486 or higher processors. Since lcc-win32 will surely run in a 486 or higher, it is safe to assume this can be done. In the documentation it is stated explicitly that lcc will not run in a 386 or without the math coprocessor...

Instead of the long sequence:
mov mem,reg1		load value
mov reg1,reg2		save old value in reg2
inc reg1			add offset
mov reg1,mem		store updated value
generate the much shorter
mov		$1,reg2
xadd	reg2,mem
This corresponds to the much-used ‘C’ idiom:
	unsigned char *p;

	*p++  = ‘c’;
The old value of the memory locations is loaded into the ‘reg2’ register, and the contents of the memory location are incremented by the value in ‘reg2. This allows us to use the old value in reg2 to do the assignment.
Preconditions: The value in reg1 shouldn’t be used later. This is never the case for the code generated by lcc, so this is a safe optimization.

3.6. Optimize sequences.

3.6.1 Sequence of calls with the corresponding stack adjustments.
In the sequence:
push	arg1
push	arg2
call	someProcedure
add		$8 , %esp

push 	arg1
push	arg2
call	OtherProc
add		$8,%esp
The additions to the stack can be concentrated in a single add to the stack. This saves space and time.
Preconditions: There shouldn’t be any intervening jumps or conditional jumps out of the sequence of instructions.

3.6.2 Initialization sequences
Instead of 
xor	%eax,%eax
movl	%eax,-4(%ebp)
xor	%eax,%eax
movl	%eax,_GlobalVar
We can do the ‘xor’ operation once and the just store the same value (zero) into the indicated memory locations.

3.7. Improving the block move instructions.

Lcc will generate a block move when one structure is assigned to another. The instruction generated will always be ‘movsb’ that moves only 1 byte per cycle. Since normally the size of the structure is an explicit constant, this can be improved by using the ‘movsl’ instruction, that moves 4 bytes per cycle, or, if the size of the structure is not a multiple of four, movsw that moves 2 bytes per cycle. It is this optimization that increases enormously the performance of the compiler in the Whetstone benchmark.

3.8. Inlining library functions.

Instead of generating:
push	128			6880000000 (5 bytes)
push	src			ff3500000000 (6 bytes)
push	dst			ff3500000000 (6 bytes)
call	_memcpy		e80000000000 (6 bytes)
add	$12,%esp			83c40c        (3 bytes)
							Total:                        26 bytes
we can generate:
movl	$128,%ecx		b980000000 (5 bytes)
movl	dst,%edi		8b3500000000 (6 bytes)
movl	src,%esi		8b3d00000000 (6 bytes)
rep		movsb		f3a4          (2 bytes)
					Total                         19 bytes
We save 7 bytes and generally, this should be faster than the call. If the memcpy function is very well implemented however, and the blocks to move are very big, it could be that this is not an optimization at all. Most calls to memcpy are for copies of several dozens or hundreds of bytes, where the cost of the call would be significant. This optimization is especially good for older processor (486). The new Pentium processors have a very small ‘call’ cost, and the quality of the memcpy function is more predominant.
Preconditions: This destroys esi and edi. They are normally saved at function entry, but in some functions they are not. This happens if they weren’t used in the original, non-optimized version. If that is the case, their contents should be saved/restored in other registers. 

Another problem is the stack adjustment. If the call to memcpy was the last of a series of calls,  (see 3.6.1) and the final stack adjustment was done after the call to memcpy, the instruction for adjusting the stack should NOT be just erased. In an example:
	.
	.
	call	somefunc
	add	$8,%esp
	.
	.
	call	someother
	add	$24,%esp
	.
	.
	call	memcpy
	add	$44,%esp	(12 for the args of memcpy, and 32 for the others)

That last instruction should be changed to
	add	$32,%esp
instead of being just erased.
3.9 Avoiding clobbering when possible.
If an instruction will destroy a value in a register, and that value is later loaded from memory, try to substitute the destination register by another one (%ecx or %edx are good choices since lcc almost never uses them).
1. movl	-8(%ebp),%edi
2. movl	%edi,-16,%edi
3. movl	-4(%ebp),%edi	; destroys the value in %edi
4. incl	%edi
5. movl	%edi,--4(%ebp)
6. movl	-8(%ebp),%edi ; reloads %edi

We can avoid the redundant load by substituting %ecx instead of %edi for the second load (instruction 3). This allows us to delete instruction 6.
Preconditions: The ‘spill’ register shouldn’t be used in other instructions further down, and it shouldn’t contain a value used later on, since this would nullify the gains.
3.10 Avoid unnecessary moves
When you acces to a member of a structure whose value is the result of a function call, lcc generates the following code :

	movl	%eax,%edi
	movl	8(%edi),%edi

We can get rid of this unnecessary operation and write directly :

	movl	8(%eax),%edi

This optimization is encountered very often, and contributes significantly to reducing the code size.
Preconditions : In general, this should be possible with any operation of the form :

	movl	%eax,%edi
	OP	offset(%edi),%edi

I restricted this, however, to mov (in any of its forms) and leal.

4. Construction of the optimizer.

Debugging the peephole optimizer has been a constant chore for months. Endless nights without sleep were lost chasing very difficult to find errors, which wouldn’t surface at first sight. In the ‘lucky’ scenario, the generated program just traps, you disassemble the offending code near the trap and you see where the optimizer went wrong. In the ‘unlucky’ scenario (by far the most common) the program will just produce incorrect results sometimes. Not always. These kinds of bugs have been very difficult to find. The problem is stating clearly the preconditions that are necessary for the optimization to work.

Besides this, I made the optimizer re-enter optimization with its own output, until there is no further improvement. This augmented its effectiveness, but... what a nightmare. Many of the optimizations were not really completely debugged for the general case. When I used the optimizer in a recursive fashion, its input at the third or fourth pass would differ significantly from what lcc generates. Assumptions about the code generated by lcc were no longer valid. But in retrospect, I think that helped to produce a more general tool.

All the source code for the optimizer is contained in the optimize.c source file in the compiler’s sources directory.

5 Speed considerations
The slowing down of the compilation time due to the optimizer is barely noticeable. Compilation remains an absolutely I/O bound process, and since the optimizer takes a memory buffer that is intended for the assembler, changes it, and passes it to the assembler, all in core, the difference when compiling a big program is not significant. Besides a compilation time of 8 seconds goes down to 2 seconds for the second time, since Windows caches the disk systematically. It is very difficult to see which part in that huge difference is due to the optimizer.

6. Results:
In general, the gains in space oscillate between 20 and 30 percent, and the speed improvement can go as high as 50 percent for the Whetstone benchmark. Since that benchmark is very sensible to block-move operations, this huge improvement is not significative of the overall improvement you can expect from this optimizer.

7. Description of the code
The only interface with the rest of lcc is the function ‘ChangeBlock’ at the end of the source file ‘optim.c’. This function receives a block of assembler instructions from ‘SendToOptimizer’, a function in ‘output.c’.

The optimizer scans the assembly code in the function ‘FindEndBlock’, that searches for an ending label within the assembler instructions. The optimization proper is done in ‘OptimizeBlock’ that calls ‘FindStateChanges’ for each assembler instruction. ‘OptimizeBlock’ does the stack adjusting optimization described in 3.6.1.

8 Further work
The next step is of course to build the graph of the program and do tail merging. I hope I find the resources to carry on the work by Fraser, (‘Analyzing and Compressing assembly code: C. W. Fraser ACM Sigplan 84) This work would mean that huge programs could be compressed by a factor of 50% or more.

The high level optimizer
Even if the peephole optimizer allows some improvement of the code generated by lcc, it is surely not enough. Impressive speed/code size gains can be only obtained by modifying the structure of the register allocation, using more evenly the available registers.

The main directions of the improvements done for the second public release of lcc-win32 are:
Improving the machine description, the basis of the tree labeler.
Introducing automatic variable caching in registers.
Improving the code generated for common C idioms
Improving floating-point performance by avoiding unnecessary copies of data from/into the floating-point unit.
Constant folding.

Improving the machine description
The x86 is CISC architecture. Thus, for generating good code for it, it is necessary to take into account all addressing modes and data types supported natively by the machine. The original version of the machine description, as published by Chris Fraser and Dave Hanson, consisted of approximately 195 rules. I have increased this to approx. 350, taking into account the byte and word-addressing modes everywhere that is possible. This eliminates many unnecessary moves to/from memory and reduces code size, improving speed. As an example of this kinds of improvements consider this rule:

stmt: EQI(CVUI(BANDU(CVIU(CVUI(CVCU(INDIRC(mr)))),con)),zero)

This sequence of instructions of lcc’s virtual machine arise when you use the innocent looking idiom in C:
	if (isdigit(c))

This sequence of statements in lcc’s virtual machine operators was translated using the standard backend into the following sequence of operations:
        movzbl  -1(%ebp),%edi
        movzbl  __ctype+1(,%edi),%edi
        andl    $4,%edi
        cmpl    $0,%edi
        je      _$2

Using the new machine description, this entire sequence of operations will be collapsed into:
        movzbl  __ctype+1(,%edi),%edi
        testb   $4,%edi
        je      _$2
Note that we save two 4 bytes constants (4 and zero), that are replaced by a one byte constant, since the type of the operation is now byte (testb). This allows using directly the machine instruction, instead of doing the conversions that are in the end not needed at all.

Most of the new rules added are just attempts to avoid any unnecessary conversions, and use directly the x86 addressing modes.

Another important issue was that several machine instructions, especially in the floating-point instructions, were missing. I added the reverse divide/substract, and all operations that allow the floating-point unit to directly address 16 bit data, avoiding (again) unnecessary conversions.

Rules to directly operate with an address using a constant.
These rules have the general form:

	ASGNX(addr,OPERATION(INDIRX(addr),constant))
where:
ASGNX can be any of ASGNI, ASGNP
OPERATION can be one of  SUB, ADD, AND, OR, RSH, or LSH.
Both addresses, i.e. the source and the destination, must be the same
constant is an immediate program constant.
The x86 CPU can directly add to an address an immediate program constant. This simplifies many constructs enormously, and makes for smaller, tighter code.
Rules concerning the usage of the constant one.
The x86 CPU supports many operations that implicitly use the constant one, i.e. the different forms of the inc/dec instructions. Some of them were catched by the original machine description, but not all of them.
Actually, these rules are just a specialization of the first kind of rules above, for the special case where ‘constant’ is one.

Rules for using the special machine modes.
This rules use (always in the case of an immediate constant) the machine modes of the x86 CPU that has a rich set of data types. It has words (16 bits), chars (8 bits), floats (32 bits), doubles (64 bits), and even others that are not used in the C language: BCD digits, or 80 bits floats.

Rules for fully using the floating-point unit.
The floating-point unit can load a 32-bit integer, a 16 bit short, without any need for extra conversions. Other modes allow collapsing long sequences of intermediate language statements into one machine instruction.

Rules for fully using LEA.
This versatile instruction allows adding three items with one machine instruction. It can be enormously useful within the context of array indexing. It wasn’t really used in the original machine description.

Problems caused by the larger machine description.
The proliferation of longer rules produces a tree labeler that has to make more tests to find the optimum solution for the given tree.  To easy somewhat the impact of the new rules:
I have modified lburg, the program that generates the tree labeler from the machine description, to generate better code by avoiding unnecessary additions of zero, putting very frequently accessed structure fields in local variables, and other modifications that speed up the labeler.
I have kept the standard back-end for use when the compiler is not called with the optimize option (-O). This faster backend keeps the same compilation speed as lcc had, when the user is not interested in code optimizations but in compile speed.32
Many of the optimizations that the peephole optimizer did in a very time-consuming way, have been moved to the tree labeler, saving much time in the optimization process, and improving the maintainability of the peephole code that had grown to a huge size.
Improving register usage
The basic problem with lcc, was that 90% of the instructions just used two registers: ESI and EDI. As an example, consider the file ‘edit6.c’ that is part of the IDE (Wedit). It has approx. 10 000 lines: This is the output of the utility  ‘regusage’

EAX    821
EBX    158
ECX      9
EDX     20
EDI   7373
ESI   2086
Total: 10467 

We see here that  9459 instructions used ESI or EDI, i.e. more than 90%! The other registers are almost never used: ECX is used sometimes in modulo operations (9 instructions out of 10467!) EDX holds the result of the modulo operation (20 instructions..), and the usage of the other registers is minimal. This means that the machine is used to 25-30% of its real capacity, making a very slow code.

The reults using the -O option look now very different:
EAX   1005
EBX    791
ECX   1153
EDX   3431
EDI   1730
ESI   1111
Total: 9221
The first thing that is apparent is that the number of instructions emitted has been reduced by 10%. This is because many unneeded instructions (conversions from char/shorts to int) were eliminated by the new machine description.

The second important fact is that the program is using the registers much more evenly, especially ‘cheap’ ones like EDX, ECX, that need not to be saved when they are used.

Register allocation now uses automatic register variables. Before code generation, the optimizer looks for the best three variables to put into EBX, ESI, and EDI. To do that, it analyzes the hints about the code in the function left by the parser and the node construction function ‘labelnodes’ (in dag.c) to determine how many registers can be allocated. The code generator and register allocator works now with only three free registers in some situations. 

Spills have not increased though, a big fear I had when embarking into the construction of the optimizer. This is due in part to the elimination of unnecessary conversions that now save a register when one was being wasted before.

Since the x86 instruction set has many ‘special features’, they have to be considered when allocating registers. Big troubles are those instructions that accept their inputs in fixed registers, and clobber them: I mean for instance the block-move instructions, that destroy ESI and EDI, and use up ECX to hold the repeat count. For the time being the compiler will NOT optimize any function that contains this instructions, to avoid generating wrong code in some cases. Since these instructions are not very frequent, this doesn’t hamper the optimization process as a whole.

The rules for choosing the best register variables are as follows:
1. If the function calls no other functions (leaf function) and has no block move or division instructions, EBX, ESI and EDI are free for register variables.
2. If the function calls another function, but has no calls within the argument list to a function, no division/modulo and no block moves, EBX, and ESI can be used for register variables
3. If the function has no block moves EBX is used for a register variable.
4. Else... well no register variables at all.

These rules seem very arbitrary, and they surely are. The problem lies in the function ‘clobber’ and in general in the register allocator of lcc that doesn’t work when those instructions are encountered. I have spent countless nights trying to find out a solution, but I had to give up. So I examine every statement trying to minimize the trouble that those operations cause.

Before the call to gencode() the high level optimizer looks at the information passed to it by the parser, and determines which registers can be used for register variables. Then it will sort the locals of the function (arguments and local variables), and allocate the best ones to the available registers.

Another small optimization that is done at that stage of compilation is the elimination of any unneeded labels. Since the peephole optimizer uses the labels as a mark for blocks to optimize, it is essential that it receive blocks as large as possible. Unneeded labels would split unnecessarily a block, diminishing the usefulness of the peephole optimizer.

After ‘gencode’ is done, if the function is a leaf function, and some cheap registers weren’t used, they will be exchanged with the ‘expensive’ registers, like EBX,ESI or EDI. Those registers are expensive since they have to be saved/restored at function entry/exit. This can be done safely if the function is a leaf function only, because having a register variable in EAX would be very expensive to maintain: at each call that register variable would have to be saved!

Improving floating point performance

Analyzing why the performance of lcc in floating point was so mediocre, I discovered that the compiler was considering each floating point number as a common sub-expression, i.e. an expression that should be saved into a register. This is not a bad idea, since the loading of a floating-point number can be costly. Problem is, lcc doesn’t use the floating-point registers in the x86 architecture due to the organization of those registers as a stack. This is surely a wise decision from the part of the authors of lcc, since other compilers do the same, probably for the same reasons.

The code for the common sub-expressions was not eliminated, however. This means that this ‘cse’ will be spilled to memory, since there are no floating-point registers. Consequence: for every floating-point operation, lcc will duplicate the floating-point number in memory, and load it from there. This slows down the code enormously.

The remedy for this was very simple: I eliminated the cse, and the floating-point code generated by lcc is now comparable with the code emitted by professional compilers.

Another improvement of floating point has been obtained by eliminating unnecessary conversions, since the floating-point unit can use directly 16 bit and 32 bit integers.

Front end modifications
Several modifications were necessary to make the optimizer work. First, since the x86 never used any register variable, I started using code that wasn’t tested before in this configuration. Second, I eliminated all the unnecessary conversions from, for instance, unsigned integer to pointer. These conversions are completely vacuous in all targets of lcc, so I just filtered them in the corresponding ‘case’ of the function ‘listnodes’ of dag.c.

Since the optimizer needs information about the instructions used in a function, I added some fields to the ‘Node’ structure to hold bits indicating whether this function has a block move instruction (ASGNB) somewhere, whether it uses division... etc. This allows the register allocator to make decisions about register usage/allocation.

Heavier modifications were needed in the register allocator of course. It has been modified to return EDX, ECX, EAX, ESI, and EDI in that order.

Another small modification is the improvement of the return instruction in the popular C idiom:
	if (!SomeFn())
		return FALSE;

I eliminated in this context an unnecessary assignment to a register, since if the function ‘SomeFn’ returns false, that same result can be returned without any further processing. This can happen of course only if the return type of the function is an integer.

Finding variables with disjoint domains
Lcc has only a ‘global’ register allocator. A register will be assigned to a variable once for all within a function body. Even if the variable is no further used, it blocks the usage of a register until the function exits. To improve this situation, the optimizer looks at the ‘firstuse’ and ‘lastuse’ fields that are maintained by lcc-win32’s front end. Those fields define the domain of a variable, i.e. the portion of code where they are ‘alive’. If the domains of the two variables are disjoint, they will be assigned to the same register.

Of course this is possible only with local variables or arguments. Global variables will be always alive.

A complication for this is loops. Consider for instance the following code snippet:

	for (i=0; i<10;i++) {
		a=10;
		...
	}
A parser looking at this and ignoring loops would think that the variable <i> is not used after the for statement... To avoid this, I extend the lifetime of all variables used in a loop until the end of the loop.
Modifications to lburg
1. I added the special symbol “;;” as a comment separator. This allows commenting those hairy rules in the machine description.
2. I have tried to eliminate all additions of zero. I didn’t succeed in eliminating them all, but most of them.
3. I factored out some common sub-expressions into local variables in the generated code. This speeds up the compilation time, since the labeler uses up 5-8% of the total compilation time (with no optimizations)
The modified sources of lburg are included with the sources of lcc-win32.

Constant folding
Constant folding is an attempt by the compiler, to replace all variables that are directly assigned to an integer with its equivalent constant in an attempt to simplify the code.

For instance :

int foo(int a)
{
	int b = 8 ;
	int c = 9 ;

	return (b+c)/(b * (c-b)) ;
}

can be replaced with:

int foo(int a)
{
	return 2 ;
}

The compiler achieves this by replacing all instances of the constant assignments with constants. This leads to :

int foo(int a)
{
	int b = 8 ;
	int c = 9 ;

	return (8+9)/(8 * (9-8)) ;
}

After this substitution phase, an evaluator reparses the output and applies the corresponding operation when possible.
Sometimes this optimization will discover dead code :

	A = 8 ;
	…
	if (A == 0) {
		…
	}
In this case, the if construct will be replaced with a jump, but the dead code will not be eliminated. 

For a variable to qualify for constant folding it must be :
A local variable
Its address must never be taken. This avoids the aliases problem.
The assignment must be directly an integer constant. This can be extended to floating point numbers of course, but this is not yet implemented.
Folding will stop if the variable is the target of an assignment, or a flow control instruction is reached, or a label.

The implementation is done in the file analysis.c.

Dividing by a constant.
Peter L. Montgomery proposed in his research article ‘Division by invariant integers using multiplication’ an algorithm for dividing by a constant using a multiplication by the constant’s inverse instead of an expensive division. I implemented his algorithm in lcc-win32, producing two functions :  GenerateUDivByConst, and GenerateSDivByConst in win32incl.c.

The algorithm for unsigned division goes roughly like this :
1. Put the quantity do be divided in EAX.
2. Test if it is an exact power of two. This is already done in the front end simplifications (simp.c) but maybe an uncaught division was generated later by constant folding for instance. If the constant is an exact powser of two just generate a shift right of eax and return. No more is necessary.
3. If it is not an exact power of two, we call Montgomery algorithm with 32 bits, and precision 32. The algorithm returns the sign of the most significant part, and a multiplier that we use for multiplying by the inverse.
4. If the high bit is set and the constant we are dividing with is even, we compute a pre-shift.
5. If the pre-shift was done, generate a shift right of eax by that amount.
6. Then, generate code to put the multiplier into edx.
7. If we need the value in eax, save it with a push or in ecx.
8. Generate code to do the multiplication. The result of this is a 64 bit quantity in EAX :EDX.
9. If the most significant bit (returned by the call to the algorithm in 3) is set, generate code to restore the dividend that we saved in step 7 into eax. At this step the generated code has the dividend in eax, and the most significant 32 bits of the multiplication in edx. If the most significant bit was not set, go to step 13.
10. Substract edx from eax.
11. Shift right eax by 1.
12. Add eax to edx.
13. Shift right edx by the shift amount returned by the call to Montgomery algorithm above in step 3. Only do this of course, if shift is different from zero.
14. Move edx, that contains the result of the division, into its destination : eax.
Optimizing ‘const’ variables
When you declare
const int C = 4876 ;
the compiler should be able to replace all appearences of that constant with its value, making it possible to use it in all contexts where a constant is needed. You should be able to write :
	switch (input) {
		case C :
			…
			break ;
	}
or 
double array[C] ;
This is implemented by modifying the function idtree(), to test if the symbol being asked for is a constant, and returning code for a constant instead of returning code to fetch the constant. Some care is needed to ensure that the const int is really initialized to a constant and not a parameter to a function for instance. This is done at initialization time, when the compiler records if the variable is initialized or not. Note that with external const ints this optimization is not possible.

The function idtree then, returns a tree node for the actual constant, instead of returning a tree that accesses that constant. Very good, but a problem will sulrely occur if the user takes the address of that constant ! Suppose :

const int C = 4766 ;
…
	pC = &C ;

This is perfectly legal, but now it will not work now, because the compiler will be confronted with the equivalent of :

	pC = &4766 ;

We have to setup a flag to tell « idtree » not to do this optimization if an address is required. We see here the problem with optimizations : each one is simple, but their interactions with other parts of the language is what makes them extremely difficult.

A further optimization would be to eliminate the const int from the generated code altogether, what can be done when it is declared static, but this isn’t done (yet).
Optimizing structure arguments
When doing operator overloading, a common situation is to hide a pointer to a big structure within an opaque « struct » with just one member.

Suppose you have then, a structure like this :
typedef struct tagV {
	void *handle ;
} SomeType ;

Then, you call a function, passing this structure by value :
	SomeType st ;
	…
	someFunction(st) ;

When you look at the generated code, you will see that the compiler generates code for copying a block of data (i.e. sets EDI to the value of the stack pointer, source as the value of the address of that data, and then generates a block copy instruction for moving the data from its origin to the stack.
This is quite a huge overhead for something that actually should be done just with a push instruction ! 
In lcc’s intermediate language, the rule for this operation in the specific case of a structure that resides in the local variables area is :

	ARGB(INDIRB(ADDRLP(tmp)))

This means : Push a block in the stack (ARGB) from the result of fetching the contents of a block that starts at the address of the local variable (ADDRLP) named tmp. Here is a more detailed look at the generated code :

ADDRLP(tmp)
reg: addr 
leal    -4(%ebp),%esi

The register allocator chooses the right register for this operation (esi) because it was told so by the function ‘target’, in w32incl.c.

ARGB(INDIRB(ADDRLP(tmp)))
stmt: ARGB(INDIRB(reg)) 
subl    $4,%esp	;make place in the stack
movl    %esp,%edi	;setup destination
movl    $4,%ecx	;setup count
rep				;now copy bytes
movsb33

A first approach would be to go to dag.c, and see the case for ARG. Then we could just change the ARGB instruction into ARGI, and everything would be perfect. : the « block » would be handled as an integer.

Well, this will never work : we get immediately a « compiler error in kids » fatal message, telling us that there is no rule for

	ARGI(INDIRB(ADDRLP(v)))

Yes, using ARGI for INDIRB is something that is not foreseen in the machine description of course, since it is a contradiction : the type of the ARG operation must match the type of its argument.

Well, another approach would be to avoid generating the ARGB in the first place. As a general rule, the sooner an optimization is done, the cleaner it is. This optimization could be done in the peephole optimizer, for instance, but there it would be much more difficult to extract the right sequence of instructions from the assembly stream. Block copies could be generated in other contextes, and we would have to distinguish the one that use the stack. Better to do it right at the source of the problem, i.e. when pushing each argument to a function call.

We write then a new function « Generateonepush() » like this :

Tree GenerateOnePush(Tree q,Tree args)
{
	if (OptimizeFlag &&
		q->op == INDIR+B && q->type->size == 4) {
		q->op = INDIR+I;
		args = tree(ARG+I,inttype,q,args);
	}
	else
		args = tree(ARG + widen(q->type), q->type, q, args);
	return args;
}

Note that we require that the size of the structure should be always equal to 4. This would mostly work for smaller structures, but at the risk of accessing undefined memory.34 Note too, that as a rule, all this optimizations are done only if the user requested optimizations. If not, the slower and straightforward code is generated.
Other changes to the front end.
1. There is no need to convert enumerations into integers since enumerations are represented as integers. I added some code in stmt.c to eliminate this conversion when reading the arguments to a function.
2. The code for assigning registers in decl.c was moved to the optimizer.
3. The option «-z» was added to the options of lcc. It will generate a .lil (lcc’s intermediate language) file for perusing if you are interested in looking at this feature of lcc.
4. The file ‘enode.c’ was modified for accommodating the ‘intrinsic’ interface. See the chapter about that below.
5. There is no need to generate an intermediate value if the return type of a function is the same as the value being returned. A small modification in stmt.c (function retcode) improves this, and eliminates a lot of unnecessary register moves.
6. Since lcc doesn’t spill floating-point registers, it would fail with some complicated expressions. This problem hasn’t been solved for the general case, but a small modification in simp.c produces now code that will use optimally the floating-point stack.
7. I have added several simplifications that were missing from simp.c: additions/substractions by zero, AND with 0xFFFFFFFF, and other operations are now eliminated.
8. Instead of doing a right shift of 24, I generate code to access a memory location 3 bytes higher.
9. Changed init.c to accept user configurable packing of structures.
10. The building of the stack frame can be avoided in some cases. This is done in w32incl.c

Quality control

The following programs are used as the test-bed for a new version of lcc.

lcc			37.000 lines
lcc’s IDE (Wedit)	72.000 lines
lcclnk			 8.000 lines
weditres		31.000 lines
tst directory		 9.000 lines
gcc 2.7.2.1		11MB of C source.
Lclint			5MB of C source

Further work
This is the first try of a high level optimizer. Many optimizations are still possible of course, but this release represents a compromise between the ‘ideal’ optimizer, that would be ready in a year or so, and the state several months ago. 

Within the framework of the existing register allocator, and the existing structure of lcc, some improvements can be readily be done still:
1. The handling of the post-increment/decrement expression forces the usage of two registers when only one is needed in 99% of the cases. This needs a change in several functions of the front end, and in dag.c. I have attempted that change several times, but I couldn’t find a stable configuration yet.
2. The handling of function call results uses up a register instead of using EAX directly. This needs some small changes in enode.c and expr.c, and in dag.c
3. The rules for assigning registers should be simplified, and the block-move / division operations should work without the contortions needed now. This will be one of the top priorities for the next months.
4. Now that variables are held in registers, this information has to be written in the object file so that the debugger is aware of that. This hasn’t been done yet, so the debugger will not see those variables.
Compiler optimizations. A case study with gcc-2.95.2
When writing the debugger for gcc, I found a bug in the code generation of that compiler. This bug appeared when compiling the following code :
#define MAXPICKLIST 8
char *PickList[MAXPICKLIST];
void UpdateList(char *p)
{
int i;

i = 0;
     while (i < MAXPICKLIST) {
     	if (PickList[i] == (char *)0) {
          	PickList[i] = p;
               break;
          }
          i++;
     }
     if (i == MAXPICKLIST) {
/* The last assignment that this code specifies is
PickList[MAXPICKLIST-2] = PickList[MAXPICKLIST-1] 
or, in numbers:
PickList[6] = PickList[7] 
This is not respected in the generated code by gcc */
i = 0;
          while (i < MAXPICKLIST - 1) {
PickList[i] = PickList[i + 1];
               i++;
}
          PickList[i] = p;
}
return (0);
}
This code searches for an empty slot in the table, and if it doesn’t find it, it will shift the table to the left one position, making place for the new slot at the end of the table. We will concentrate in the second loop (in bold in the text), where the bug appears. 
To make the time difference measurable I changed the size of the table from 8 to 100,000 elements, and I called the loop 10,000 times.
The code generated by lcc for this loop is :
        xorl    %edi,%edi               (i = 0)
_$10:
        movl    _Table+4(,%edi,4),%ebx  (read table[i+1])
        movl    %ebx,_Table(,%edi,4)    (write table[i])
        incl    %edi                    (i++)
        cmpl    $99999,%edi
        jle     _$10
As you can see, it is a straightforward, very simple code.  We maintain the loop index in a register (edi in this case), and make one read, one write per pass.
Gcc, generates the following :
        xorl %ecx,%ecx
        movl $_Table,%esi
L10:
        leal 1(%ecx),%edx         (1) t1 = i+1
        leal 0(,%edx,4),%ebx      (2) t2 = t1*sizeof(int)
        movl (%ebx,%esi),%eax     (3) t3 = table[t2]
        movl %eax,(%esi,%ecx,4)   (4) table[i] = t3
        movl %edx,%ecx            (5) i++
        cmpl $100000,%ecx         (6)
        jle L10
Obviously this is an optimizing compiler… the code generated is quite complicated ! But, is it really faster ?
Note that for adding one to a register it uses leal 1(%ecx),%edx. Clever, you add 1 storing the result in edx.
1) Then, it loads the effective address of 4*index into ebx.
2) Finally, it access the table and puts the table element in eax.
3) Stores the table element into the index pointed by ecx. Note that edx contains the index + 1, and ecx contains still the old value.
4) Now the counter is incremented by copying edx into ecx, the counter
5) Comparison, here there was a bug since sometimes this upper bound is not correct. But let’s forget this, this is not so important in this context.
I think that the obvious point here is the complexity of the generated code.

I decided to measure the speed of this « improvements ». I wrote a test function using the code generated by lcc, another one with the code generated by gcc, and a third one with hand optimized assembler.
The results were the following :

D:\lcc\src\test>test
lcc: 12.9 seconds
gcc: 20.0 seconds
optimized assembly: 12.9 seconds

The code generated by gcc is almost twice as slow as the simple minded code generated by lcc. This has several reasons :
The code generated by gcc performs many unneeded operations.
It uses too many temporary variables.
It maintains two parallel counters instead of one.
Why this situation ?
Gcc is a popular freeware compiler. Many people have worked on it, and many have added code to it. Most of them want to be remembered for what they left in there, not by the number of things they erased… so nobody ever takes the time of simplifying the code, erasing unnecessary or buggy routines, etc.

But erasing unnecessary routines, simplifying the code, etc, are things needed by any software. It is not possible to always add code. We must get used to erase code too. When this cleanup work is not done, the software as a whole gets so complicated and buggy that nobody ever can fully understand how it works. It becomes slowly more and more difficult to maintain. The maintainers of gcc are really afraid of touching things, since the interactions between the dozens of passes and optimizations are beyond their understanding.

I sent an e-mail to bugs-gcc@gnu.org and asked them if all this complexity is at all necessary. The answer I received is revealing :
> It would take even more code to disable this transformation in this
> case and cases like this, leading to an even larger compiler and
> buggier compiler...

Well, this has allowed that the simple optimizations of lcc-win32 arrive at 90% of the speed of fully optimized gcc.




The intrinsics interface
In the lcc discussion mailing list, we had a very heated debate last December about in-line assembly. I defended the point of view that in-line assembly is very useful, and can and should be used in any C program.

Now, several moons later, older and wiser, I think that the best thing would be to have the money of the cake and eat it too. The solution is to combine the efficiency of assembly language within a high level framework using the compiler to recognize pseudo functions, which will be inlined to its assembly instructions counterpart.

All the MMX calls are done this way.

The choice of each intrinsic is somewhat arbitrary. I didn’t want a full-blown interface that would mean you program assembly language in ‘C’. I choose some instructions from the many this CISC machine offers, and I am open to suggestions from your part concerning instructions that you would like to add. This interface is realized in the file ‘intrinsic.c’, in the compiler sources. For the prototypes for this pseudo functions see the file « intrinsics.h » in the include directory of the distribution.

For the documentation of the mmx functions see the Appendix 2

The intrinsics (non-mmx) recognized by lcc-win32 are:

Table 1: The intrinsics of lcc-win32
Name
Description
_rdtsc(void)
Returns a long long integer (64 bits) containing the number of cycles that the machine has done since it was turned on. Since this counter is automatically incremented at each cycle, to get a time in seconds you have to divide by the clock speed of your machine. For example if you divide the value by 166 x 1e6 you get the number of seconds elapsed for a 166 MHz machine. This intrinsic will use up some cycles for converting the 64 bit value into a floating point number, so there will be an overhead of at most 1000 cycles: at 200 MHz this should be 5 millionths of a second...
_bswap(long)
Returns the byte swapped long integer
_fsicncos(arg,cos *)
Returns sin(arg), and stores the cosine in the address pointed by cos *.
_fcos(double)
Returns the cosinus of its argument
_fsin(double)
Returns the sinus of its argument
_fldpi(void)
Returns the constant pi in floating point format
_fldl2e(void)
Returns the logarithm base 2 of e.
_fldlg2(void)
Returns the logarithm base 10 of ‘e’
_fldln2(void)
Returns the natural logarithm (base e) of 2.
_carry(void)
Returns the carry flag as an integer. This value is VERY volatile, since all calculations set/unset it. You shouldn’t assume that the value returned is the value of the last C instruction done, since the lcc’s optimizer could re-arrange the instructions
_fistp(arg)
This will return a long integer from the given double using the rounding mode that is in effect at the time of the call. Normally this should be rounding to nearest, since lcc-win32 never changes this setting. This allows for very fast rounding. It must be remembered that to satisfy the rules of ANSI C, lcc-win32 is forced to set the rounding to truncation, make the rounding, and then restore the original mode. This can be avoided by using this intrinsic function to round floating-point data.

int rint(double) 
Rounds the given floating point number to an integer using the current rounding mode. By default, the rounding mode is round to nearest. To use this, you should include <math.h>
_bsr(long)
Returns an integer with the index of the first non-zero bit in the given integer, starting with the most significant bit.
_bsf(long)
Returns an integer with the index of the first non-zero bit in the given integer starting with the least significant bit.


Implementing the operators redefinition in lcc

The C language has been more or less stable since its last major revision with the introduction of function prototypes and other improvements with C89. The latest standard, C99, adds many necessary things but fails to address the modifications needed to the language to make it less error prone. It is thought implicitely, that C programmers should become C++ programmers, and have to give up the simplicity of C to get a monster language that a few people in the world fully understand.

The situation where there is only a primitive language, frozen for all eternity, and a monster language at the other side forces people to leave this non-alternatives and look elsewhere. Most of the popularity of the Java language arises precisely from the fact that it is a less complex language than C++, maintaining some superficial similarity with C.

As far as I know, lcc-win32 is the only C compiler being actively developed. All other compilers that I know of are C++ compilers, where developments are done exclusively in the C++ side. I believe that C is a viable language by itself, and that it could benefit from the latest experiences in other languages and from progress in software engeneering in general.

The objective is to add some key features that would make C programming safer, and less painful than what is now.

Array bounds checking would eliminate nasty memory overwrite bugs, a real nightmare of C programming.
A garbage collector would easy the memory related problems we all know: keeping exact accounting of memory chunks is a tedious and error prone work, better suited for machines to do.

I decided then, to add this features to the implementation of the C language I distribute: lcc-win32.

To my surprise, the implementation required very little modifications to the source code of the compiler. Only a single small file, (called operators.c) was added to the distribution. When the operator keyword is detected by the front end (in decl.c), a list of operators overloaded is maintained, and at the appropiate places the corresponding function call is generated. In most cases this was quite easy to do, since I had just to insert the corresponding call before emitting the error message that was supposed to be emitted when something like 

	struct A + struct B

was seen.

C and C++
After implementing operator overloading, many people asked about other features of C++. Here is the explanation why some of those features will not make it into lcc.
Function overloading.

Function overloading is a C++ feature that allows you to define several functions with the same name that are differentiated by the compiler using their arguments list.

This way you can define:

	print(int);
	print(char *);
	print(double);

etc.

The justification for this is given in “The C++ programming language” by B. Stroustrup, in the paragraph “Overloaded function names”.  It is interesting to note that the paragraph begins with: “Most often, it is a good idea to give different functions different names”, but then… Bjarne continues: “The overloaded function names are primarily a notational convenience”.

Convenience? Convenience for whom? For the writer of the program obviously, not for the maintenance programmer that has the job of figuring out which of the zig “print” functions is being called at this concrete call point!

I have the old fashioned opinion that a language shouldn’t be only easy to write, but also, and that is equally important, easy to read!

The problem is that it may not be obvious which overloaded function is being called, and that the algorithm for the compiler in C++ runs for several pages! And the reader of the program is supposed to redo that algorithm in his/her head when reading the program at each call site?

A nightmare. Compared to this, the famous “computed goto” statement of Fortran is much clearer! This feature leads to “write only” computer languages, i.e. languages that are easy to write programs with, but that are impossible to read after the program has been written.35

The implementation of this feature in lcc-win32 is designed to allow for easy reading. The overloaded functions must be marked with the « overloaded » marker, so it is clear that this particular function is special. 

Other “hidden” but important cost of this feature is that in C++ forces the compiler to figure out a name, an “internal” name, for each function defined. Since the compiler can never know if in another module a new print function with different arguments is defined, it must rename all defined functions without exception.36 This feature would then provoke a host of changes that are absolutely unjustified. One of the main design issues in the implementation of overloading in lcc-win32 has been to avoid this feature at all costs. 

Stroustrup says about this way of doing things:

“Compared to the overloaded print(), we have to remember several names and remember to use those correctly. This can be tedious, defeats attempts to do generic programming and generally encourages the programmer to focus on relatively low-level type issues.”

Lcc-win32 tries to let you have the cake and the money of the cake too !  You avoid the complexities of C++ with the additional problem of the class hierarchy that compounds the complexity of function overloading, but you let the computer figure out most of the names it needs to implement a generic function.

This is not really generic programming in its real sense, since we are calling different functions, even if we are using the same name. This fact is barely hidden by the compiler machinery that tries to give the user of the language this impression, but as we will soon see, this impression can disappear very quickly.

Another problem with the overloading scheme, is that since the decision which function will be called is passed to the compiler, there is no way to call print_int(double), when we happen to store an integer value in a double. We can make a cast, but then… it is much easier just to call that print_int function in the first place isn’t it?

Up to now we are considering simple functions with only one argument. What happens when several arguments are given? Then, the real nightmare begins:
Consider:

int     pow(int,int);
double  pow(double,double);
complex pow(double,complex)
complex pow(complex,int);
complex pow(complex,double);
complex pow(complex,complex);

Wih this scenario, the call

	double d = pow(2.0,2);

will be rejected by the compiler!

The reason is that the poor compiler can’t differentiate between pow((int)2.0,2) and the other possible function pow(2.0,(double)2).

Stroustrup says:
“Some C++ novices get irritated by the ambiguity errors reported by the compiler. More experienced programmers appreciate these error messages as useful indicators of design errors”.

Well, wait a minute, what about the need to avoid to “focus on relatively low-level type issues” that he just talked about several lines before? Forgotten?

Function overloading should relieve us from those “low-level” issues isn’t it? 

No! It is the contrary that happens. Those low level issues get worse, and take more time to solve. We can’t just take the time needed by one programmer to write the stuff, we have to take into account the time needed by him and all others to get hold of those strange results, debugging, finding which function is called etc.

Other problems complicate the situation even further: What happens when a pointer to the function '‘print'’is taken, and passed around? Will the match take the right overloaded function? It all depends on the right declaration of the function pointer, of course. But then, we are forced to pay a LOT of attention to the exact types of that function pointer, precisely what Stroustrup said at the beginning we should try to avoid, and the very objective of function overloading!

Conclusion: Function overloading complicates both the programs and the compiler for  a very limited usefullness in the general case. This is a feature to avoid, if possible. 

The implementation of lcc-win32 was more or less forced because the need to implement easily constructors for data types that can receive several forms of initialization arguments. For instance :

typedef struct tagExample {
	char *n ;
	int a ;
} EXAMPLE ;

EXAMPLE * overloaded newExample(char *) ;
EXAMPLE * overloaded newExample(int) ;

This is easier than

EXAMPLE *newExampleFromInt(int) ;
EXAMPLE *newExampleFromString(char *) ;

Specially when the structure has many different fields, the number of names to remember increases too much. In this cases it is handy to have a single creation name that branchs into different functions, according to the creation parameters given.


Default function arguments
What are ‘default’ function arguments?

To keep the above example, it would be nice for instance, if the function ‘print_int’ would take an extra argument, the base in which the given integer should be printed.

The problem with this, is that in 99% of the cases that base will be 10, so we would have to write an unnecessary argument at most calls.

The C++ solution to this problem is to introduce default argument, i.e. you would write:

	print_int(int n,int base = 10) { /* … */ }

At the call site we would invoke the print_int function like this:

	print_int(n);

Only in very rare case we will use
	
	print_int(n,16); or print_int(n,2);

There are several ways to achieve the same result in C.

1. #define print_int_base10(n) print_int(n,10)
2. void print_int_base10(int n) { print_int(n,10); }
3. setbase(10); print_int(n);

Solution 1: The pre-processor is not “in” any more. Fads come and go, and year 2000 the pre-processor is considered harmful. Why? It is simple and in many cases very useful. But simple and useful things (as anything) can be over-used, and Stroustrup warns against it. This solution is equivalent to an inlined function, so it costs in extra space at each call site.

Solution 2: Make a cover function for the often used argument. This has the advantage that the program is much clearer, and hints to the reader that printing in other number bases is possible. On the contrary, print_int(n) with default arguments doesn’t ever give the reader the hint that another argument can be used. There is no way to know unless you look up the definition of print_int. This solution  is space conservative, since the passing of the extra argument is avoided in most calls.

Solution 3: Use a global variable. See solution 1. Global variables, as many other simple and useful things are ‘out’. True, they are not thread safe, and used too much they can make program flow very confusing. But a simple solution like having a current output base, using a function to read/write to it can be very effective. Besides, global variables can be protected by semaphores. Used with care they are as good as other solutions… This solution is very space conservative, since the extra argument is never passed. The variable needs to be changed only when the base changes.

Conclusion: Default arguments do not bring anything really useful. They can be easily avoided.

Namespaces
In C++, you can use “namespaces”, i.e.  you can define a scope that will automatically hide all the names defined within it, and be accessible from outside only with specific qualification. For instance you can define:
	namespace debug {
		int debug_print(Mystruct *p);
		int debug_active = 0;
	}
later on in your program you can access those name qualifying them with their namespace prefix:

	debug::debug_print(p);

There are several ways of implementing an equivalent construct in C.
1. Each file or compilation unit provides an automatic namespace. Only names that are not declared static are exported.
2. You can easily prefix your identifiers with a standard set of letters to avoid name clashes. For instance you could use the prefix appl_debug to all exported names that refer to debugging in your application.
3. Use the import/export “wizard” of Wedit to easily tune which names are exported, and which should be kept private in a module.

The cost of implementing namespaces is quite high: the compiler would have to rename all functions (the same cost as function overloading), without really gaining much in program clarity. A solution done “by hand” or with the aid of the IDE is much easier for everybody: the compiler, that is simplified, and the user: another construct less to learn and be aware of.

To export definitions from a module, place all those definitions in a common header file. All private definitions should be placed in the beginning of a .c file, and declared static. This way, we achive exactly the same result without any new constructs.

Example:

We use the same example as Stroustrup’s ‘lexer’ example, used to justify the namespace construct. In C, you would place in the public header file a single definition:

file lexer.h:
	double Parser_interface_get(int);

This file would be included by all clients that want to use the module. Only a small set of symbols would be exported, prefixed by “Parser_interface”.37
Sometimes, as Stroustrup remarks, it is necessary to have a double interface: one for the clients of the module, and another for the people implementing the interface. In that case, it is very easy to make another header file, say “lex_intern.h”, that contains the internal definitions needed by implementation modules, and is not exported to the general public. This is another variation in the “simple is better” argument. All this works, and allows us to avoid the namespace construct, the “alias” directive38, and the using directive.

Namespace composition can be trivially achieved in C by including several headers defining different interfaces. Note that there is no possibility to resolve a name clash at compile time, what implies that the two interfaces must be compatible with composition: they shouldn’t have common names.

Note, too, that the resolution of the name clash can’t be done without modifying one of the conflicting names. The most trivial solution is to add a prefix, a solution that will always work. In C++ you use a “using” directive to disambiguate the name, i.e. you tell the compiler which definition to prefer. This could be a useful addition, since it would allow the compiler to resolve ambiguities directed by the user. A “using” directive would take a header name and a symbol, and would resolve any name conflict that way. But this would introduce yet another feature into the language. For the time being, this is not implemented.

Note that in C++ function overloading works across namespaces, so that you could introduce several unknown complexities in your software by importing a namespace. In C you have no such troubles. If there are any name clashes the compiler will warn you.

Conclusion: In general, in C you have a single point of definition for all names in use in a compilation unit. This rule that contributes a lot to C’s simplicity and readability would be destroyed by namespaces without any big practical gain.

Avoiding complexity

The current trend in C++ programming seems to be: 

Do not use a clear and simple construct when you can build an obscure and complicated one.

Simple things, simple notation leads to programs that can be understood by most people. This is very bad, and essentially against information hiding, an old OO principle39. You can always add an unexpected construct, a hidden “gotcha”, and a useless complication to make the maintenance programmer go nuts.

An extreme example of this way of thinking is the paper “Techniques for scientific C++” of Todd Veldhuizen. One of the chapters of that document treats the following problem: Adding the contents of 3 tables.

If you use operator overloading for arrays, the expression

Vector<double>40 a, b, c, d;
a = b + c + d;

will generate code for making a temporary array of b+c, then adding to that temporary array the contents of d. All those temporary arrays produce a lot of data movement between memory and the CPU, and performance suffers.

The solution of course is to write:

	for (int i=0; i<N; i++)
		a[i] = b[i] + c[i] + d[i];

But this solution is not very “elegant”. Anybody would understand this kind of simple stuff. Let’s do better. And Todd starts an incredible explanation of “expression templates”, i.e. parse-trees that are built from pairs of types by the compiler, and then inlined… After several pages of very abstract C++ code and many incredible contortions, he comes to: (I quote)

[snip snip]

So the end result is:

	for (int i=0; i<N; i++)
		a[i] = b[i] + c[i] + d[i];

Nowhere is explained in the paper why this contortions are needed to arrive to the same result that could have been obtained with much simpler notation! What is basically wrong with writing the loop above in the program text?

Well, maybe this is just an example of expression templates, and maybe there are some situations where this complexity is needed. Unfortunately, the author never explains those cases, so we are left wondering what is so wrong with the simple loop above.

The Pentium SSE/SSE2 back-end

Intel decided at the end of 2000/beginning of 2001 to strip down the very complex architecture used (with so much success) until now, and speed up the clock, up to 1.5GHZ or even more in later models.

I decided to implement a new back end for this machine, and started working on this part in September 2001.

The new machine features some impressive changes, that make it quite an improvement over earlier processors. The new 128 bit registers xmm0 to xmm7 were extended to accept all MMX instructions, and could for the first time work with double precision numbers, what make them a serious choice for improving lcc-win32 floating point performance.


The ‘pedump’ utility
All along our discussions of this feature or that feature of the assembler, the linker, whatever, we have come across this utility. Here, I will describe a little bit more how it works.
Matt Pietreck wrote the original pedump that was included in his book: Windows 95 programming secrets. I have added many new binary formats to the code, but kept the original structure that Matt designed.

The sources are located in \lcc\src\pedump. They consist of the following files:

com.c. This module dumps the typelibs for activex/ole objects. It uses the ItypeLib interface for getting the type library, and the ItypeInfo interface for getting the data out of the type lib. It will show recursively all interfaces defined in the dll or type library.
disasm.c. This module disassembles the object code. Parts of this module are used in wedit’s debugger to show the machine instructions.
cplus-dem.c . Demangles gcc mangled names. This part is only necessary if you include the stabs debug info dumping module.
exedump.c. Dumps an executablefile. Here is the code for dumping the debug information that only appears in executable files (the Sst* tables described in various places in this documentation), and other constructs like the relocation table, that exist only in executables.
objdump.c. Dumps an object file. The object file relocations are of course different than the executable file relocations. Their format is analyzed here. You will find in this module the library dumper, that understands all library formats of Win32: the traditional one, and the new import library format.
resdump.c. Dumps a resource file. This part is just thought as a debugger for the resource editor. It could be better…
common.c. Common routines for reading COFF object files and dumping the debug information. Here you will find extensive comments for each function. This is one of the big files in the pedump module, containing the header dumpers, the debug info dumpers, and many others.
elf.c. Dumps an elf executable format. Useful only in Unix.
stabs.c. Dumps the debug information that has the stabs format.  Useful only with gcc.
debug.c. Dumps the debug information in the stabs format.
pedump.c Main module. The routines for dumping .dbg files are here too.

You should define the keyword ‘UNIX’ if you want to include the routines that use the stabs/elf formats. Normally this is not very useful under the windows OS.
To build pedump go to the \lcc\src\pedump directory and type ‘make’ at the command prompt.
You can use pedump to dump the debug information of any program that uses the NB09 Microsoft standard. Specifically, when using the MSVC compiler, you should specify the –z7 compiler option.


The linker
Motivation
When I had my assembler working, I could test it with Microsoft’s linker. For the first time I could compile Wedit’s source code with lcc and I could at last experience the thrill of looking at a program that was built with this first, embryonic system.

But I wanted a self-contained tool. It would be annoying to tell the users: well folks, you have to buy MSVC and use the LINK command. They would surely answer: ‘If I buy MSVC, I do not need your system at all...’

So I started working in a linker.

The tasks a linker has to do are the following:
1. Consolidate all sections from all its input files into a single section. This means that all .text sections should be thrown together in a single .text section, all .data sections should be consolidated in a single .data section and so on.
2. Build an executable with the sections it finds in the specified object files or in the libraries it searches according to Microsoft’s PE specifications.
3. Link all the debugging information consolidating the definitions repeated several times within the object files into a single .debug section, and build a debug directory using Microsoft’s NB09 specifications. This is done by Microsoft’s CVPACK utility. within the MSVC system.
4. If any of the input files is a resource file, convert it to COFF format and link it with the rest of the object files.
5. Build the table of imported functions from system/user dlls.
6. If the user demands a dll, build the .reloc and .edata sections, with the relocation data and the export data.
The format of the PE Executable.

Figure 1. 
An executable file contains basically two things:
Image data
Instructions for the loader
Under Win32, Microsoft adopted the COFF format that we have already reviewed in the chapter about the assembler. Executables follow this format, adding several sections that we will discuss in detail later. 
The ‘Dos stub’
Windows is a better DOS. But that venerable ‘system’ is still with us, even years after the last version was out. Microsoft Disk Operating System must and should be supported, even if we are in 98, and the original MSDOS with 32K RAM would fit into the cache of today’s processors! Still, this commitment to preserve the user’s investment in software has made popular this environment, so we should take that seriously.

The very first part of an executable is then, a ‘Dos stub’, i.e. a program that will just print out ‘This program cannot be run in Dos mode’ and exit. This is a constant part of the executable that the linker writes at the beginning of the exe file. More sophisticated linkers have an option to use another ‘stub’ dos executable, instead of the standard one. I have thought for a moment doing this, but later discarded it, since contradicts the KISS principle. Why complicate things?
The File header
Then follow the interesting parts. The file header, the ‘optional’ header (required for executable files), and the data for each section. Here is an example of the output of the dump utility for this header:
File Header
  Machine:                      014C (i386)
  Number of Sections:           5
  TimeDateStamp:                32FBD489  (Sat Feb 08 02:19:05 1997)
  PointerToSymbolTable:         00000000
  NumberOfSymbols:              00000000
  SizeOfOptionalHeader:         00E0
  Characteristics:              010F
    RELOCS_STRIPPED
    EXECUTABLE_IMAGE
    LINE_NUMS_STRIPPED
    LOCAL_SYMS_STRIPPED
    32BIT_MACHINE
The linker at the end of the linking process writes this part, just before it exits. The reason is simple: the linker knows this information only when the whole file has been built, all symbols have been counted (and relocated) and the position of each item is known.

You will find in the source code of the pedump utility, in the file common.c, the function ‘DumpHeader’ that parses this table and prints its values.
The ‘Optional’ Header
Here is an example for this header:

Optional Header
  Magic                              0x10b        267
  linker version                     1.01
  size of code                       0xE200       57856
  size of initialized data           0x1E00       7680
  size of uninitialized data         0x1000       4096
  entrypoint RVA                     0x113D       4413
  base of code                       0x1000       4096
  base of data                       0x10000      65536
  image base                         0x400000     4194304
  section align                      0x1000       4096
  file align                         0x200        512
  required OS version                1.00
  image version                      0.0041
  subsystem version                  4.00
  Reserved1                          0x0
  size of image                      0x15000      86016
  size of headers                    0x400        1024
  checksum                           0x0
  Subsystem                          0x3 (Windows character
  DLL flags                          0x0
  stack reserve size                 0x100000     104857642
  stack commit size                  0x1000       4096
  heap reserve size                  0x100000     1048576
  heap commit size                   0x1000       4096
  loader flags                       0x0
  RVAs & sizes                       0x10

Data Directory
  EXPORT       rva: 0x0         size:        0
  IMPORT       rva: 0x14000     size:     1794
  RESOURCE     rva: 0x0         size:        0
  EXCEPTION    rva: 0x0         size:        0
  SECURITY     rva: 0x0         size:        0
  BASERELOC    rva: 0x0         size:        0
  DEBUG        rva: 0x11000     size:       84
  COPYRIGHT    rva: 0x0         size:        0
  GLOBALPTR    rva: 0x0         size:        0
  TLS          rva: 0x0         size:        0
  LOAD_CONFIG  rva: 0x0         size:        0
  unused       rva: 0x0         size:        0
  unused       rva: 0x0         size:        0
  unused       rva: 0x0         size:        0
  unused       rva: 0x0         size:        0
  unused       rva: 0x0         size:        0
  heap commit size                   0x1000       4096
  loader flags                       0x0
  RVAs & sizes                       0x10

The different fields are:
‘Magic’: Just that, a number that HAS to be there to verify that this is indeed an executable file.
Linker version: Lcclnk sets this to its version, 1.2 now, 1.01 in the example shown.
Size of code: The total size of the .text section.
Size of initialized data: The total size of the .data section. When you write in a ‘C’ program a variable (not a local variable that is allocated in the stack) but a global/static variable that is initialized, the linker arranges so that it points to a portion of the .data section.
Size of uninitialized data: The size of the .bss section. Here points any variable that is just declared, without any initialization. This .bss section is not written to the file. The linker just declares it, so that the loader will reserve at this address a portion of memory that will be zero filled.
Entry point RVA: The Relative Virtual Address of the entry point. This is simply the offset in bytes of the entry point minus the base of the image. The loader NEEDS to know this, since it will pass control to this address once the program is loaded in memory. If, for any reason, the linker doesn’t know the address of the entry point, it will abort the link, since the generated executable will never run.
Base of Code: An offset from the image base, where the .text section is located. Normally this is 4K. I suppose that this is to make the very first page of memory absent, so that the system can catch any writes to NULL pointers. If this weren’t the case, you could read from a NULL pointer...
Base of Data: Where the data of the program begins. This can be, as this example shows, the starting address of the .bss section. It depends on the program.
Image base: An offset from the start of the virtual address space, where this program is being loaded.
Section align: The alignment for each section. Lcclnk uses a 4K alignment, but this wastes some precious RAM. A way of eliminating this wastage would be to cram several sections in one, so that the alignment is not needed. For instance, we could pack the .bss section at the end of the .data section, saving the alignment of the bss section. If I have time and resources, this is definitely a thing to do for a better version of the linker.
File align: The alignment chosen by lcclnk is too big. I should experiment with smaller alignments like 16 instead of 512, its value now.
Required OS version: All programs linked with lcclnk will run in the Win32 environment. I was not sure what to put in there, so I settled for a value of 1.0. I do not think that the loader cares a lot about this value, but this may change in the future.
Image version: This is a user defined value that defaults to 0.00. With the -version option of lcclnk, you can put a value in here.
Subsystem version: Again, I didn’t know what value put in here, so I settled for the same value as LINK: 4.0
Reserved1: Always zero.
Size of image. The sum of all sections.
Size of headers. Lcclnk will always put a 1024 in here.
Checksum: Lcclnk doesn’t support this value, because I haven’t found the algorithm needed. It should be in ImageHlp.dll, according to the documentation. Looking at the exports of that dll, you will find indeed a ‘CheckSumMappedFile’ function. Now, this is another thing that future releases will cover. In any case you need that checksum only of you are writing a device driver, or similar stuff. If you do it, just send me a mail and we will see how this works.
Subsystem: Lcclnk has a -subsystem option. The value you enter ends up in here. 
Dll Flags: The documentation marks this as ‘obsolete’ so I put always zero in there.
Stack Reserve size: The maximum size the stack can grow. Lcclnk sets here 1MB, what should be enough for the most demanding applications. There is no option for configuring this however.
Stack commit size: The amount of real RAM that the system will commit for you before the program begins to run. You can set this value with an option in lcclnk.
Heap reserve size: Same as Stack reserve.
Heap commit size: Same as Stack commit.
RVAs and size: This is a table of 10 positions, each with a relative virtual address and a size. Lcclnk uses the following:
EXPORT: The .edata (exports) section. This is needed for dlls only, and it is described further down.
IMPORT: The rva of the import table and its size. This is the same as the .idata, and consists of the names of the imported functions from other dlls. All programs have this table, because you will surely need to import from the C run time library or Kernel32 or other basic system dlls.
RESOURCE: If you have a windows program with resources you will use this entry.
DEBUG: The debug information address and size.

The function ‘DumpOptionalheader’, in the source file of pedump common.c, reads this table and shows its values. In the linker sources, this is done in the “WriteExeFile” function, in lcclnk.c.
Standard sections

The linker builds the image based upon the data found in the object files it uses: each section of the object file will be assembled in a section of the executable file. All the .text (code) sections will build the final .text section of the executable, all .data sections are gathered together in a single .data section, etc.

This sounds simple but is not very easy to do. I spent a lot of time in the linker, trying to do things that are very easy said, but no so easily done. For instance, the linker just puts the different sections in the order of the object files given in the command line. Taking a concrete example, if you are linking ‘foo.obj’ and ‘bar.obj’, the text section of foo.obj will be taken first, and then the text section of the file ‘bar.obj’. But then we have to worry about alignment between different sections (I do not use any), and other complications like the fact that the startup object file must be first in the order, because it contains special sections for building the import libraries, etc.

The standard sections that lcclnk understands and uses are the following:
.text: The code of the program. These are sequences of bytes that the processor you are using ‘understands’ This bytes are interpreted by the processor as a series of instructions, executed, etc. All the executable and all computer processing comes down to this: a series of numbers that the processor executes in an absolutely stupid way. It has no ‘soul’ nor free will, nor nothing else but this never ending desire of doing what is being told to do!
.data Here come the initialized data items, i.e. data that is know to the program at program start.
.bss: Non initialized data. This is just RAM space reserved for future use by the program at the program start. This name ‘non-initialized’ data is a misnomer since this RAM will be cleared to zero by the program loader.
.idata: The imports table. This is a table constructed by the different ‘import libraries’ and several sections in the startup code, that tells the program loader which dll to search and which functions in that dll to link at load time.
.edata: The exports table. In the case of a dll, this tells the program loader, which functions this dll exports.
.rdata. Several small information pieces about the executable, like the position of the Coff debug header, and other trivia. Not really necessary, and I am thinking that in a future version of the linker I could well just ignore it.
.reloc: Relocation information telling the program loader which sections to fix if the program can’t be loaded at its default load address, the Image base value we discussed above.
.rsrc: Resources of the application.
.reloc: Relocation information for the program loader. This is used only in Dlls.
.debug: Debugging information. The program loader at startup does not load this section.
The linking process (overview)
Roughly, the whole thing goes like this:
Process all command line options.
If any file in the command line has a .res extension, assume it is a resource file and convert it to an object file.
If any file has a .def extension process it as a .def file containing the names of the functions that will be exported from the dll being built.
Open all files given in the command line.
Read in all sections from all object files and calculate the size of each of the output sections. Each output section is just the sum of its component sections.
Store all symbols encountered when reading the object files into the global linker hash table.
Look for undefined symbols, and search in the libraries for them.
Perform the symbol table construction, relocate the line numbers and auxiliary entries.
Perform the relocations, writing out all relocated sections into the executable. At this step all symbols should have been read. If a relocation points to an undefined symbol we can’t go on.
At each relocation above save the position of the relocation for the building of the .reloc section if this is needed.
Link the code view debug info. This steps eliminates redundant definitions and compacts the debug info. If the file doesn’t contain CV debug info, the linker tries to figure up some of that information using the COFF symbol table info.
Write the headers (file headers, optional header, etc).
If the -x options was indicated, scan all global symbols to see that they are used at least once. Print a report.
If a map file was indicated, write the map of the executable generated.
We are done, close everything and get out of the way!

The linking process: detail
Parsing the command line
This is not very interesting. All command line options are listed at the end of this chapter. The file name expansion is done at this stage. Here the type of the input file is deduced from the file name extension, i.e. .res files are handled different than normal object files. File name expansion is done in expand.c that returns a table of all the files that correspond to a given specification.
Convert the resources to object files
Well, this is not like parsing the command line options. Definitely not. It took me more than two months to write the ‘cvtres’ utility, to convert resource files to Coff object files. Basically this builds two tables, one with a series of pointers and directory structure, and the other with the actual data I read from the resource file. This two tables are merged into a .rsrc section by the linker.
Parsing and processing the .def files
This isn’t especially exciting. I build a linked list of exports that are read from the .def file. Of course, the usual problems have been detected after the first release... I hope I parse the .def files OK now. 
I expect a file containing just:
First line: “LIBRARY”  Name of the dll, without the extension.43
EXPORTS keyword
A list of name with 1 name per line specifying the symbols to be included in the export table. I accept the two identifiers separated by the equals sign, so that you can rename a symbol for exporting it, maybe eliminating decorations, etc.
As time passd, I have added some missing stuff like accepting comments (they start with a ‘;’) or accepting (and ignoring) things like “description” or other keywords from the 16 bit dlls. All this is read into a linked list with the following structure:

typedef struct tagExportList {
        struct tagExportList *Next;
        char *Name;
        char *VisibleName;
        int Ordinal;
        unsigned long Address;
        unsigned long Flags;
        struct LinkerEntry *h;
} EXPORTLIST;
#define EXPORTFLAG_ISTEXT       1

I keep the name, optionally the visible name that I will write into the exports table, the ordinal, even if lcclnk doesn’t use that, the actual address of the export, a flag telling me whether this is something that lives in the .text section or not, and a pointer to the linker symbol structure so that if needed I can get any information from this symbol that I need when writing the export table.

The bulk of the work obviously isn’t parsing the rather straightforward .def files but building the .edata section in the executable. This is done in ‘BuildEdataSection”  function. That function goes through the exports list, filling the address field, that has to be passed to the program loader. Then I allocate a buffer and write it all.
The edata section contains several tables, that I allocate contiguously.
 
Table name
Description
Export directory table
A table with just one row (unlike the debug directory). This table indicates the locations and sizes of the other export tables.
Export address table
An array of RVAs of exported symbols. These are the actual addresses of the exported functions and data within the executable code and data sections. Other image files can import a symbol by using an index to this table (an ordinal) or, optionally, by using the public name that corresponds to the ordinal if one is defined. Lcclnk doesn’t support the linking by ordinals, so the numbers it emits here are mainly for compatibility.
Name pointer table
Array of pointers to the public export names, sorted in ascending order. Sorting is done in the “SortExports” function (lcclnk.c).
Ordinal table
Array of the ordinals that correspond to members of the Name Pointer Table. The correspondence is by position; therefore, the Name Pointer Table and the Ordinal Table must have the same number of members. Each ordinal is an index into the Export Address Table. I substract the base of the ordinals to all numbers given, but I have never verified that this is actually correct. Beware.
Export name table
A series of null-terminated ASCII strings. Members of the Name Pointer Table point into this area. These names are the public names through which the symbols are imported and exported; they do not necessarily have to be the same as the private names used within the image file. This explains the equals sign in the .def files.

Open all files given in the command line
This needs a little reflection. As with the compilation process, the linking process is limited by I/O. It is essential that the linker reads the information from disk in the most efficient manner. Since I am not a disk guru, and besides I wouldn’t think that a linker should mess with the type of disk it is running in, I leave that to the operating system. Let’s face it: the operating system will have done a much better job of tuning its I/O than I could ever do. So I use this feature of Win32 called memory mapped files. This means that I use the swap file for all my input output, so that in fact the OS does all input output for me! This speeds enormously the linking process.

The linker that builds its symbol table as it goes, processing all object files. The embedded directives emitted by the assembler as .drectve sections, are processed. For the time being, the compiler only uses this  for __declspec(dllexport). The linker processes those records, and updates the exports list accordingly.

Each object is scanned, and the symbol table of each object goes into the global linker symbol table. Basically there are within the C language only two types of scopes: local to the compilation unit (object file) and global to the whole project/executable. This is not a very sophisticated arrangement, and I have discussed within the lcc mailing group the possibility of introducing ‘name spaces’, i.e. spaces of scopes that could alleviate the problem of having all modules share all global names. For a variety of reasons my proposal was rejected, so we stick to C language conventions for the time being.

The contents of the text, data and bss section of each object file are added up to its containing section, so at the end of the process, we know exactly how many bytes will be in each section, and the position of each global symbol within its section. For instance if the symbol i_table is located at the address 50 in the data section of module 3, and module 3 is starting at address 250, the address of  i_table will be 300.

A weakness of lcclnk is that it doesn’t know (or it doesn’t try to guess) what to do with sections that aren’t named « text », « bss »,or « data ». It could obviously use the section flags to figure out where a section should go. In the case of a general-purpose linker this would be highly desirable. Lcclnk is not a general-purpose linker however. It is designed to link the object files generated by lcc, so this schema it is enough for its needs.

A special treatment is done with the .bss section, since its contents are not read in anywhere: they are just implicitly defined by the sum of the .bss sections of all object files.

Symbols
Symbols are just aliases for memory locations within the program. For people, it is easier to refer to « strcmp » than to 0x479887. The symbol « strcmp » then, is used to indicate the memory location 0x479887.

Symbols can refer to unknown memory locations, i.e. memory locations that will be resolved later in the linking process. The linker can see the first time a symbol just as undefined external symbols. It will add it then, to the undefined set of symbols.

There are then, the following sets of symbols during the linking process:
The set of defined symbols, not in the common section. All this symbols have a fixed address already.
The set of symbols in the common section
The set of undefined symbols that have been seen as externals but where the definition is not yet processed.

Symbols can be moved from the undefined set, into the common or into the defined symbols.
This needs some explanation. Suppose you have in the file file1.c the following declaration:

int iconst;

The symbol ‘iconst’ will be assigned to the common section that is initialized to zero at program startup. But consider what happens if you include ‘file2.c’ in the link, that contains the declaration:

int iconst = 53433;

The linker will move the symbol ‘iconst’, from the common section to the data section. The definition in file1.c will be lost.

And there are worst things that can be done:
file1.c:
int buf[256];

file2.c:

int buff[512];

The linker will leave ‘buf’ in the common section, but will set its size to the bigger value, i.e. 512. This is harmless, but beware that you make a definition in a file3.c

int buff[4] = {0,0,0,0};

Your table will have a size of just four positions instead of 512!!

The discussion about the common storage model
This issue has provoked heated debates in the lcc mailing list, especially when David Stes, came with his objective C compiler, where he needs this feature for initializing his objects. In earlier versions of the linker, I had a warning, when a symbol was moved from the common storage area to the data area. David wanted at all costs that the warning disappear. I argued that the following bug would be impossible to catch without that warning:

From jacob Tue Apr 28 11:53:30 1998
Subject: A case study.
To: lcc@cs.princeton.edu

Let's assume the following scenario:
In the file f1.c, I have code like this:
char *p;
int somefn(void)
{
        if (p == NULL) {
                doInit();
                p = "Initialized";
        }
        ....
}
Since p is in the bss, I can safely assume that its contents are zero at program startup.
I compile this, and it works without any problems. Several months later, in another completely unrelated file, let's call it f2.c, in the same program, I write:

char *p="Here is the bug David";

I compile, link, and everything seems OK, but... the program crashes! After several days of work, I realize that the function doInit() is never being called!!!
What happened???
That according to David proposition, the warning 'redefinition of p' was dropped!!!
The char *p was assigned to the character string, its contents weren't NULL at startup, and doinit() is never called.
Well, you see the problem?
The linker *should* warn about this. Because there is NO OTHER tool that can issue that warning!!! The compiler will NEVER detect this since it sees only one file at a time.
And this can be IMPOSSIBLE to find if the linker doesn't issue a warning!!!

David wasn’t happy with this, and he answered:


Date: Tue, 28 Apr 1998 17:20:13 +0200 (MET DST)
From: David Stes <stes@mundivia.es>
To: Jacob Navia <jacob@jacob.remcomp.fr>
cc: lcc@CS.Princeton.EDU
Subject: Re: A case study.

[ he cited the example above]
> Since p is in the bss, I can safely assume that its contents are zero at program startup.
>
No, you can't !

p is called a "tentative definition" of p, and it may very well be non-zero.

So, I discovered this issue about « tentative definitions ». I am not a lawyer, but programming language issues tend to become quite full of « legalese ».
Dave Hanson, one the authors of lcc, entered the discussion and he wrote:

From: Dave Hanson <drh@microsoft.com>
Date: Tue, 28 Apr 1998 13:33:43 -0700
Subject: RE: Re: A case study.

[ he cited the message from David, and then continued ]

For the record, the declaration for p is indeed a tentative definition, but that status persists only until the end of the compilation unit, i.e., the end of f1.c. Since there's no subsequent external definition of p, the tentative declaration acts exactly as if there was a file-scope declaration for p with an initializer equal to 0. (See Sec. 3.7.2 of the ANSI Standard, which I think is Sec. 6.7.2 of the ISO Standard). As a result, p is null at program startup--assuming there are no other similar declarations for p.

This example illustrates nicely a problem with the common storage model: You can't determine whether or not a declaration is also a definition by examining just the program text, and it's easy to get strange behaviors. In this example, there was only one definition, which passes without complaint from linkers. In the stricter definition/reference model, linkers would complain about multiple definitions when combining the object code for f1.c and f2.c. This example also shows why it's best to initialize globals, because linkers will usually catch these kinds of multiple definitions.

The common model also permits C's (admittedly weak) type system to be violated. I've seen programmers declare "int x[2]" in one file and "double x" in another one, for example, just so they can access x as a double and as a pair of ints.

For a good summary of the four models of external definitions/declarations, see Sec. 4.8 in Harbison & Steele, C: A Reference Manual, 4th ed., Prentice-Hall, 1995.

Dave Hanson

Since David needed this feature of the common storage model, I dropped the warning. I think objective C is a nice object oriented language, and wanted to support the work of David with lcc-win32.
Relocate all symbols
The next thing to do is to go through all symbols, and decide whether they will go into the final symbol table or not. Many of them are discarded, since they are local symbols of each compilation unit.44 Global symbols need to be relocated, i.e. the ‘value’ of the symbol has to be set to its final address. This is easy now that the position of the section that contains the symbol is exactly known: we just go through them setting the value field to the right number. The function that does the relocations is called RelocateSection().
Its algorithm outline is simple:
1. Read the relocation information from the object file.
2. According to the type of relocation, adjust the value of the symbol. The relocations supported by lcclnk are just a few: the pc-relative relocation (code 7, and code 20), the normal 32-bit relocation (code 6), and two types of relocations for the debug information, code 10 and 11.
3. Save the position within the executable file where the relocation is being done in the case of relocation type 6 (normal 32 bits relocation), to later build the .reloc section if this is needed. Normally this is needed only when generating a dll, since executables aren’t relocated under windows.

Line numbers, in their COFF variant have to be relocated too, if they exist at all. This is the same as for the symbols. We know the starting virtual address of the section the line number records refer to, so it’s a matter of a few additions and subtractions to be done with them. Lcclnk uses this COFF line numbers to convert them into a NB09 compatible format. Both line numbers formats are written to the executable file.

Build the symbol table
The final symbol table of the executable contains all global symbols of the program. This table will be generated only if the debug information will be included in the resulting executable file.
The format used is the same as the symbol table built for the object files, with some minor modifications. The ‘.file’ entries are processed, because their ‘value’ field needs to be the next symbol in the symbol table that is a ‘.file’ symbol, and this needs to be fixed at link time. In a similar way, the entries for the function COFF descriptions are fixed.
You will find in the source code of the pedump utility the function DumpSymbolTable, in file common.c, that prints the symbol table contents.
Relocating/building the line numbers.
lcclnk supports two types of line numbers: the code view format line numbers, and the COFF line numbers. They have to be relocated by the linker.

The line numbers as generated by the compiler are in COFF format. From Winnt.h we have:
typedef struct _IMAGE_LINENUMBER {
    union {
        DWORD   SymbolTableIndex;				(1)
        DWORD   VirtualAddress;				(2)
    } Type;
    WORD    Linenumber;						(3)
} IMAGE_LINENUMBER;

If the field (3) Linenumber is zero, the information in the union is interpreted as a symbol table index that gives the offset of the function where the line number exists. The line numbers are emitted in sets, each starting with a line number with this field set to zero, and followed by a set of records where a line number is associated to a virtual address (2) second field of the union above.

This schema is a limitation since no line number information can be emitted for non-code symbols, i.e. data symbols. They have an address of course, but that information is not passed on to the debugger.

Besides, all this thing of line number misses the point that a line can contain a lot of code, and there is no way for the compiler to pass that information to the debugger using this schema. This means that a line like:

	for (i=0;i<5;i++) if(i == 3) fn3(7); else fnX(i);

is not debuggable and should be avoided...

The offset stored by the compiler for each source line refers to the beginning of the text section (code) of the module being compiled. The linker knows where this module will be in the executable when it runs, so it fixes the line number information according to:

	offset = original offset + code section offset + displacement - Image Base

The code section offset, is the start address of the .text section. The displacement is the position of the current module within the code section, and the Image base is the start address of the image in virtual memory. Now let's see this in greater detail.

The code section offset is normally 4096. The first page of the executable image is not mapped, so any access to it using a badly formed address will provoke a trap, and the execution will stop. From the linker point of view this is just a number that should be added to the total offset.

The displacement is the position, relative to the beginning of code, of the module we are linking. If we have several modules to link (and that is always the case), the second module begins some bytes after the first. If the first module makes 1019 bytes, the second module will start at offset 1024 since modules are aligned at 16 bytes boundaries by the linker. The displacement of the second module would be then 1024.

The image base is the virtual address where all programs are loaded. This is normally 0x400000 for windows programs.

The line numbers for the code view debug information is simpler: They have just the offset from the base of the module. The linker using the information from the COFF line numbers creates them. At each Coff line number, the corresponding routine for CV line numbers is called, that builds the record needed in another format. Maintaining two formats is cumbersome, and maybe slows down the linker. It was valuable when the linker was being built though, since other debuggers understand COFF debug info, and provided a checkpoint for the CV information.
Performing the relocations
Once symbol relocating and line number relocating is done is done, we go through all object files performing the relocations as specified in the corresponding sections. We add,  subtract the image base, etc. At the same time that we do this, we record the position in the output file where each relocation is done, so that we can tell the program loader, that in the case that the image can’t be loaded at the calculated address, it should patch the address <here>. This is called a .reloc section, and is used mainly in Dlls.

More specifically, what the linker does, is fixing the data/code references that each module contains from all others, patching the code with the offsets that the external symbols have, now that the positions of all sections are known. For a C source line like:

	foo(5);

the linker reads the corresponding relocation record emitted by the compiler, and looks up the symbol ‘foo’ in the symbol table. It patches the zeroes that are stored by the assembler at the position following the call opcodes with the relative offset from the point of the call to the address of foo. This will allow the processor to make a PC relative call instruction: the 4 bytes after the call instruction contain a 32-bit offset to the address of foo.
Using the utility pedump, you can see this process. Consider the following well-known program:

#include <stdio.h>
int main(int argc,char *argv[])
{

        printf("Hello\n");
}

Compile this with:
	lcc -g2 hello.c
Now, disassemble hello.obj with pedump like this:
	pedump /A hello.obj45
You will see near the end of the long listing that follows, the disassembled text section:

section 00 (.text)  size: 00020  file offs: 00220
--------------------------------------------------------------
_main:   Size    18
--------------------------------------------------------------
[0000000] 55               pushl  %ebp
[0000001] 89e5             movl   %esp,%ebp
                                                            Line 5
[0000003] 6800000000       pushl  $0   (_$2)	(relocation)
[0000008] e800000000       call   _printf	(relocation)
[0000013] 83c404           addl   $4,%esp
                                                            Line 6
[0000016] 5d               popl   %ebp
[0000017] c3               ret
[0000018] 0000             addb   %al,(%eax)

Let’s follow the relocation to the function printf. You will see that pedump has a listing of the relocations that looks like this:
Section 01 (.text) relocations

Address  Type    Symbol Index Symbol Name
-------  ----    ------------ ----- ----
4        DIR32           4   _$2
9        REL32          16   _printf

The linker will then take the bytes starting at the address 4, and put the address of the symbol 4 in the symbol table of main.obj. It will search the address of printf, and put the relative address, i.e. the difference between the address of printf and the address of main+9 in those bytes starting at byte 9.

As you can see there are several types of relocations, each specifying a different way of doing these additions. The compiler emits only three types of relocations:
Type 6 : Direct 32-bit reference to the symbols virtual address
Type 7: Direct 32-bit references to the symbols virtual address, base not included.
Type 20: PC-relative 32-bit reference to the symbols virtual address.

This last one is the one used in the relocation to printf. We have to know too that the relative call is relative to the next instruction, i.e. to the byte 13 and not to the byte 9. Happily for us the linker now knows this stuff...46
And we are not done with the relocations. If the linker is building a dll, we have to send a message to the program loader to tell it that there was a relocation here, so in case the dll can’t be loaded at its preferred address, this addresses, i.e. code bytes 9-13 and 4-8 should be patched with the new load address.

This message is sent in the form of a relocation section that is mandatory for dlls. It can be issued for .exes too, but lcclnk doesn’t do it. What for? The executable is always the first to be loaded into its virtual address space, so there is no need to relocate it.

The documentation for the reloc section says:

The Fix-Up Table contains entries for all fixups in the image. The Total Fix-Up Data Size in the Optional Header is the number of bytes in the fixup table. The fixup table is broken into blocks of fixups. Each block represents the fixups for a 4K page. Each block must start on a 32-bit boundary.

Each block of fixups (as they are called the relocation messages for the loader) then, starts with an address and a size. Then follows the information: the address, and the type of relocation to be performed, in a much similar way to the other relocation records. Since we are describing the relocations for a 4096 byte page, the address is written over 12 bits, using the other 4 bits of a 16 bit word for the type of relocation.

Clever isn’t it? But not so easy to generate.

Relocations in lcclnk avoid most of the complexities of the x86 architecture. Since we are using the flat model, where all segments are the same, we avoid the complex issues of segment relocations, etc. Lcclnk is not designed to handle relocations to intersegment jumps that could theoretically be generated in another segmentation model.

You will find in the source code of the pedump utility, in file exedump.c, the code that dumps the relocation table.

Counting a symbol’s usage

If the -x option is specified in the linker’s command line, at each relocation lcclnk increments the symbol’s ‘usage’ field. After the link is done, all the symbols that aren’t used (i.e. an ‘usage’ field of zero) are printed out. This is not very sophisticated, since in the case of a symbol from the .text section (a function), it could be that is used implicitly by a relative call instruction, that doesn’t use any relocation. Lcc doesn’t generate a ‘call myfunction’, but a ‘call +587’, with 587 being the difference between the value of EIP at this point, and the position of the function to call, i.e. the function ‘myfunction’ would be 587 positions from the program counter (eip) relative to the beginning of the next instruction.

Lcc doesn’t ever generate a jump without a relocation when you are calling a function that is in another module, so this problem will appear only when the function is used in the same module.

Linking the debug information
When you write a windows program, and you #include <windows.h>, all definitions that you use from it generate debug information. This means, when you link several modules that include windows.h, you will have several times the debug information for structures like LOGFONT, or whatever. This is wasteful of space. The linker should pack that information so that only one definition of the LOGFONT structure is linked in.

Besides doing that, the linker should build the information relative to the debug directory: start and size of each module that has contributed code/data to the link, and other information.

To support CodeView debug information, the linker:
1. Generates the header and "NB09" signature.
2. Packages the header with .debug$S and .debug$T sections from object files and synthetic (linker-generated) CV4 information, and creates a debug directory entry.
3. Generates the subsection directory containing a pointer to each known subsection, including subsections that are linker-generated.
4. Generates the sstSrcModules subsection, which specifies the address and size of each module's contribution(s) to the image address space.
5. Generates the sstSegMap subsection, which specifies the address and size of each section in the image.
6. Generates the sstPublicSym subsection, which contains the name and address of all externally defined symbols. (A symbol may be represented both by .debug$S information and by an sstPublicSym entry.)

The function that coordinates the linking of the debug information is called WriteCVInfo(), and is located in cvlink.c.  It does the process described above, beginning with a call to CreateSignature(), followed by a call to CreateModulesFromCoff().

That function writes for each module contained in the link, a structure like this:
typedef struct OMFModule {
    unsigned short  ovlNumber;	// overlay number. Not used always zero
    unsigned short  iLib;		// library that the module was linked from
    unsigned short  cSeg;		// count of number of segments in module
							// This is for now always one.
    char            Style[2];		// debugging style "CV"
    OMFSegDesc      SegInfo[1];	// describes segments in module
    char            Name[1];		// length prefixed module name padded to 
							// a long word boundary
} OMFModule;

The OMFSegDesc structure is just two integers indicating the start address and the size of each module.

Once this part finished, the linker writes the descriptions of the source modules. This done, the stage is set for linking the type information. 

The task of the linker is to find out all the types that are defined several times in different source modules, and emit only one definition for the type into the executable debug information.

Since symbols refer to the corresponding type information using a number that index the types table, if different definitions of a type are consolidated, the indexes will be all wrong. The linker arranges to modify all those indexes to make them point to the new ones. The function that does all this is LinkTypes(), in cvlink.c.

But we are far from finished. The global tables for the debugger have to be built and written to the output file.

The rationale for writing those tables is that they allow the debugger to quickly find the offset of a symbol in the debug information, without having to scan all debug information for all loaded modules. The format of those tables is fairly involved.

They begin with a header that contains:
1. The index of the symbol hash function. For this I use the only published algorithm, that has an index of 10.
2. The index of the address hash function. The same as above, I use the only known one, 12.
3. The number of bytes in the symbol table.
4. The number of bytes in the symbol hash table.
5. The number of bytes in the address hashing table.

Once this header is out, the linker writes all public symbols. The linker loops through all modules, reading the symbol information (that was previously patched when linking the types), and building the name hash tables and the address hash tables, as it goes along.

The linker uses a fair amount of memory for this operation, what is not really a problem these days. I shudder when I read the documentation specifying what to do in low memory situations, because in the times of windows 3.0 and windows 3.1, all this had to be written with the limitations of 64K for each data object. Today, machines with 32MB are common, and many machines have already 64MB of RAM or more. In this context, and considering that we have a virtual memory system, the linker just builds all those tables in memory, to be able to write them in one pass to the executable. In this, lcclnk has certainly an advantage over Microsoft Link that wasn’t rewritten for Win32...

Mapping source files to addresses
The debugger needs to know which source line corresponds to which address. This mapping is built by the linker from the COFF line number information generated by the compiler.
The central table is the sstSrcModule table (type 0x127),  a fairly complicated construction building a many to many mapping between source files, modules, and source lines. Let’s use the following simple example to see the issues involved:

File f0.c :

#include <stdio.h>
int f0(int a)					
{						// line 3
	return a+6 ;			// line 4
}						// line 5
#include « f1.c »
int main(void)
{
foo1(5) ;				//
	printf(« hello\n ») ;
}

File f1.c is :

int foo1(int a)
{
	return a+9 ;
}

Here we have :
1. Several source files contribute to the object code file 
2. A source file contributes several different portions to the object file.

We need then, to specify three code ‘segments’ 47:
1. The code of function f0
2. The code of function foo1
3. The code of ‘main’

We have to associate each section with a consecutive range of addresses, and with a sequence of line number information.

Lcclnk builds the segment list, adding a segment whenever a .file special symbol is seen during the link. For each module, we have then, a list describing all the files seen for that module. The linker tries to avoid making duplicates, i.e. when a .file symbol is seen, it verifies that it is not the same as the last one before adding it to the table.

The information is generated in a table as mentioned before : the sstSrcModule structure. This structure has several parts :
It begins with a header, describing the information that follows .
For each file, a table describing the modules and the line numbers is built. Roughly, the structure of the table is a sequence of file information blocks describing each source file for each module that participates to the link.
The file header
Size
2
2
4 * cFile
8 * cseg
2 * cseg
Name
cFile
cseg
baseSrcFile
Start/end
seg

This header consists of the following :
1. The number of files that participate to the object module (cFile).
2. The number of code segments that make the module (cseg).
3. A table of integers specifying the offsets relative to the beginning of the table, where each file will be found (baseSrcFile).
4. A table of 2 integers per segment, specifying its start address and the end address (Start/end pairs).
5. A table of numbers specifying which section will receive code from this piece of code. This is always one, i.e. the text section, but it could be that we generate later line number information for data description, for instance, to be able to see the place in the source code where a data item is defined (seg).
The information per source file
Size
2
2
4 * cseg
8 * cseg
2
*
Name
cseg
Padding
baseSrcLn
Start/end
Name len.
Name

For each source, we write the number of pieces of code that this source contributes to. For instance we have in the example above that file f0.c contributes two separates pieces of code : the function ‘f0’ and the function ‘main’, separated from a piece that comes from another source file (f1.c). For this example we would write 2.

Afterwards, we build an array of offsets to the line number information that will be written for each of those pieces. This offsets are relative to the beginning of the whole sstSrcModule table.
Then, we write a length prefixed chain of characters with the file name proper. Under lcc-win32 the file name will be always a fully qualified file name, containing an absolute path.

Size
2
2
4 * cPair
2 * cPair
Name
Segment
cPair
Offset
Line

Then, at last, we write the line numbers for each piece of code from this source file, as two parallel arrays with the address and its corresponding line number, i.e.an array of 4 bytes integers for the addresses, and an array of 2 byte shorts for the line numbers.

You will find in the source code of the pedump utility, in the file exedump.c, the function DumpSstSrcModule, that dumps this table.

This table is an example of the complex tables the linker has to build for the debugger. Maybe I would have been able to design a much easier ad-hoc format, but using the Microsoft standard ensures that the generated code is compatible with many other tools, and, last but not least, allowed me to have a reference implementation : it suffices to start the MSVC debugger to see if I generated the tables correctly or not .

Building the executable headers
Just before the executable will be finally be written to disk, the linker sets the corresponding fields in the headers, so that the loader will accept it.

Under Windows 95, there were holes in the file, left by moving the file pointer beyond the end of file without actually writing any data into it. This produced the very bad effect of getting garbage creep into the executable. Any contents of memory could be written in the executable, even the documents you were editing or even mail messages you were reading when the linker was working. I corrected that problem which wasn’t a linker problem but an OS problem at this point by writing zeroes to the empty space in between any sections.

Loaders are not really user-friendly. They will load or refuse to load, and the linker writer has not many clues as to what is wrong when the loader just tells: « This is not a valid executable ». Obviously, it is impossible for the loader to give a meaningful message anyway, since the average user wouldn’t understand anything about sections/loader tables etc.

The source distribution of lcclnk.
The source files of lcclnk are located in \lcc\src\lcclnk. They are the following :
lcclnk.c. This is the main linker file. Here are the relocations done, the executable format is writtezn to disk, etc etc.
cvlink.c. This is the part concerned with the linking of the debug information.
cvtres.c. This converts a resource binary file into an object file.
expand.c. This file performs the wild-card file name expansion, i.e. it will transform an argument like *.obj into a list of files.
Dynamic linking
Motivation
Within the context of the interpreter development, I needed to be able to load an object file into the running program. The idea is that the interpreter or the debugger could be able to load any library object file by just entering some command at the interpreter’s prompt.

This dynamic linking package is a nice thing to have when you do not want the problems associated with building a full blown executable, a dll.

The first motivation for doing this, was in the debugger context. You have just modified a function, and you want to recompile and go on with the new version. The object file for the new function should be loaded by the debugger, and in the place where the old version was, a jump instruction will refer to the freshly loaded and (hopefully) corrected version.
Implementation
In principle then, the algorithm is the following :
Load the object file into memory. I did this with memory mapped files.
Copy the code section into a freshly allocated memory block.
Copy data and bss segment (initialized and not initialized data) to the data segment, in a freshly allocated memory block too. 
Relocate the code and the data segments, relative to their loading address. The base of the allocated code block becomes the base of the code segment, the base of the data segment becomes the base of the data segment. All relocations are relative to this addresses. The dynamic linker handles two types of relocations only : direct addresses, and relative addresses, for relative call instructions.
The still unresolved symbols are put in a symbol table. The symbol table of the running executable is then opened, and the dynamic linker figures out where each address is, by looking at the load address field in the extended « optional » header. This addresses are then patched in the code and data segments of the loaded object file.
The symbol table of the loaded object file is used to build a small « symbol table », i.e. just a list of names that indicate which functions and data are defined in the loaded file. This small symbol table will be used to find out where a concrete procedure is located and to return its address using the GetProcedureAddress call.

Binding the object file
Object files can reference functions from external DLLs. When they do so, (and most of them will do so), a problem arises : how will the dynamic loader resolve those references ?

The solution I retained was to build several utilities to support dynamic loading. The first, is a small dll that will generate a list of all APIs from windows in a text file called ‘Apilist.txt’, that resides in the « lib » directory of the lcc-win32 distribution. This file is useful in other contextes, like, for instance, when you forget an import library and the link step fails with ‘unresolved references’. The IDE can now look into this list and find out in which import library the flagged function exists, and automatically add the needed library to the link step.

The format of the apilist.txt file is very simple :
The first line contains the number of DLLs used
The next <n> lines contain the names of each dll
Then, the names follow with a number indicating which DLL contains this name.
The file is build using the list of known DLLs in \lcc\buildlib\dlls.txt. If you want to add your own dll to the apilist.txt file, you should just add the name of the dll to this file, and copy your .exp file to the \lcc\buildlib directory.

For instance, if you want to add ‘mydll.dll’ to the list of known DLLs in apilist.txt, you build the DLL. The linker will automatically generate a .exp and a .lib for you. Copy the .exp, in this case mydll.exp to the \lcc\buildlib directory. Then add a line ‘mydll.dll’ to the dlls.txt file in \lcc\buildlib. And then run buildapi.exe, that lives in the \lcc\bin directory.

Once this list was build (no easy task:  at last count there were 10 810 entries!), the ‘bind’ utility has just to look up in this list all external references from an object file to determine which DLL contains a given symbol, if any.

The list of needed dlls is appended to the end of the object file. This list has the following format :
IMPORTS
somedll.dll
_somefn@16 somefn
…
$$end$$
The keyword ‘IMPORTS’ starts the list, and the keyword ‘$$end$$’ ends it. This is all in ASCII, so you can read it with an hex editor.

The import librarian
This utility allows you to build an import library from a dll executable. This is nice, when you do not have the source code. For building your own dlls, you should leave this problem to the linker that has been changed to take care of this problem: it builds an import library automatically when building a dll.
Import libraries
Import libraries are just a series of ‘stubs’ that will satisfy the linker, but contain no code. They are very easy to write, since they are just an indirection through a function pointer table.

When you call any function that is in a dll (all standard C library functions, windows functions and any other functions the executable imports), you do NOT call directly the code in that function, but you call a ‘stub’ that consists of only one instruction:
	call	jmptable[10]

This ‘jmptable’ is the .idata section. It will be filled with the actual contents at load time, when the loader searches in the PATH where the dll in question is, and determines the addresses that need to be written to the table.

The task of the ‘import’ utility is just to generate a series of object files in the .lib format so that they contain pointers to that jump table.

Basically, the building of an import library is the process of creating a series of object files, that will in most cases contain just those 6 bytes above. Obviously, it is more complicated than that, the whole object file structure has to be built, the symbol table, the string table, and the different idata sections.

The import librarian comes in two flavors: one (called implib.exe) that just emits the library by reading its information from the dll, and the other called ‘buildlib.exe’,  that builds the library from an Ascii description of names.

The importance of ‘implib’ will decrease in the future, since the linker has been modified to use buildlib directly. At the end of the linking process, lcclnk will emit a .exp file for the buildlib utility that makes possible to include the building of the library in the link.

The format of the generated ascii .exp file is very simple:
1. The first line contains the name of the dll we are building this import library for.
2. The next lines contain three columns, the last being optional. The first column should contain the name of the symbol as emitted by the compiler. The next column should contain the name of the symbol as exported from the dll. The third optional column contains (or not) the keyword ‘data’ to indicate to buildlib when the export is a data item, and no ‘jmp’ instruction is needed.
There aren’t any checks to verify the correspondence of those names, to allow the user to introduce ‘alias’ for an exported function from a dll. I use intensively this feature in the CRTDLL.EXP file, where there is always the problem of the underscores Microsoft has added to many functions of the standard library like _open, etc. This is easily solved by making two aliases for the real open dll function: _open and __open. With this, both names will be accepted and produce the same result.

Summary: Building an import library from a dll.
The usage of the implib utility is really simple: you just give it the name of a dll. It will eliminate the .dll suffix, replace it by a .lib suffix, and build a library file with all the stubs for the exported functions of the dll.

The resource compiler
The .rc language specifications.
This language was developed to specify resource files. It describes the basic resource types, i.e.; the following objects:
Menus
Dialog boxes
Accelerators
String tables
Icons
Bitmaps
Cursors
Fonts
Version
Each object is introduced in the following manner:
Name or ID	OBJECTNAME	[Options]
For instance, to specify a Menu object, you would write:
2800	MENU	Discardable
The language supposes that there is a preprocessor that allows for #defines, #if, #ifdef, etc. The specifications of the preprocessor are identical to the C preprocessor, so I will not discuss it further here.
This language is only slightly 'specified'. The specifications are actually the behavior of the Microsoft's resource compiler 'rc'. For instance, rc accepts that instead of writing a keyboard objectname, you can replace it with a number from 1 to 16, specifying a resource type in numerical form. 

Parsing
Initially, I was tempted to use the public domain ‘rcl’ resource compiler developed by Gunther Ebert, in Leipzig. Gunther used the standard Unix approach of lex/yacc. 

His compiler is constructed with a ‘lexer’ that is written in the ‘lex’ language specifications, and a parser, specified in the ‘yacc’ notation. The ‘lexer’ is built by a program called ‘lex’ that generates a lexer from the specifications it reads. The parser is generated by the ‘yacc’ program, that writes a parser using the specifications given in the ‘yacc’ language.

This approach is very flexible, but it had several disadvantages for the purposes of a resource compiler:
It is very hard to debug a ‘yacc’ specification.
Yacc and ‘flex’ are not readily available under Windows 32. I had to use my linux machine, to compile the lexer+parser, then use ftp to move the result to windows, and then recompile. And this for each change done to the specification.
It was very complicated to do apparently simple things like processing optional arguments etc.

So I decided to use the same approach as described by Fraser and Hanson in their book about lcc: the recursive descent approach.

The resulting parser was much smaller, and  much easier to debug.

The parser
Parsing is done following a rather simple ‘algorithm’:
while (not EndOfFile) do {
	token = readtok();
	if (isAnObjectToken(token)) {
		ParseObject(token);
	}
}

Following are the object tokens, i.e. the tokens that introduce an object:
DIALOG MENU,ACCELERATORS STRINGTABLE VERSION BITMAP CURSOR ICON MESSAGETABLE

Simple isn’t it? The parser just ignores all input except those words. When it sees one of those, it will parse an object specification that should leave the last token untouched.

To avoid that the resource compiler sees a token in another context it #defines the following pre-processor symbol: RC_INVOKED. Most definitions in the windows header files are enclosed in a pair of ifdefs
#ifndef RC_INVOKED
typedef ...
#endif

This prevents random matches. If you use structure definitions in the header files the resource compiler will see, take care to enclose your definitions as shown. In any case, the consequences of seeing a random definition are not very bad, since it will only provoke a cascade of error messages.

The function ‘gettok() does a classification of the input passed to the parser by the preprocessor. It returns :
A character, i.e. a value between 32 and 127. This will be returned for commas, brackets, etc.
A constant between 1000 and 1999 for different classes of input, indicating whether the input is a number, an identifier, a floating point constant, a string, or other things. The value will be left in a global variable, so that the rest of the parser can use it.
A constant between 2000 and 3000 if the input is an rc keyword.

The top level parser function looks like this:

static int Parse(void)
{
	int ttype;

	ttype = gettok();
	do {
		switch(ttype) {
		case EOI:
			return(1);
		case KEY_DIALOGEX:
			ParseDialog(1);
			break;
		case KEY_DIALOG:
			ParseDialog(0);
			break;
		// other cases omitted for brevity
		}
		ttype = gettok();
	} while (ttype != EOI);
	
	return(1);
}

Each of the functions called will parse the grammar for the description of the object, leaving the last token in the input. Here is the description of each one:

Dialog statement
nameID DIALOG [ load-mem] x, y, width, height
[optional-statements]
BEGIN
    control-statement
    . . .
END

The ParseDialog() function retrieves the last integer/identifier, and uses that as the name for the dialog. Then, the ‘load-flags’ are parsed, but ignored. Those flags were very important under windows 3.1, but now they are not used. They were maintained to have a backward compatibility with the resource scripts written for windows 3.1.

The function goes on parsing the coordinates of the dialog box. After that, we arrive at the optional statements. Those can be:
FONT Followed by a point size, a font name, and if it is a DIALOGEX statement, the weight of the font and an italics flag.
CAPTION Followed by a character string indicating the caption text.
CLASS statement indicating the class of the dialog. Normally this is not used.
CHARACTERISTICS field, followed by a 32 bit number. Windows do not use this, and the resource editor never generates it.
STYLE followed by the window style of the dialog box window. 
EXSTYLE followed by the extended style of the dialog box window. This can be used only within a DIALOGEX statement, and not a normal DIALOG statement.
LANGUAGE followed by two numbers specifying the language and the sub-language code.
VERSION followed by a version number for the dialog. Windows do not use this.


Once this preliminaries are done, we can start parsing the contents of the dialog box, the different CONTROL statements. This statements have all the same syntax, excepting the CONTROL statement.
NAME text, id, x, y, width, height [, style [, extended-style]]

Here is a table indicating for each of the named controls, its class, default styles and usage.

NAME
Remarks
Default Styles
Class48
GROUPBOX
This statement builds a transparent rectangle to group some items into a common group
BS_GROUPBOX
Button
LTEXT
Left aligned static text
SS_LEFT
Static
CTEXT
Centered static text
SS_CENTER
Static
RTEXT
Right aligned static text
SS_RIGHT
Static
LISTBOX
Builds a listbox. Normally the ‘text’ field is empty
WS_BORDER LBS_NOTIFY
Listbox
EDITTEXT
Builds an edit field. Normally the ‘text’ field is empty
ES_LEFT WS_BORDER WS_TABSTOP
Edit
ICON
This creates a static text window at the position specified. Since Icons have a fixed width and height, those fields are not necessary. If you specify them, the resource compiler will read and ignore them.
SS_ICON
Static
PUSHBOX
This creates a button with the BS_PUSHBOX style
BS_PUSHBOX WS_TABSTOP
Button
PUSHBUTTON
This creates a normal push button.
BS_PUSHBUTTON WS_TABSTOP
Button
RADIOBUTTON
This creates a radio button
BS_RADIOBUTTON
Button
SCROLLBAR
Creates a scroll bar
WS_TABSTOP
Button
STATE3
Create a three state check box
BS_3STATE
Button
COMBOBOX
Creates a combo box

Combobox
CHECKBOX
Does a check box
BS_CHECKBOX WS_TABSTOP
Button
AUTORADIOBUTTON
Radio button with the ‘automatic’ style.
BS_AUTORADIOBUTTON
Button
AUTOCHECKBOX
Check box with the ‘automatic’ style
BS_AUTOCHECKBOX
Button
DEFPUSHBUTTON
This is the default button that will be used when you press return.
BS_DEFPUSHBUTTON WS_TABSTOP
Button

The general Control statement has the following form:
CONTROL text, id, class, style, x, y, width, height [, extended-style]
All statements numbered before can be written using the ‘control’ statement. They are just shorthand’s for this one.
The ‘extended style’ can only be used if it is an extended dialog (DIALOGEX).

MENU Statement
menuID MENU [load-mem]
[optional-statements]
BEGIN
    item-definitions
    . . .
END
  
This statement introduces a menu description, with each of the POPUPS described within a BEGIN/END block.
The binary format generated is as follows:
1. Normal resource header with type 4 (menu).
2. A flags word. If the flags contain the ‘POPUP’ flag (0x10) this indicates an implicit begin/end block. If not, it is a menu item. The text of the popup follows in unicode characters.
3. A menu item contains a flags word, followed by the ID of the menu item (the parameter you will receive when processing WM_COMMAND messages), followed by the text of the menu item in unicode characters.
4. The last item of the menu contains the flag 0x80 to indicate the end of the menu description.
The different image resources (icons, bitmaps, cursors)
nameID ICON [load-mem] filename
nameID BITMAP [load-mem] filename
nameID CURSOR [load-mem] filename


The specifications for those resources are like this:

The ICON statement in the .RC script does not create a single resource object, but creates a group of resources. This allows Windows-based programs a degree of device independence through the use of different pixel bitmaps on hardware configurations with differing capabilities. Icons, most often designed for differing numbers of pixel planes and pixel counts, are grouped and treated by Windows as a single resource. In the .RES and .EXE files, however, they are stored as a group of resources. These groups are stored in a .RES file with the components first (in this case the different icons [type 3]) and a group header following (type 14). The group header contains the information necessary to allow Windows to select the proper icon to display.

The components have the following structure:
     [Resource header (type = 3)]

     [DIB Header]
     [Color DIBits of icon XOR mask]
     [Monochrome DIBits of AND mask]

I had a lot of trouble building that resource header. I think I have gotten it right now, but beware... As a test of the correctness of ‘lrc’, I used ‘weditres’, that will display the icons, and decode that resource header.

Basically, the compiler treats all of these the same: it will read a file specification, and put that file unchanged in the resource file. No magic is performed, i.e. for instance for icons, the Xor of the image is not performed to have a black and white and a color version. The compiler doesn’t generate different icons for vga, svga, and other resolutions either... SO: please edit your icons with another tool before. Of course, the resource editor will eventually have an icon editor, but this is not done yet...
The string table resource
STRINGTABLE [load-mem] [optional-statements]
BEGIN
    stringID string
    . . .
END
  
As usual, the ‘load’ flags are parsed but ignored. The optional statements can be ‘Language’, ‘Characteristics’ or ‘Version’ keywords.
The format of each string is just a numerical ID, followed by the string enclosed in quotes. The usual expansions for C character strings are performed.
Strings are clustered together in blocks of 16 strings, keyed by the numerical ID. The algorithm is rather complicated;
1. ID should sort the strings, because the linker lcclnk will not sort them when transforming the resource in object files.
2. Transform all strings into unicode before storing them. They are stored preceded by a word indicating the string length. They are NOT zero terminated.
3. Use the lower 4 bits of the id to indicate a position within a block of 16 strings with consecutive Ids.
4. Use the upper 12 bits of the plus one, to give a resource ID for a string resource of type 6 (string table resource type).
This means that if you give a string an ID that is isolated from other Ids you will waste space in the resource file, since an almost empty block containing only one string+the resource header will be stored.

Here is the essential part of the string-resource writing function:
	idx = 0;					// running index through the table
	buffer = allocate(20000); 	// buffer space
	bufferlen = 20000;			// its length
	do {
		memset(slots,0,sizeof(slots))// clean the slot
		first = StringTable[idx]->id;// first index
		len = 32; // 16 * sizeof(word)
		// the variable ‘strings’ is the total number of strings in the table
		while (idx < strings ) {	// fill a slot of 16 strings
			id = StringTable[lastidx]->id; // get this string id
			// test if this string belongs to this block
			if ((first & (~0xF)) == (id & (~0xf))) {
				slots[(id&0xF)] = StringTable[lastidx];
				len += 2*(StringTable[lastidx]->len);
				lastidx++;
			}
			else {// this block is full
				break;
			}
		}
		// test if the buffer is big enough
		if (len > bufferlen) {
			len += 500;
			buffer = MyRealloc(buffer,len);
			bufferlen = len;
		}
		// Now copy all the strings found into the output buffer
		p = buffer;
		for (i=0; i<16; i++) {
			if (slots[i] && slots[i]->len) {
				len = slots[i]->len;
				p = WriteWord(p,(WORD)(len));
				mbstowcs((WORD *)p,slots[i]->Text,len);
				p += 2*len;
			}
			else p = WriteWord(p,0);
		}
		WriteStringResource(buffer,
			p - buffer,
			1+(first >> 4),
			characteristics,language,version);
		idx = lastidx;
		
	} while (idx < strings);

The string table format uses two bytes for each character, plus the overhead for storing the blocks. If you want to save space, it is much more efficient and faster to use a structure with a tag and a pointer to the string, and looking up that at run time yourself. As an indication, I had the string table in resource format in earlier versions of wedit. When I translated the format into a normal C structure with ASCII characters the program shrank by 22K.

The RCDATA resource
nameID RCDATA [[load-mem]]
[[optional-statements]]
BEGIN
    raw-data
    . . .
END
This resource is not extremely difficult to do. Just parse a normal header, its type in the resource header is 10, and then read a series of strings or integers between the ‘BEGIN’ and ‘END’ keywords. A thing to be remembered is that integers, unless they end with the ‘L’ are 16 bits...
The Message Table resource
nameID MESSAGETABLE filename

This resource type is generated by the message compiler mc. This tool hasn't been added to the capabilities of lrc, so you will have to get it from another compiler. Probably the capabilities of mc will be incorporated into lrc at a later stage in development. For the time being, it is only possible to use already compiled message tables. This is used in NT service executables for instance, or in other specialized applications. The format of the binary resource is very similar to the string table resource format.

The ACCELERATORS resource
Syntax:

acctablename ACCELERATORS
[optional-statements]
BEGIN
    event, idvalue, [type] [options]
    . . .
END

The acctablename token is either a number or a name. The optional statements that lrc recognizes here is only the LANGUAGE keyword.
event
Specifies the keystroke to be used as an accelerator. It can be any one of the following character types:
"char"
A single character enclosed in double quotation marks ("). The character can be preceded by a caret (^), meaning that the character is a control character.
character
An integer value representing a character. The type parameter must be ASCII.
virtual-key character
An integer value representing a virtual key. The virtual key for alphanumeric keys can be specified by placing the uppercase letter or number in double quotation marks (for example, "9" or "C"). The type parameter must be VIRTKEY.
idvalue
Specifies a 16-bit unsigned integer value that identifies the accelerator.
type
Required only when the event parameter is a character or a virtual-key character. The type parameter specifies either ASCII or VIRTKEY; the integer value of event is interpreted accordingly. When VIRTKEY is specified and event contains a string, event must be uppercase.
options
Specifies the options that define the accelerator. This parameter can be one or more of the following values:
NOINVERT
Specifies that no top-level menu item is highlighted when the accelerator is used. This is useful when defining accelerators for actions such as scrolling that do not correspond to a menu item. If NOINVERT is omitted, a top-level menu item will be highlighted (if possible) when the accelerator is used.
ALT
Causes the accelerator to be activated only if the ALT key is down.
SHIFT
Causes the accelerator to be activated only if the SHIFT key is down.
CONTROL
Defines the character as a control character (the accelerator is only activated if the CONTROL key is down). This has the same effect as using a caret (^) before the accelerator character in the event parameter.
The ALT, SHIFT, and CONTROL options apply only to virtual keys.
Resource format
The format of the accelerators is simple: they consist of a normal resource header, followed by a table of structures like this:
typedef struct tagAccelTableEntry {
    WORD     fFlags;// This contains the flag fields above
    WORD     wAscii;// Contains the value of the accelerator
    WORD     wId;   // Contains the value of the identifier
    WORD     padding;	// not used
} AccelTableEntry;

The fFlags field contains the values for the qualifiers described in the 'Syntax' header above. There is one called ACC_LAST, the appears in the last member of the table. Basically, this resource consists of a normal header size, followed by the entries, each one, containing the structure above.
I always write the last empty table member, with all its members to zero, and only in the fFlags field, the value ACC_LAST, but I am not sure if this is really necessary, since the size of the table can be easily deduced from the size of the resource divided by the size of each element.

Limitations of the resource compiler
The FONT resources are not supported yet. They will be added in the future as time permits...
The same is true for the user defined resource types.

The source distribution of the resource compiler
The sources of the resource compiler are located in \lcc\src\lrc. The following files are in there :
parse.c. Main file of the resource compiler. Everything, from lexing to resource file generation is contained in this file.
ncpp.c. The preprocessor for the resource compiler. It is almost the same code as the same named file in the C compiler distribution. It is there because I decided to separate the modifications done to the preprocessor code from the ones in lrc, that needs much less complexity for its own modest needs.
The main file contains a lexer in a very similar pattern that lcc uses. It will return an integer with the token parsed so far. The parsing routines decide how the tokens are interpreted.

The librarian
lcclib was the last utility that was missing to complete the cycle of lcc’s environment. Its task is to store several object files into one file called ‘library’, that contains the object files and three headers to describe to the linker what are the contents of each. The object files are stored without any modifications. No compression or other processing is required.
The structure is very similar to the one used under UNIX.
The signature
All archives have a signature that marks them as a library. Under win32 the signature used is
!<arch>\n 
All .lib files have those 8 chars at the very beginning of the file.
The « first linker member »
After the signature, there are normally three headers. called ‘members’ in techspeak. The first one is a very simple table that tells the linker which symbol is in which object file. The name of the first linker member is "/". Its format is the following:

Offset
Size
Field
Description
0
4
Number of Symbols
Unsigned long containing the number of symbols indexed. This number is stored in big-endian format. Each object-file member typically defines one or more external symbols.

4
4*n
Offsets
Array of file offsets to archive member headers, in which n is equal to Number of Symbols. Each number in the array is an unsigned long stored in big-endian format. For each symbol named in the String Table, the corresponding element in the Offsets array gives the location of the archive member that contains the symbol.

*
*
String table
Series of null-terminated strings that name all the symbols in the directory. Each string begins immediately  after the null character in the previous string. The 	number of strings must be equal to the value of the Number of Symbols fields.						

The elements in the Offsets array must be arranged in ascending order. This fact implies that the symbols listed in the String Table must be arranged according to the order of archive members. For example, all the symbols in the first object-file member would have to be listed before the symbols in the second object file.

The second linker member
The second linker member has the name "/" as does the first linker member.
Lcclnk does not use it. The second linker member includes symbol names in lexical order, which enables faster searching by name.

Offset
Size
Field
Description
0
4
Number of members
Unsigned long containing the number of archive members.

4
4*m
Offsets
Array of file offsets to archive member headers, arranged in
ascending order. Each offset is an unsigned long. The number
m is equal to the value of the Number of Members field.
*
4
Number of symbols
Unsigned long containing the number of symbols indexed. Each
object-file member typically defines one or more external symbols.
*
2*n
Indices
Array of 1-based indices (unsigned short) which map symbol names to archive member offsets. The number n is equal to Number of Symbols. For each symbol named in the String Table, the corresponding element in the Indices array gives an index into the Offsets array. The Offsets array, in turn, gives the location of the archive member that contains the symbol.

*
*
String table
Series of null terminated strings that contain the symbol names, sorted alphabetically.

Once all those headers are written, the only thing to do is to write the object files, each preceded by a header.

Usage of lcclib
An option consists of an option specifier, which is either a dash ( - ) or a forward slash ( / ), followed by the name of the option. Option names cannot be abbreviated.

Some options take an argument, specified after a colon (:). No spaces or tabs are allowed within an option specification. Use one or more spaces or tabs to separate option specifications on the command line. 

Option names and their keyword or filename arguments are not case sensitive, but identifiers used as arguments are case sensitive.

lcclib processes options in the order specified on the command line and in command files. If an option is repeated with different arguments, the last one to be processed takes precedence.

/VERBOSE
Displays details about the progress of the session. The information is sent to standard output and can be redirected to a file.
/LIST
Displays information about the output library to standard output. The output can be redirected to a file. You can use /LIST to determine the contents of an existing library without modifying it.
/OUT:filename
Overrides the default output filename. By default, the output library is created in the current directory, with the base name of the first library or object file on the command line and the extension .LIB.
/REMOVE:object
Omits the specified object from the output library. LCCLIB creates an output library by first combining all objects (whether in object files or libraries), and then deleting any objects specified with /REMOVE.

Lcclib source files
The whole code of lcclib is a single file called appropriately lib.c. It is very small, but it implements all the machinery described above.

The resource editor 
I wrote a resource editor for JFC Informatique & M?dia in 1994, for Windows 3.1. That editor was specially tailored to them and started with the need that they have, of producing high quality dialog boxes and resources for their applications. 

They used the ‘MDI’49 paradigm in all their applications. Problem is, it wasn’t easy to create the controls in the MDI’s by hand. They attempted this at the beginning, but quickly they arrived to the conclusion that they needed a tool for writing their dialog boxes and designing them interactively. They paid me an amount of money to do it, and I delivered to them an editor that could design dialog boxes without using dialog units, as they desired. The problem of dialog box units, as you maybe have experienced, is that it is impossible when you use them, to specify the positions in pixels. This means that depending on the circumstances your controls will miss a pixel here and there, and will not be exactly aligned. This was unacceptable for them.

I decided to use the experience I had accumulated about resources and resource files, to build a resource editor for Lcc-Win32.

The best place for starters was evidently the code of DLGEDIT, a simple dialog box editor that is distributed freely by Microsoft with the SDK. That code is clear, more or less easy to follow if you understand what the program is doing. So, I think that the best would be that we start by that: what the program is doing, i.e. the format of the .RES files under WIN32.

The format of the .RES files

The only document that briefly describes the format of the resource files is the one by Steve Firebaugh that appears in the MSDN CDs under the strange title of ‘Windows NT File format specification’, sub item ‘Win32 Binary Resource formats’

There are currently about a dozen predefined resource types. These include Menus, Dialogs, Accelerators, Strings, Icons, Cursors, Bitmaps, Fonts, and Version. These resources are used by the Windows system to define the appearance of the application window, or to store dialog templates or other data.. The resource script (RC file) allows the application writer to represent these features in an easily editable form.
The general format of the entire resource file is simply a number of resource file entries concatenated together. Each resource contains the information about a single resource, such as a dialog template or a string table.
Each entry consists of a resource header followed by the data for that resource. A resource header is composed of four elements: two DWORDs containing the size of the header and the size of the resource data, the resource type, the resource name, and additional resource information. The data for the resource follows the resource header and is specific to each particular type of resource.

The reasons for this are simple: To go from one resource to the next within the file, you just add the fields for the header and the data, and you are all set... if you forget the alignment problems of course.

After the “Header size” field, we find immediately after it a data structure we will meet very often here: a ‘Name or ordinal’. Simply put, you examine the first WORD. If it is -1 (0xFFFFFF) the next WORD indicates the ordinal that is used instead of a name. If the first word is NOT -1, this means that a wide character set string starts at the given position, finished with a double zero byte.

The fixed part header then, is followed by a ‘Name or ordinal’ indicating the type of the resource that follows. The predefined resource types are described in the Appendix 1.If the type field is a string, its a user defined type. Lcc, for the time being doesn’t use those.

This is followed by the name of the resource that is in most cases just an ID to save space. 
The predefines resource IDs that weditres understands are the following:

Resource type
Numerical identifier
Cursor
1
Bitmap
2
Icon
3
Menu
4
Dialog
5
String table
6
Font directory
7
Font
8
Accelerators
9
RCDATA
10
Message table
11
Group cursor
12
Group Icon
14
Version resource
16
Include file name
17


The other fields of the header are language ID for indicating the language used, some flags to specify how the resource will be loaded, that are maintained mostly for compatibility with older Windows 3.1 applications, some version information and a ‘Characteristics’ field.

So, we have for our header the following format:
struct tagResource {
	DWORD		DataSize;		//Size of data without header
	DWORD		HeaderSize;	//Length of the additional header
	Ordinal or name TYPE		//Type identifier, id or string
	Ordinal or name NAME		//Name identifier, id or string
	DWORD		DataVersion;	// Predefined resource data version
	WORD		MemoryFlags;	//State of the resource
	WORD		LanguageId;	//Encoded language ID
	DWORD		Version;		//Version of the resource data
	DWORD		Characteristics;//Characteristics of the data
	} ;

Since this is not a regular C structure, we have to find out which type of data (ordinal or name type) each time we access it. In the code of the resource editor we do this in functions called “SkipResHeader”, etc, that will parse the fields according to the type of data stored in them. All those functions, together with the code to read and decode, write and encode resources are in the file “util.c”, in the resource editor source distribution.
Building a dialog box dynamically
Having read the resource file into memory, we have all the information needed to build a resource like a dialog box dynamically. The procedure for doing this is essentially very simple: Read the header, that contains the number of controls of the dialog box, and loop for each child window, making a CreateWindowEx() for each control. You get the position of each window to be created from the resource object, together with the class, font to be used, etc.

Of course this is more easily said than done...

I use the same structure that Microsoft proposed for doing that in the windows SDK. I use a ‘grabber’ window, that is created in front of each control, and that lives only to be able to drag and drop the controls, in this way allowing the user to manipulate them visually.

The core  of this process is building the data structure in memory that will be accepted by the DialogBoxIndirect function. This structure consists of two parts: a header for the dialog box, and a list of controls that follows it in memory. Beginning with the resource of the dialog box, I write that structure in the function ResToDialog, in dlgio.c, one of the central parts of weditres.
First then, I get the dialog box header, in the following structure:

typedef struct {
    DWORD lStyle;                   // Style for the dialog.
    DWORD lExtendedStyle;           // The extended style.
    WORD NumberOfItems;             // Number of controls.
    WORD x;                         // Starting x location.
    WORD y;                         // Starting y location.
    WORD cx;                        // Dialog width.
    WORD cy;                        // Dialog height.
} DIALOGBOXHEADER,*PDIALOGBOXHEADER;

As you can see from the above definition, the number of items that follow is given. We have then, after this,  NumberOfItems times the following structure used for each control:

typedef struct tagControlItem {
    DWORD Style;                   // Style for the control.
    DWORD lExtendedStyle;           // The extended style.
    WORD x;                         // Starting x location.
    WORD y;                         // Starting y location.
    WORD cx;                        // Control width.
    WORD cy;                        // Control height.
    WORD ID;                       // Control id.
        char Class;
} CONTROLITEM;

Reading the binary res file, I build this structure in memory, and there it goes, I pass it to DialogBoxIndirect.

I encountered a difficult problem with the dialog boxes that used the extended styles. Microsoft changed the specifications for the dialog box header and the control items. It took me hours under the debugger to try to figure out what needed to be done and what changed. Several months later, I found a small notice in the SDK, that described this structure:

typedef struct tagDLGTEMPLATEEX{
    WORD wDlgVer;           // use 1
    WORD wSignature;        // use 0xFFFF
    DWORD dwHelpID;         // Dialog's context help ID
    DWORD dwExStyle;        // Extended style
    DWORD dwStyle;          // Style
    WORD cDlgItems;         // Number of controls in dialog
    short x;                // Initial position, horizontal
    short y;                // Initial position, vertical
    short cx;               // Width
    short cy;               // Height
} DLGTEMPLATEEX;

The items had changed too. Here is the definition of the new structure:

typedef struct tagDLGITEMTEMPLATEEX{
    DWORD dwHelpID;         // Context help ID for control
    DWORD dwExStyle;        // Control extended styles
    DWORD dwStyle;          // Style
    short x;                // Initial position, horizontal
    short y;                // Initial position, vertical
    short cx;               // Width
    short cy;               // Height
    DWORD dwID;             // Window ID
} DLGITEMTEMPLATEEX;

The heart of the loading of the structures from disk (in the .res file) into memory is the AllocDialogResource  procedure, in dlgio.c. This function has grown into a very big and complicated piece of code, reflecting all the complexities that are inherent into reading this format.

It starts by setting a Boolean flag to indicate if we are building a control with an extended style (the “new” controls in ComCtrl32.dll, tree view, etc) or a traditional control like edit fields or check boxes. Then, it determines if we are building a new dialog from scratch or just using the selection, in the case of a copy operation for instance.

hen building a dialog for testing, i.e. when not saving/reading to disk, we have to take care to avoid including the real class of the dialog or control, since those aren’t available in the editor environment.

We calculate then, the size of the header, composed from the caption text, the class name (an ordinal) the point size of the dialog font, and all the fields detailed above. The function allocates a buffer (that is later resized as the controls are added), and writes the fixed part of the dialog box resource.

Then, we loop for each control in the dialog box, allocating and filling a control decription. The buffer is resized at each pass through the loop. We have to take care of the alignment specifications, and account for the fact that all the editor works in ANSI and not UNICODE, but the resources are all in UNICODE, i.e. two bytes for each character. It would have been maybe easier if the editor would have been always in UNICODE, but windows 95/98 users would be in bad shape since UNICODE is not supported in those systems.

The result is a RES structure, containing the size of the data, the size of the header, and followed immediately by the data itself. 
Testing a dialog box interactively
To do this, the editor constructs on the fly a dialog box specification and calls DlgBoxIndirect. The procedure of that dialog handles the initialization of the diverse controls that need something to look better, like list boxes for instance, that will be filled with some lines. Some of the new controls like the tree view control, need to be initialized with some items too.

This is done in the function CreateTestDialog, in styles.c. The detailed process of creating a dialog runs like this:
We start by erasing any current selection.
We copy the current state of the dialog being edited into the list of dialog resources that the editor maintains.
We allocate memory to hold a temporary copy of the dialog and copy the current dialog resource into it.
We call  the Windows  API CreateDialogIndirect, passing to it the resource copy.
If creation of the dialog succeeded, we gray several menu items in the main menu, and the new dialog gains focus.
The dialog receives the WM_INITDLG message. The procedure for handling the messages sent to the dialog is called TestDlgProc, (also in styles.c). Here we loop through the controls of the dialog, looking at its type. We do some initialization actions for several classes of controls, by calling the TestInitDlg function. List boxes are filled a bit with some lines, edit fields are assigned an “Edit” character string, TreeViews are filled with some levels, etc. The idea is to simulate as far as it goes a working dialog box. The “progress” controls, need a timer, that regularly sends them “update” messages, so that they show a continuous progress, and when arrived at the end, they are again restarted, what provides a continuous display. Owner draw controls are provided a default procedure so that they show as rectangles. Drag lists are watched too, so that they receive the messages they need. 
When the user presses any button that has either the ID_OK or the ID_CANCEL identifier, the dialog box is destroyed. Note that in dialog boxes where those buttons are absent the only way to close them is to press the “test” switch in the toolbar to stop the testing.
Writing the .dlg file
This file contains the description of all the dialog boxes that you define with the editor in the ‘resources’ language. It is built by parsing the binary structures used by the editor, and emitting the corresponding keywords. This is a tricky business, especially when you consider the difficulty of interpreting correctly the different bits of the class styles. There is no simple correspondence very often between a bit and a style, but the signification of a bit changes if another is on, etc. This has been a constant problem, specially now in Win32 when you have more controls to worry about!

The code for this part is in dlgio.c  The principal entry point is the function Save,  called directly from the main window when the menu item is selected. It receives several flags, to indicate which type of save (normal or save as) is necessary. It will prompt for a name if save as is requested, and then call WriteTheFile, giving it the type of file to write (res, rc, or dlg).

WriteTheFile is straightforward, limiting its work to resolve the extension (dlg or res) and calling a specific function WriteRes, WriteRc, or WriteDlg.
Writing the .res file
This consists simply in writing all the binary structures to disk. A special marker is emitted as the first resource to mark it as a Win32 resource file. There is a perfect correspondence between the structures stored in RAM and the format of the file in the disk, so just a call to lwrite with the data field of each dialog resource list item is necessary. Note that the writing of the resource include header file is done here too. This is a special kind of resource that indicates the path of the include file that is used to associate the numeric codes for each control (or dialog) with their symbolic counterparts.

Writing the .rc file.
This was a new development. The problem was that weditres edited only dialogs, not accelerators, menus, icons, etc. That is why in the first time I generated a .dlg file, that was included in the main .rc file, where the ASCII descriptions for all other resource types could be written.

When I found time for it, and people pressed me to do it, I added the string table editor, and the accelerator table editor to the software.


Basically those table editors are not very difficult to do/use. They edit the string table, whose format was described in the chapter about the resource compiler, and the accelerator table.

The only interesting problem was how to enter the accelerator key... It's not easy to open a window just for keyboard input that will register correctly ANY key combination. One of the biggest problems is how to detect the ALT key, a problem that I haven't solved completely. The proper way to do it is probably to follow the WM_SYSCOMMAND message, but this detects the combination of Alt+F6 Alt+F4 and Alt+any ASCII key. The other Alt+FXX combinations aren't detected, and they do not seem to generate any messages.

Another problem is the writing of all the resources in ASCII form. This was solved already for the dialog boxes, but had to be done for the accelerator tables, for the string table, and for all the icons/cursors/whatever.
The big difficulty is to keep the association between the external files needed/used by the image resources, and the binary resource data. I modified the resource compiler to emit that information if given the (undocumented) /a option. That option makes the resource compiler write to the given file name a list of all external files used by the resource. The syntax is:
lrc /afilename.dat
At the end of compilation, "filename.dat" will contain a table of external files and the resource identifiers associated with them.

To complexify even more this already cluttered problem area, we have resource directories for the image resources, that add yet another set of problems. To make possible to write icons for different screen resolutions, an icon resource can be associated with several images, that windows at run time chooses according to the resolution of the user's screen. 

I had to figure out then, which resource to edit, within an icon file. I built correspondence tables, and solved (halfway) the issue.

What happens however, when weditres has loaded a binary resource file? The information about the external file is not available at all. I had two choices:
1) Modify the resource compiler so that it would understand a hexadecimal format, where I could enclose in the .rc file a binary description of the resource. Borland adopted this solution in their windows 3.11 resource compiler.
2) Edit/write the icons/cursor/bitmaps into temporary files, and generate a normal ICON resource statement for the resource compiler.

There are advantages/problems to each of the two solutions. If I would use 1), I would loose the compatibility with Microsoft's resource compiler.
Wedit: the Integrated development environment
History
This part of lcc-win32 is the oldest. I started working on an editor for programmers around 1989-1990. I used some code from the then popular ‘micro-emacs’ editor, to handle the display logic, mixed in a lot of code to handle the display, and had a functional editor that had the same functionality as window’s notepad, but without the limitation to files smaller than 20K...

Time passed, and I continued to work in the editor, adding the function list, the ability to jump to a symbol’s definition with a function key, and a ‘make’ utility..

I developed special purpose-parsers to be able to reparse a whole file in a 486-33 without much waiting. Programmers tend to be impatient, and a long wait is always something that puts people off This special purpose scanners just ignore most of the text, and concentrate in some sequence of characters of interest. This makes them very fast. No I/O is needed, since the text is already loaded in memory by the editor.

One of the earliest was the parser to scan for function definitions. That one only searches for the sequence of a closing parenthesis and an opening brace, ignoring white space and comments of course. This method is extremely effective, and easy to implement.

Another things that I added were a versioning system, software metrics, and then, the real-time syntax coloring of keywords/comments.

I built several utilities in the editor like ‘grep’, ‘diff’, a ‘camera’ to take screen snapshots, an utility to generate automatically .hlp files from the C sources, another utility to extract strings into .def files, the project management module, the keyboard configuration... the years passed by. 

I quitted my flat in the center of Paris to go to the suburbs, where I found a home with a small garden, and enough space to put the two children that Annie gave me.

And I went on building that system.

Programmers are bound to build ephemeral works. Nothing is left from all the programs we write. In a few years, all of our work is thrown away with that obsolete system we wrote it in, that can never be like the new one... just because its ridiculous hardware limitations. 

I wondered sometimes where are now those APL programs I wrote during the early seventies...Not even the docs of that Siemens 4004 are left, with that ‘enormous’ virtual workspace of 32K. And APL itself, has faded into the emptiness awaiting obsolete languages. ‘STSC’, the biggest ‘APL’ company has disappeared from view, and many people today have never even heard that name.

There were good concepts in that language though, concepts that I have been re-introducing into lcc-win32 with the ‘intrinsics’ interface. Operations with tables were the basics of APL. You could write in that language:
	C = A+B
A and B being vectors of the same size, C would become the element-by-element sum of A and B. The notation was simple, and very powerful.

This ephemeral nature of my activity was frustrating though.. I concentrated in Wedit because I tried to build something that would stand the judgment of the years, something that was worth working for. Most people are happy if they can work and are being paid for what they do. No matter what they do.

I don’t.

How to start an editor.
Wedit started with ‘multipad’ the MDI demonstration program that came with the Windows 3.0 SDK. It is an MDI application, i.e. it supports multiple windows with different documents open at the same time.

As you know, it starts in that function... WinMain. That function does all the initialization, and then enters the infinite loop processing the messages that windows sends.
Messages to the frame window are processes in FrameWndProc, messages to the document windows go to the MainWndProc procedure. The commands from the menu are done in HandleCommand. That function uses a dispatcher table, to each of the function that treats a command, mainly in the file command.c.

Commands lead very often to a dialog box. In command.c you will find the association between a command and a dialog box in the form of:

void HandleNewProject(void)
{
...
		r = CallDlgProc(NewPrjDlg, IDD_NEWPROJECT,&tmpPrj);
}

This means that the dialog box with the numeric identifier IDD_NEWPROJECT and the dialog procedure NewPrjDlg, will ask user input to treat this command.
When you want to find out the sequence that associates a dialog box procedure to a command you just have to follow the association from the command dispatcher to the function that processes that command in command.c, to the dialog box procedure mostly in dialog.c.

Of course, there are a lot of commands that do not involve any dialog box: Cut/Paste, and many others.

Other messages that windows sends are important: WM_PAINT is one of those.

Coping with legacy code
Software is developed with a specific machine, and it runs under a specific version of a concrete OS. This imposes to the software certain limits, certain conventions, etc. It is really not the same if you are limited by the power of a 386DX-16, with real RAM of 4MB, and with a 16 bit OS, or if you run under a Pentium 200MHZ with 64MB of RAM under a 32bit OS. No, it is really not the same at all.

Windows imposed in its first versions a lot of limits to the programs. Data couldn’t be handled in chunks of more than 64K at a time, the machine power at your disposal was limited, and many idiosyncrasies of Windows entered into your design. One of the most dangerous, as it turned out, was the reliance on global variables.

Why global variables?
Globals are a very fast and efficient way of passing arguments from a procedure to the next. Since all is implicit, the machine saves the pushing of the arguments, and the restoring of the stack frame afterwards. Besides this, the event-driven nature of windows, and above all the interface of the dialog boxes, made much easier to communicate with dialog boxes using some global variable than to explicitly pass the parameters. 

Of course, you could pass your parameters to a dialog box procedure, but the way of doing it was (and still is) very cumbersome. You had to call another function, not the usual DialogBox, and pass a parameter to that function, that windows would then pass to the dialog box in the WM_INITDIALOG message. Even more difficult was to return results. You were limited to a 16 bit signed number. That was all. You couldn’t return any pointers, and you were forced to use globals to return pointers.

It would have been possible to return values in a structure, whose address would be passed to the dialog box function at entry, stored in a static area, and then used to store all results of the dialog box. But then, you would have to reserve a static area of at least 4 bytes for each dialog box. This looks quite acceptable today, with 64MB of RAM, but in the environment of windows 3.0 and windows 3.1 you had to solve a difficult problem: you were limited to 64K of space for holding all the initialized data of the program, all static data, and all the stack...

Fitting all the tables of Wedit, all the character strings used somewhere, and all the stack into 64K was an incredible difficult undertaking. I moved all the strings to the resources, doing a string table, and tried to allocate the data from the heap instead of using static or global data.

In this context, using 4 bytes for each of the several dozens of dialog boxes that I had already built, seemed out of the question.

So I used globals, especially one called ‘OpenName’ that contained a file name that many dialog boxes returned from user input.

And once this started, I got used to it, even later, when I moved to windows 32 bit. In that system, many of the horrible constraints that had formed my software disappeared, but then, I was confronted with the problem of changing all those globals to something more readable, a work I started leaving always for tomorrow. We all develop software under time constraints, and that code was unreadable yes, but it worked. Changing it, I knew, would inevitably bring a new set of bugs that I could happily live without...

So, my code became legacy software: running, but unmaintenable.

I have only recently started to invest into eliminating all globals from Wedit, and forcing upon myself a discipline of globals usage. The problem with them is, as I painfully discovered, that I couldn’t understand what the code was doing in many places, and that it became impossible to add easily new features. There was always some trashed global that would either provoke a trap or just provoke bad results. I was forced to clean it up.

Maintenance work is inevitable, and it is better done in small chunks at each change, than left for later, when its bad results accumulate, provoking other bad consequences that have to be eliminated too. For instance, you can abstract away a global if you save its value before using it, and restore it later, but this is a step in the wrong direction of course. Later on, you have to eliminate the global anyway, and then you have to eliminate the code that you are just adding...

How does Wedit work
Wedit consists of different components: the editor, the debugger, make file generation utility, other utilities etc. Here is an overview of each one.

Window structure of Wedit:

Main application window (Frame window)
Manages the menu, and the application start/exit sequence
MDI Client
Manages the document windows
Open files toolbar
Manages the file list display
Output window
Manages editor output
Document 1
Document 2
Document n
N buttons, each with a file name
Sub classed listbox
Lower left buttons

The main application window cares for the following tasks:
1. Creating the mdi child window
2. Dispatching all menu commands
3. Finalizing the editor at applications exit
A child of the MDI client window handles each open source. The window procedure for those windows is quite complex, since handles all tasks touching the input and display of program text.
The open files toolbar is an independent window that just displays the open file names. It has some code to resize itself to the right size given the names it contains. Each name is drawn in an owner draw button. Those buttons send to the main frame window commands to change the display from one source file to another.
The output window at the bottom of the editor should display all utilities output, make (build) results, and debugger displays. It contains a list box, and some owner draw buttons at the lower left.
Editor
The editor is a normal MDI Windows application. It uses no controls for drawing or selecting text, all is done by logic within the editor itself.50 The procedure for managing each document window is the same, of course, as is the case for most MDI applications. 

Scrolling is done either with the ScrollDC primitive of windows, or just by redrawing the whole screen with a different line origin. Normally, ScrollDC is used when the whole screen has to be shifted only one line, redrawing is preferred in other cases. The smooth scrolling effect is done by scrolling the whole screen just 1 pixel at a time (in the case of very smooth scrolling), or at most 3-4 pixels. This effect allows for text that appears to scroll slowly and smoothly, instead of the "jump" feeling of normal scroll of a line at a time. In fast machines (more or less any machine today), the slowdown is barely perceptible.

The selection is managed by using a region list, and inverting it. There are still problems with this in some cases, because keeping a list of regions to updates becomes fairly complex if you want to follow arbitrary mouse movements. In retrospect, a simpler algorithm of just keeping a selected region of rectangular shape would be much easier to implement.

Proportional fonts are supported in theory, but this is not well tested. Normal programs look so horrible with proportional fonts that I have barely tested this feature. It is assumed in most of the code that the user has chosen a fixed font, what greatly simplifies the drawing, specially the drawing of the selection.

The 'Undo' feature is one of the most acute problems in the editor. It is implemented as a circular list of commands to undo, but it has many problems, especially because not all the commands can be undone, sometimes because the effects of adding a new command to the user interface weren't done in the 'Undo' counterpart.

The ‘Autosave’ feature
Sometimes the computer will crash, or Wedit will crash. If you have been working for hours in a set of programs, this can be highly annoying…
The ‘Autosave’ feature will save any modified files into a dedicated directory51 regularly after 3 minutes. It works like this:
At program startup or when you check the corresponding check-box in the configuration tab, the autosaver is started. Each 3 minutes windows will call the autosave function.
This autosave function will go through the list of loaded files, looking for the ones that have been modified and do not have the ‘autsoaved’ flag set. Each one of those files will be saved into the autosave directory and its ‘autosaved’ flag will be set.
Each time you make any modifications to the text of a loaded document, the ‘autosaved’ flag will be cleared.
At program exit, all files that have been written to the autosave directory will be erased.
When the program starts, it will look in the autosave directory for any files that may be present. If there are any files in that directory, it can only mean that a crash has occurred. It will ask the user whether he wants to restore the files, and act accordingly.
The autosaved files will contain a contents line (the first line) with a format like this :
Autosaved <file name> <time stamp>
This allows wedit to restore the file to its original location.
Real time coloring of text
Two different problems arise with coloring text.

The first is to find out where all the comments start and end. The second is to display the text that is NOT a comment, according to the keyword table.
Comments
To find out the comments I scan the entire file, storing the information in a linked list. Then, I find out the comment (if any) that begins just before the screen that the user will see. I save this comment in the screen display structure.

This is done in the file edit6.c, in the functions FindComments. That function goes through an indirection because Wedit supports other languages than just the C language. Each document has a document type, and the type of language of the document determines which function will return the list of comments. The type of a document will be set at load time (in edit4.c), and is deduced from the name of the file.

Wedit supports both kinds of comments that the C language has specified. This is not important for the description of the comments we are interested in: we just want to know where they start and where they end, that is all. We assume that for a comment that spans several lines, the start column and the ending column will use the whole line, that is all.

Keeping that comment list in a consistent state with the text in the document is not really an easy task. The user is constantly changing text, lines are inserted, deleted, whole blocks of text arrive and disappear, and that list must be consistent at all times, and updated in the screen in real time, i.e. immediately after each character is typed.

To avoid spending too much time rescanning the whole file at each character typed, the following assumption is used:

When the user makes a change to the file, it MUST make a change in the visible part of the file. Keeping a pointer to the comment just before the visible portion of the text allows me to start re-scanning the comments at that point, instead of re-scanning the entire file from the beginning.

There are many events that can force a reconstruction of the list, or a partial build beginning with the last comment:

A letter typed in a sensible place: For instance you have:
/* This is a comment */
and you type a ‘b’ just after the first ‘/’. The editor should immediately change the color of the whole comment to normal, since it is no longer a comment.
A sensible character: For instance you type a ‘*’ after a slash. All the text up to the end of the display should change color (if there are no intervening comments of course).
The delete char has to be tested for the same reasons. And block move operations as a matter of course.

Once the comments are found, we can draw the rest of the text. At each word, the editor looks up the current keyword table to see if it matches, and then draws the text according to the current color table.

At each character typed, wedit calls for the current document language, the function that filters the characters for comments. This is done in edit3.c.

The key components of the system are:
UpdateDisplay(), in edit5.c This function orchestrates the whole display refreshing.
FindCComments(), in edit6.c. This function rescans the source file, rebuilding the comment list.
Keywords
Keywords are displayed in a (user configurable) color. The list of keywords is not fixed but can be dynamically modified by the user, using the ‘Configuration’ menu. The key components of keyword displaying are:
DrawProgramText() in file edit5.c. This function does the actual display, and parses each line looking for keywords. Its structure is overly complex since FORTRAN, and PASCAL are supported too.
IsKeyword() in file edit6.c. That function determines, using the current language of the document, if the given word is a keyword or not.
ChangeKeywordsDlg(), in dialog.c, handles user interaction in the dialog box that manages the keyword list.
Special cases have to be handled, like, for instance, pre-processor directives, can contain embedded blanks:
#ifndef
is equivalent to
#     ifndef
and both should be colored.

Representing text

For each file loaded, Wedit stores a circular linked list of lines. There is one special line, called HeaderLine that represents the beginning of the text. Each line has a pointer to the next line, and to the previous line. The way of representing this, is a structure with a fixed header, where the pointers to other lines are stored, together with other information, and a variable length part that follows, and stores the actual text of the line.

typedef struct  TEXTLINE {
        struct  TEXTLINE *NextLine;
        struct  TEXTLINE *PreviousLine;
        short   Size;
        short   Used;
        char    Flags;
        char    Text[1];  /* Variable length part */
}       TEXTLINE;

The ‘Flags field only is uses one flag: whether the line is a breakpoint or not. It has unused space for other possible uses, like hidden lines, for instance, a thing would be nice to have but a pain to implement.

Note that the fields ‘Used’ and ‘Length’ are signed shorts, so lines longer than 32K are not supported.  For each line, there is an overhead of 13 bytes... not very space efficient. But it is a fast design, that allows you to go easily (and fast!) from one line to the next/previous. This structure is allocated when the line has been read from the file, and only one allocation is done, since the header and the variable part are allocated as a block.

Even if only one allocation is done, for run time systems like windows, where the library function can be very slow, it is nice to have a fast memory allocator. Under windows 3.11 I wrote a memory allocator specially designed for Wedit, since under that system, memory allocation was a complete mess52. I wrote it in assembly, and was real fast, but when porting it to win32 I discarded it. I decided to use ‘malloc’, since it works again...

That wasn’t a really good decision, since the library function malloc from crtdll.dll is really slow. Most of the loading time of Wedit (approx. 88%) was spent in that allocation function.

This problem became apparent when I compiled gcc 2.7 with lcc-win32. It took Wedit 44 seconds to load the 88 files that make that software package. This was very bad when I compared it to MSVC 4.2 that loaded the files in 13 seconds. So I decided to do a quick memory allocator, specially designed to allocate big chunks and split them into smaller ones, avoiding too many calls to the library functions.

I used a simple design: I have a table of slots, each slot having a list to blocks of the same size. At the beginning, I had just a power of two function, i.e. each slot would contain a list of blocks of twice the previous size. But this leads to an enormous amount of wasted memory, so I created slots of different sizes, to better fit the allocations done in Wedit: small blocks of maximum 600 bytes, mostly between 50-250 bytes. The algorithm for the allocator is then, very simple:
Find the slot that contains enough space for the demanded size. If the size is larger than 1K, I just call GlobalAlloc(), and do not worry about that block any more.
See if the list of blocks at that slot is empty. If it is, I allocate around 4096 bytes, and make a linked list within the allocated block.
Take the first block of the list at the given slot, and move the head of the list to the following block, if any.
Return that block

The symmetric function, to free a block, just tests to see if the size is bigger than 1K. If it is, I call directly GlobalFree(), since it is not in the table. If the size is smaller, I add the block to the list of free blocks in that slot.

This very simple scheme allowed me to reduce the load time from 44 seconds to only 6. It has his weakness of course: I never return the memory to the OS for the small blocks. This means that if you load a multi-megabyte project, and then load a smaller one, the memory will not be returned. But I do not think a rewrite of malloc() is justified. It is much simpler to quit Wedit and then reload the new project... this will free all unused memory, and now it goes so fast, that it is not a big problem.

Lines come and go, characters are inserted/erased, etc. When I allocate a line, I allocate some extra space, so there is no need to reallocate the line structure for each character typed in. When a line is deleted, care must be take to correctly update the pointers to the next/previous line, and update the pointer in the neighboring lines too. This is done mostly in the source file edit3.c.

A weak point of this scheme, is that there are many pointers to global lists, like the bookmark list, the breakpoints list, etc, that need to be updated each time a line is deleted. This is a very error prone process, but I haven’t been able to design a better one, and since this schema is working, the inceptive for improving it is low, as you can imagine.

Big troubles gave me the comments list, that needs to be kept in synch with the list of lines in the file: it is a bad idea to keep pointers to erased lines!

The problem is aggravated by the fact that each time you type more characters than the line can hold, the old line structure is copied into a freshly allocated line, and is then released. Again, all the global lists must be kept in synch.

It can be argued that a better design could have made these problems less painful, but I have serious doubts about that. Any editor lives in a perpetual world of change, and it is very difficult to keep fixed points to text regions in the middle of all possible insertions/deletion sequences. For instance, what should the editor do when a line is erased that contains a breakpoint? Should the breakpoint go to the next line or to the previous one? Decisions, decisions. I decided that any editing would erase the breakpoint. Period.

The files that the editor reads in are organized in TEXTBUFFER structures, that contain the file name, and general things about the file, like the list of functions, the list of comments, the pointer to the current line (i.e. the line where the cursor is), the pointer to the selected text, and other things.

There is still some fields like ‘WindowCount’, and should make possible to implement multiple views of the same buffer, but early during the construction of the editor I decided to ignore this feature, that is seldom used.

In this TEXTBUFFER structure I keep a numerical representation of the time stamp of the file. When Wedit regains the focus, it will search the date of each file in the disk, and compare it with the stored date. If there is a difference, it means that the file has been changed from outside the editor. The user receives a warning and is asked whether to reload the file from disk or not. This detail, and thousands of others together make for a good editor.

Together with this TEXTBUFFER structure, there is a WINDOWTEXT structure that is created for each opened MDI window. It contains a pointer to its TEXTBUFFER, but more screen oriented information, as opposed to the file oriented information in TEXTBUFFER. Here is stored the current row (row in the window) the current column, the number of text lines this window can hold, etc. Windows can be of any size and shape, gone are the good old days of 24 lines and 80 columns that made so easy the life of editor writers in the middle of the 80ties.

Software dust

These structures are very old. Their basic design was done around 198053, and they have stayed like that since then. It is a proof of how lasting the code written in C can be, that this set of data structures and procedures, has survived intact from the days of windows 3.0 to 1998. It is a pity the editor doesn’t put dust into old code, so we could readily see when some code is old. But, as software goes, some editor writer will surely do this somewhere in the near future. 

The rationale for ‘dust’ is not so far fetched. I am sure it would be interesting to know at a glance what has changed in a file, since some date back in the past. The problem with organizing the code in files, is that there is only ONE date for all the lines in there. There is no way to know which parts of the file are new, or old. Everything has only one time stamp. It would be feasible (and not very complicated actually) for an editor, to store an array of dates for each line in the file, that would hold a time stamp so that it could be possible to know which year that line was written, and which month that other one, and by whom...

It is interesting to note that the text representation of programs hasn’t changed since more than 30 years. I am not arguing we should store programs as other things as text, but some essential features are missing. The argument of space is gone with the huge disks of today’s computers, and the argument of slowing down compilation is gone too, since the editor could strip date information from the program text when saving, storing two files instead of one.

The virtual screen

Text in the TEXTLINE structure is not directly drawn in the screen. The editor passes through a virtual screen image, where tabs are expanded into their positions. The text is copied from the lines into the virtual screen at each display. The virtual screen holds the contents of the currently active MDI window. The structure used is the following:
typedef struct  tagSCREEN_IMAGE {
	int	flags;
	int     Selectionstart;
	int     Selectionend;
	int     LastCol;
	TEXTLINE *TextLine;
	COMMENTLIST *Comment;
	char    Text[1];
}    SCREEN_IMAGE;

The flags field is used by the debugger to show the breakpoints and the current source line. Note that this is not a list. It is a table of such structures that make the virtual screen. This imposes that at startup the editor will have to decide what is the longest line that it will support. Currently that limit is fixed to 512 bytes, but this can be changed by editing the constants SysMaxRows and SysMaxCols in edit1.c.
Again, a better design would have made this a list, with variable length screen lines, so that the editor would support lines of any length. Is this an issue? I do not think so. The editor has been in use for years without encountering any problems but once, when I attempted to load a C file with embedded PostScript that contained a single line like this:
static char *Text = «  ..... 512k of Postscript ... « 
This virtual screen, will be displayed by the function UpdateScreen(), that lives in edit5.c.
The algorithm of that function is just to loop by the number of lines, calling DrawProgramText or drawing the comments, as indicated by the corresponding pointers in the SCREEN_IMAGE structure.
Handling the keyboard
Wedit doesn’t use normal accelerator tables, contained in resource files. This was forced because of the need to allow the user to change the keyboard bindings, and accept them dynamically. The format in memory of the accelerator tables used by windows was poorly documented, and it seemed to me easier just to process the raw keyboard event, and then lookup in a table if the key combination corresponds to an accelerator sequence or not. In retrospect this was a wise decision, since the format has changed surely between windows 3.1 and Windows 95, and maybe will change again for the new releases of windows.

Some keys deserve special treatment, like for instance, the arrow keys: Wedit ignores the type ahead, and will only process one of those messages, even if there are more. The reason is that it is better to stop scrolling instantly when the user releases the key, rather than scrolling beyond the goal... This is less of a problem now, with very fast machines being the norm, than it was when this part of the editor was written, in a 486/33.

Some function keys are active only in the context of the debugger that has a special accelerator table. Roughly the handling of the keyboard goes as follows:
Special keys like arrows, or Page down/up are handled with the WM_KEYDOWN message.
Normal characters are handled with the WM_CHAR message. Macros are searched for first, and if found, expanded. Other characters go into the InsertChar() function, that process them further into the text buffer.
The WM_KEYUP message is used to erase any typeahead for the up/down arrows.
The escape character is used to implement the ‘completion’ feature. This feature allows you to type just the beginning of a word, and then type escape. The editor will search all known identifiers and select all those that begin with the same characters. If there is only one it will be inserted right away, if there are more the user is presented the choices available.

The central function for keyboard handling is the HandleWmChar function in edit5.c. This first processing stage receives the raw message from the windows system. It handles the escape key, the control-xxx macros, backspace, tab, return key specially, and if there is a real character waiting to be processed calls the InsertChar function in edit1.c.

This function, the second filter, handles the OVERWRITE condition, filters other chars, and eventually calls the LineInsertChar in edit3.c. Here the actual text is entered into the editor, and all the necessary updates are done. When inserting a character, the line length could make that the line is reallocated. In this case all structures that contain this line pointer should be updated with the new pointer. This is a weakness of the design. Originally, there existed few lists of lines, but the need to associate lines in sets arises in many contexts, so this has become a bottleneck for saving information.

Before inserting the character typed in the text, InsertChar will see if the character was a closing brace. If it was, it will do the necessary indenting, to close a block scope;54

The LineInsertChar function (in edit3.c) is where the real work of inserting a character is done. It will first look if this is the special case when the line being edited is the last line of the buffer. If it is, it will allocate a new line structure and insert the characters. Next time that you type a character, that line will not be the last.

This done, we come to the normal case. If the new character makes the current line be longuer than its allocated length, a new line must be allocated with more space, the old text must be copied into the new one. If a bookmark pointed to this line, the bookmark is made to point into the new line, and the old is released.

If there was enough space, the character is inserted into the text of the line, and we are done, since we haven’t modified any pointers. We go then through the text window list, and find the window text descriptor for this buffer, updating any mark (selected text) that may be there.

If we have added a line, we have to update the comment list, to avoid preserving a pointer to the old one. Besides, the length the comment could have changed, if the user was typing in a comment. We update this.

Since we have modified something, the history list that keeps the list of visited functions must be updated too. 

And we aren’t done yet! The character typed could introduce or destroy a comment. We have to take care of that possibility, and we call the function that checks for this possibility. Since this is highy specific to the language we are displaying, we call a function pointer that is contained in the “language” structure. Each document has a (possibly NULL) pointer to its language descriptor, fo the sets of supported languages.

If the user was typing something within the name of a function, the current function name at the bottom right of the editor needs to get refreshed with the new name too. This is done by CheckFunctionNameChange, a function in edit3.c.55

If this looks like a lot of work to do when just a character was typed, consider that with modern machines, this takes probably far less than a millisecond, i.e. the editor is finished with all this  processing before you have had the time to leave the key that you pressed.

With regrets then, it was so fast… we leave LineInsertChar, return to InsertChar, that just returns to HandleWmChar, that takes care of the undo feature, and calls ReDraw. And here another story begins.

Redrawing the screen.

The function ReDraw checks if there is something to do by looking the flags field of the current window text descriptor. If it has something to do, it will first check the framing, i.e. will ensure that the cursor is visible in the screen. We ignore what is inside that function for the moment, and suppose it works OK. The next thing to do is to update the virtual screen, i.e. the buffer that the drawing primitives use to actually draw the text. This is done by UpdateLine in edit1.c, but again we ignore what happens inside, and we just go on with the general outline of ReDraw. Next is to update the current position, that could have changed. This is done by UpdatePos, in edit1.c.

Now, at last, we are ready to actually redraw the line with the new character. We call the function UpdateScreen that lives in edit5.c, that does this.56

UpdateScreen first chore is to get the device context (HDC) of the current window. It is stored in the text window structure. Then, we update the selection, and take care of drawing it.
We move the caret with MoveCaret , and we hide it, since we are going to draw some text, and the caret could leave ugly traces if we do not do that first.

We start then a loop for all rows in the virtual screen, and draw the text. If there isn’t any, we draw the background only. Wedit accepts a user configurable background color that is put into the screen with the FillRect API. But that’s the easy case obviously. More complicated stuff is left to DrawOneLine, that has to handle the comments, the keyword colors, the left margin, etc.

After the loop is finished and we have redrawn all lines, there could still be a problem if the last line didn’t exactly end at the window’s height. We clear the last empty rectangle and we are done. We validate the window rectangle so that we avoid any more WM_PAINT messages, we show the caret and we return.

Drawing a line is straightforward, in principle. It draws the possible icons at the left for the debugger, it draws the comments, and calls DrawProgramText for drawing the text with the keywords in the current keyword list colored according to the color the user has decided for keywords. If the line is longuer than the window”s width, it draws a rectangle after the last char, to signal that the line goes on.

Other things that DrawOneLine does, is to take care of the background color if the line to be drawn is the current line in a debugging session. Here comes the yellow color of the position the program is executing that you know from the debugger display. If the line has been marked as part of the selection, the colors are inverted.

DrawProgramText uses the TextOut API to put the text in the screen. Besides telling you that, let’s not speak much about it. It is very complicated, because of the need to support multiple languages, determine what a keyword is, etc etc.

UpdateScreen returns to ReDraw, and ReDraw returns to MainWndProc, case WM_CHAR. We have followed the whole process that happens when you type a single character in the editor.

Of course, there are other situations. If you type the down arrow at the last line in the screen, the text has to be moved up. To avoid flickering, I move the whole bunch of lines up with the ScrollWindow API, and draw just one line at the bottom. If the user has selected more smooth scrolling, I make several scrollings, with a finer increments than a character.
Handling the selection and the clipboard
Each time that MainWndProc receives (or looses) the focus, the current clipboard has to be exported/imported to/from windows. This is done in wproc.c, in the function SaveClipboard and ImportClipboard. The code for inserting or deleting text from the editor is in the file edit3.c.

Each time the frame window of Wedit receives the WM_KILLFOCUS message; the clipboard is filled with the editor’s clipboard. Each time Wedit gains the focus, it imports the system clipboard. The functions for doing this aren’t very complicated, and described in many books about Windows programming. They are in wproc.c.

Much more complicated is drawing the selected text in inverse video, and following mouse movements when selecting. This is done in edit5.c using a set of regions. The intersection of the old region, that contained the text already drawn in inverse video, and the new region with different text is found, and then that intersection only is drawn. This is done in DrawSelectedRegion(), in edit5.c.
That function looks like this:

static void DrawSelectedRegion(HWND hWnd, int col, int line)
{
	HRGN ToInvertRegion;
	HDC hDC;
	hDC = GetDC(hWnd);
	NewRegion = BuildNewRegion(hDC, line);
	if (DrawnRegion) 
		ToInvertRegion = FindIntersection(DrawnRegion, NewRegion);
	else
		ToInvertRegion = NewRegion;
	UpdatePos();
	MoveCaret();
	HideCaret(NULL);
	InvertRgn(hDC, ToInvertRegion);
	ReleaseDC(hWnd, hDC);
	UpdateStatusLine();
	ShowCaret(NULL);
	if (DrawnRegion) 
		DeleteObject(DrawnRegion);
	DrawnRegion = NewRegion;
	if (ToInvertRegion != NewRegion)
		DeleteObject(ToInvertRegion);
}
The editor keeps in a global variable, the point where the user started initially to select text with the mouse. All parameters like ‘line’ are relative to that screen position.57

First, a new region is built, from that point to the end of the line where the mouse is. Then, the intersection is found and drawn in inverse video. The other functions just take care of the myriad of details that should be taken care of when doing this: maintaining the line number and column, hiding the caret, etc.

Maintaining the status display
Wedit assumes that the user wants to see a maximum number of lines of his/her program, and tries to avoid taking any space for status lines, tool bars, etc. Modern IDEs are horrible, from this point of view: the program text almost disappears from view, hidden beneath a thick layer of status lines, buttons of all sorts, docking windows, what have you. All this hides the essential of an editor: the text.

Following this philosophy, I decided against any status line that would occupy precious screen real estate, and implemented a ‘status line’ in the window’s title bar. This way, I used a line that is almost empty, and has to be there anyway. I use the WM_NCPAINT message, to repaint the portion of the title bar that interest me with:
The name of the function the cursor is currently in, if any.
The line number
The column number.
Wedit is the only programmer’s editor, as far as I know, to maintain at all times the name of the current function in its status line. This is extremely useful for small screens, where most of the time you have to page down/up to find out where you are. Even in a 17 inch display, common nowadays, you can see at most 40-50 lines, depending of the font selected, and functions longer than that are common in C.

This feature wasn’t easy: the parsers must cope with syntax errors gracefully, since the user is modifying the text permanently, comments can be unclosed, parentheses mismatched etc.
Since the special purpose parsers ignore most of the text, they are fairly robust, but they do get lost when momentarily, the number of braces doesn’t match. In those cases the display will show only the line number/column.

Handling dialogs
Dialog boxes are the standard way of user interaction under windows. Here is where object oriented programming languages shine, and C... well performs, but it is not so adapted. Messages arrive at each dialog procedure that has to be written to answer to events in the dialog. All of them have the usual structure of a big switch statement, that handles all the messages they want to handle, and pass all the other ones to the default HandleDefaultMessages(). That function will automatically end the dialog with a return code of zero if a Cancel button is pressed, 

Under windows 3.1 it gave a look to the dialogs similar to what they look now: group boxes had a 3D look, check boxes were less horrible, and similar to the ones I saw under OS2, and other enhancements to improve the look. Those enhancements were all dropped under Win32, but still, that function allows you to move a dialog box around just by pressing its surface somewhere, as if the whole dialog was a big button. This is done by treating the button up/down messages and making windows believe that the caption was pressed:

	case WM_LBUTTONUP:
		if (wParam == HTCLIENT) {
			SendMessage(hDlg, WM_NCLBUTTONUP, HTCAPTION, lParam);
			return (1);
		}
		else
			return (0);
	case WM_LBUTTONDOWN:
		if (wParam == HTCLIENT) {
			SendMessage(hDlg, WM_NCLBUTTONDOWN, HTCAPTION, lParam);
			return (1);
		}
		else
			return (0);

List boxes need to be subclassed to really implement in only one place the handling of the horizontal scroll bar, that (I do not know for which reasons) is not done automatically by windows.

This is done in the function SubClassListBox, in dialog.c.

LRESULT CALLBACK SubClassListbox(HWND hwnd, UINT msg, WPARAM mp1, LPARAM mp2)
{
	int i,count,width,lbwidth;
HDC hDC;
	DWORD textExtent;
	HFONT hOldFont,hfont;

	if (msg == WM_PAINT) {
		count = GetListboxCount(hwnd);
		if (count == LB_ERR) goto dodef;
		width = 0;
		hfont = (HFONT)SendMessage(hwnd,WM_GETFONT,0,0);
		hDC = GetDC(hwnd);
		hOldFont = SelectObject(hDC,hfont);
		for (i=0; i<count;i++) {
			SendMessage(hwnd,LB_GETTEXT,i,(DWORD)buf);
			textExtent = GetTextExtent(hDC,buf,strlen(buf));
				if (LOWORD(textExtent) > width) 
width = LOWORD(textExtent);
		}
		SelectObject(hDC,hOldFont);
		ReleaseDC(hwnd,hDC);
lbwidth = SendMessage(hwnd,LB_GETHORIZONTALEXTENT,0,0);
		if (width > lbwidth) {
			PostMessage(hwnd,LB_SETHORIZONTALEXTENT,width,0);
			return(0);
		  }
	 }
dodef:
	return(CallWindowProc(lpLBProc, hwnd, msg, mp1, mp2));
}

At each WM_PAINT message, I look if there are any items in the list box. If there aren’t I skip everything and call the normal windows procedure that I saved previously in the lpBProc function pointer.
Else, I get the font currently in use in the list box, then I loop, calculating the length of each text line in the dialog box. At the end of the loop I get the current horizontal extent for the horizontal scroll, and see if it is smaller than the length of the longuest text line. If it is, I reset it and return zero, another WM_PAINT message will be send anyway when I reset the horizontal extent, so there is no need to produce flickering.

Note that I use things like GetListboxCount, that isn’t really a windows API but just a small function that will SendMessage(hLB,WM_GETCOUNT,0,0); to the list box window. It is amazing how much code space you can save by encoding frequently used functions with similar arguments this way. All the machinery of subclassing teach list box in the whole application is done only once, in the HandleDefaultMessages function. In this way, I can make big changes to the whole user interface without repeating it everywhere.

There is an attempt, that I never finished, of doing resizable dialog boxes, i.e. those that resize their components as their size changes. This is a development project in its own right, and I implemented only the strict necessary to make the binary editor that is really a dialog box, resizable.
Handling the bookmarks: what is important in a user interface?

There are bookmarks in the editor, i.e. fixed points where the user can make a jump with a simple selection or with the key Ctrl+F7.  The bookmark list looks in principle quite simple: just make a list of file and line locations, and be done with it. 

The problems appear however, when we examine this problem in a real environment. What happens when the user adds lines between the beginning of the file and a bookmark? Does the bookmark move too? Obviously it should. 

This is solved by maintaining a pointer to the specific line where the bookmark is placed. As lines are edited from/to the line list, we keep a pointer to that line, and it will move automatically with all editing actions. But this efficiency comes at a price: each time this pointer changes, either because the line has grown and must be reallocated, or is erased, we have to avoid letting a dangling pointer creep in.58

Other editors use other solutions. In the IDE of Visual Studio, you can name bookmarks, and you jump to a named location.59 I found that interface much more difficult to use than an interface where you can see the text of the line where the bookmark points to. First, you have to figure a name for that place, what imposes a certain effort from the part of the user, then you have to type it in, and last but not least, you have to remember what place this bookmark is pointing to. That is surely much more difficult than just pressing the F7 key at the place where you want . From the user efficiency point of view (the usability of the software) the second interface wins.

Then, when you want to jump to a bookmark, the user interface doesn’t show you the text, just the name of the bookmark, the file and line number.  The user has to remember what those names stand for. Programmers have to remember a lot of things. It is just a waste to use-up valuable brain memory to keep track of this details. I decided that a user interface without any user action is obviously easier to use than any other.

Then, there are the add ons. Ctrl+Shift+F7 will allow you to go to the next bookmark, and cycle through all the points you have defined in any of the loaded files. This happens quite quickly, and if you have defined only a few boomarks, you can avoid the dialog box asking you which one you want, what is less disruptive of the work in progress than a dialog, where you have to break your current line of thought.

This are the things to watch in a user interface: the user’s point of view. Of course, there are many places where Wedit’s interface isn’t intuitive, but that doesn’t imply that this basic truth is wrong, to the contrary. It only shows that it is a difficult goal to attain.

The output window
This window is a direct child of the main MDI frame window, i.e. is a sibling of the MDI client window. It consists of a list box control that provides a convenient way of having clickable lines of text. It is this window that manages the display of the status at the lower right, and displays all output of the debugger, the GREP search utilities.

For each utility that should display something in this window, there are several handlers defined: the 'build' display is managed by the 'make' utility, the 'search' display is managed by the GREP display, etc. Each handler has basically two functionalities: filling the display, and reacting to a click in a line. This is managed by a table of function pointers that is changed each time a new class of display is active. Each of this functions maintains its own data, so that the window doesn't have to take care of saving and restoring the actual data displayed.

The buttons at the lower left are owner draw buttons that use the standard window bitmaps for slightly different purposes. You can obtain from windows those bitmap by using the LoadBitmap primitive, and passing special arguments to it. This has the advantage of providing a known visual interface (those bitmaps are displayed in every window of the system), and saving space to store custom made bitmaps. They are drawn using the BitBlt primitive, according to an internally maintained state descriptor.

I achieve the effect of buttons that raise themselves when the mouse is over them very easily by handling the WM_MOUSEMOVE message. When the output window receives that message, it sees if the mouse is over one of those buttons, and draws it accordingly. The 3D effect is easy to simulate by using the DrawEdge primitive. The code to do that is like this:

hDC = GetDC(hwnd);	// Get the device context of the button window
GetClientRect(hwnd,&rc);	// Get the rectangle of the window
// Draw a raised edge around the left and top borders
DrawEdge(hDC,&rc,EDGE_RAISED,BF_ADJUST|BF_LEFT|BF_TOP);
// Draw a different edge around the lower and right edges, to provoke an illumination effect.
DrawEdge(hDC,&rc,EDGE_RAISED,BF_ADJUST|BF_FLAT|BF_BOTTOM|BF_RIGHT);
ReleaseDC(hwnd,hDC);
SetTimer(hwnd, 10500, 200, NULL);

Note the last line that sets a timer to redraw the button after a certain amount of time has elapsed. This way, the button checks regularly if the mouse has left, and if it has, it will redraw itself without the borders.

The output window can be resized in the vertical direction. This is achieved using the WM_MOUSEMOVE message and checking that the mouse is under the border that separates the output window from the rest of the open document windows. If it is, the shape of the mouse cursor is changed, to provide a visual feedback to the user. If the user presses the left mouse button, the 'BeginDrag' operation begins. This just captures the mouse, and follows the mouse drawing an horizontal bar using the whole length of the MDI frame window's client area. To avoid leaving traces when drawing/undrawing this bar as the mouse moves, a special window is created at the start of the drag operation, and destroyed when the drag operation finishes. Since that window shouldn't receive any input, it is just a static control class window. This way, it is the responsibility of the windows system to redraw the window. This simplifies the code, and follows the basic principle of good Windows design: if Windows does it already, do not rewrite it, just use what Windows provides.

When the user releases the mouse button, the drag operation finishes, the static window is destroyed, and the height of the output window is recorded. I implement in the drag function a special 'Message loop', getting windows messages, and examining them. If it is a message that indicates that the user has pressed the ESCAPE key, the whole operation is cancelled. If it is a mouse move operation, there is a check that the new coordinates are well between the maxima/minima that the output window should have, and only if this test succeeds, the bar is moved. This makes it impossible for the output window to put all text windows behind it.

The output window can be 'detached' from its 'home' at the bottom of the editor, and make it a standalone window that can be resized and moved around independently of the editor. This is done by checking for WM_LBUTTONDBLCLK messages that actually create a dialog box of the same size as the output window. The output window is not destroyed but just made invisible. It continues to process messages as before, but all messages go now to the dialog box. This dialog box creates the list box in the processing of its WM_INITDIALOG message, and processes the messages of the output window in the same way.

To achieve the effect of a 'dockable' window, the list box processes the WM_NCLBUTTONDBLCLK message that is received when the user clicks in the title bar. This messages provokes the destroying of the dialog, and makes visible the output window just as before the whole thing started.60

The list box of the output window has a contextual right mouse button menu, that allows the user to save the contents into a file. Since the designers of windows didn't foresee this, I had to subclass the list box and handle the WM_RBUTTONDOWN message myself. When that message is received by my subclassing procedure, I built dynamically a popup menu with just one item.

A big development issue with the output window was the interaction it has with the other document windows. Whenever the output window appears, or is resized, it will resize the MDI client window (the parent of all document windows) to make space for itself.

Handling the menu
The raw WM_COMMAND message is received by the frame window, and handled in edit5.c, function FrameWndProc. There only the quit command is handled, all others are passed to the function HandleCommand in menus.c.

That function centralizes all command handling. It starts by looking if the debugger is active, since some shortcuts have a different meaning in the debugger. The F5 function key binds to “call the debugger” when in the editor, but it binds to “continue execution” when the debugger is active.
That done, it will see if the resource editor is active and if that’s the case see if this command is actually a command for the resource editor. Then, at last, it starts scanning the commands table to see what type of command that is, calling the function indicated in the table “Commands”, that associates a numeric command value to a function handler. The prototype for all those functions is the same: void Handle_XXX_Command(void).  Most of those functions are defined in “command.c”, but not all. If you want to follow the logic, it is easy to put a breakpoint at the call site in HandleCommand, and see where it goes.
	pCmd = &Commands[0];
	while (pCmd->CmdId) {
		if (pCmd->CmdId == cmd) {
			(*pCmd->fn) (); // put a breakpoint here
			return 0;
		}
		pCmd++;
	}
There are some commands that did not require a new function, or that have some special requierement so they are handled in HandleCommand directly. Some of them just test for a special condition and call eventually one of the normal handlers. To add a new command to the editor, you would like to add here a new command.

The right button menu
The right button mouse click is handled as an information request. Wedit builds dynamically a drop down menu depending on the identifier that is under the cursor. The possibilities are many, so here is a table that tries to summarize all of them:

Conditions
Description
Cursor is somewhere in an #include line.
Opens the include file without asking any questions or showing the menu at all.
Cursor is under an #if
Adds a menu option to go to the matching #endif
Identifier under the cursor is one of case, switch,  default.
Adds a menu option to show all cases in a dialog box.
Cursor is under a normal identifier
Adds menu options to show or goto the definition, or show the  usage of that identifier.
Character under the cursor is a left or right brace
Adds a menu option to go to the matching brace.
Always added if the debugger is not active
Options to show the global variables, the file description or the file metrics.
The debugger is active.
Options to show the value of the identifier under the cursor, move the execution point, run to that position or insert a breakpoint.
Always added
Cut, copy and paste options.
The cursor is within a function scope.
Add options to show the local variables, or to edit the standard description of the function.

All this is done in the function DoRBMenu, that lives in menus.c. The window procedure for the active window just detects the WM_RBUTTONDOWN message. The pop-up menu returns either zero if the menu was canceled, or a menu command ID, that is sent to the frame window as if the user had pressed the corresponding option in the main menu. All those functionalities can be accessed from the main menu, but the right button click makes it possible to concentrate them in a powerful and simple way.
Special purpose parsers
Since Wedit started with a 386, having a full blown C parser and parsing a maybe 200K file at each character typed was out of the question. I was forced to devise special algorithms to speed up parsing. Basically, I decided to build a parser for each usage: one for scanning the functions, another for parsing structures, etc.

The first one I wrote was the parser for the functions. It is contained in the file edit6.c, in the function FindCFunctions(). Its algorithm is very simple:

After eliminating comments, #defines, constants, etc, look for a closing parentheses followed by an opening brace. This means you are at the beginning of a function61. Easy isn’t it?

Obviously you should count the brace level. When it is bigger than 0, this should be stopped until the last brace is closed again. This is (as always) true in general, but there are the exceptions that have to be special cased since you can have

#ifdef cplusplus
extern « C » { // That dammed brace!
#endif
... // here the level of braces is not zero!
#ifdef cplusplus
}
#endif

As you see, the special purpose parser does not preprocess the whole file. This is much faster and works like a charm in most cases. The few cases where it doesn’t, we write special case code, that is all.

This function is used for instance, to maintain the current function name at the upper right corner of the editor. At each cursor movement, the pointer to that function name is checked, so that at all times, the name is displayed correctly. This is tricky, when you take into account block moves, for instance. In those cases I just give up and re-parse the whole file again.

In general, this algorithm works well, it will break down however, when faced with constructs like:

#ifdef __STDC__
double sqrt(double s)
#else
double sqrt(s)
double s;
#endif

After detecting the first closing parentheses, Wedit will search for an opening brace, and will find the preprocessor instructions. Up to now I haven’t found any way out of this situation, so the parsing breaks down. This is not fatal, only that all the functions list and other utilities will not detect this function.

The software metrics module.
 This part if the IDE displays several metrics calculated in the fly by one of the special purpose parsers in edit6.c: AnalyzeFn()

Software metrics means in this context a set of measurements done to the source code of your program to find out certain metrics or ratios. This is a domain with a long story of continuous refinement of the definitions and metrics involved that would be impossible to describe in the context of this documentation62. It must be said however, that (in my very personal opinion) this field has lacked the raw data from a lot of measurements by many people. With this idea in mind, Wedit tries to provide you with a set of tools to measure your code and deduce your own conclusions. The emphasis is in providing raw data and displaying it without any interpretation, the objective being that you interpret the measurements, as you like. What is important is not the actual numbers displayed, but the experience you accumulate by investigating your own code and seeing how those numbers correlate to your experience with the software you write or maintain.
After reviewing the enormous amount of papers published within this field, I (sort of) abstracted following information that seems to be widely recognized as meaningful measurements:
·	The number of lines of a program/module
·	The number of unique operands
·	The total number of operands used.
·	The number of unique operators
·	The total number of operators
·	The number of flow control statements
·	The volume of commentaries.

For the C language, Wedit considers the expression "++" or "+=" as an operator. A constant or a variable are considered as operands (the objects that operators manipulate). A construct like 'while' or 'for' is considered as a control flow directive.
The formulae used are the following:

LENGTH: Total number of operators + total number of operands.
VOLUME: Length * (log(number of unique operands)/log(2) )
LEVEL:    (2 / unique operands) * (unique operands / total number of operands)
DENSITY: VOLUME / LEVEL

These formulae correspond to the work of Halstead.
How Wedit collects the data?

Obviously is not necessary to have a lengthy discussion about what is a line of code63. Defining what is an instruction is a little bit more complicated. Wedit uses for the C language the number of statement separators (the semi-colon) as a guide. The other definitions are straightforward: All operators are counted for the number of possible operators, including the preprocessor commands. The rationale behind is that they count for the comprehension of the text. Parentheses are counted each as an operator.
Numbers are considered operands, as well as static character constants or strings. The flow-control operations like 'for, case, while', etc are counted, and they are important for the McCabe complexity measurement.

The implementation of the metrics counting is done in metrics.c, specially in the function AnalyzeFn. That function basically has the following structure:
Initialize. All counters are cleared and space allocated for the operators table. That table contains a count in each position for the corresponding operator.
Test if there is a comment before the function. If there is, add the character count of the comment to the comments character count.
Then loop for each line in the function text, eliminating strings and comments. Each character will dispatch to a different case statement in a big switch. Identifiers are added to a growing list, and count as operands, as numbers or character strings. Brace depth is tracked, and the maximal depth is recorded.
The results are passed to CalculateMetrics, that implements the formulae above.

The whole is passed to the plotting functions, that displays the results.
The 'TREE' utility
This option shows the calling tree of a function graphically. The code for this is in the source file ‘drawtree.c’. You can reach this option by using the ‘Utils ->Analysis’ menu item, and then choosing the tree option.

Clicking in a leaf, a dialog box will be displayed, and you will be able to visualize all points of call for the given function call point.

To avoid having to display enormous bitmaps, only 3 levels down will be displayed. In my opinion, when displaying more levels, the tree becomes rather more confusing than helpful.

Here is an example of the graphics displayed. This is a photograph of a display under windows 3.1. Just to get nostalgic!

The small menu at the left allows you to print the tree or to show information about it like depth, number of branches, etc.

Identify an executable or an object file

When a file that has been distributed to customers fails, it is very convenient to know the set of sources that built the file, and the date of each one. Wedit has the option ‘ID’ in the ‘Search’ menu, that will insert a static character string within the C source file of type: 

''$keyword:value$''. 

Since the static characters strings are included in the executable, this will allow the 'Identify file' utility of the 'Find' menu to search for all this strings within the executable to identify the name and the date of each module that was used to build the final product. The editor recognizes this static character strings and updates the date automatically each time a module is saved.
This is done very easily when loading the source file. The editor will compare each line to the signature, and will check the ‘ID’ menu item in the ‘Find’ menu, if it finds it.
The signature looks like this:

static char *_CMSID = "$CmsFile: TOPLEV $ $Date: 1998.5.31.10.24.4 $";

This means that the name of the file (without extension) is ‘toplev’, and that was last saved the 31 May 1998, at 10:24.  You can add a sequence of characters of your own, if you want, after the date.64

To visualize all strings like this contained in an executable file, just use the ‘Identify file’ option in the ‘Search’ menu.

The purpose of all this is to allow you to rebuild exactly the same sources that were used to build the executable: an executable can contain many of this character strings, each one from a different module of the system. This allows you to see each of the sources that were used to build the final product and can be a precious help to rebuild the state of the sources to find a problem at a client's site.

Building the history list
The history list uses a timer associated with the output window. After a fixed amount of time (configurable by the user) the editor records the current function in a table. The name of the file is allocated from fresh storage, as well as the name of the function to avoid problems if a file is closed. The “History” command calls the HistoryDlg, defined in outputwnd.c. This dialog fills the list of visited functions, and displays the current settings of the history recording feature.

When the user makes a modification to a file, the history list is updated immediately. The rationale is that functions where modifications were done are surely of interest, even if the time required to do the editing was less than the specified history time.

The user can disable this feature by setting either the time or the size of the recorded history to zero. I left this because in small memory/slow machine environments the overhead could be too much for the user.

The object file cross-referencing utility
This functionality has been incorporated in the linker (the -x option), but I still retained the code in Wedit because it allows much more flexibility, since there is no need to build an executable. You can add/eliminate object files according to the interests you have at the time of the search.

Two types of display are supported: a dialog box where you can search for a symbol, and a graphical display that shows the relationships for all modules: which functions are exported or imported from each module.

The algorithm for doing this is quite simple, involving only a reading of each object file’s symbol table, and keeping a list of the symbols that are public. After all object files are read, it is trivial to see where each symbol is used, and which symbols aren’t used anywhere.

The source for this utility is in the objxref.c source file. The scanning of the object files is more or less trivial, the same as in the pedump utility. What is more complicated is displaying the object file relationships. This is done by placing the files in a circle and connecting them with lines of different colors. Of course, if there is only one or two files, this doesn’t look like a circle at all.

User interface considerations: an example.
The object file cross referencing utility starts by proposing the user a set of files to use. I had in previous versions of wedit, the following interface:



The files existing in the start directory (or the directory the user changed to using the browse button) were displayed in the list box at the top. The files that will be actually used were displayed in the lower list box. The user had to select all the files (in 99% of the cases), then press “add”. This would take the file names from the upper to the lower list box, where the OK action read the list of selected files.

This interface was a bit more flexible. If you eliminated a file by mistake, you could add it again without having to restart. But actually, most users will be interested in scanning their build directory, where anyway all files should be considered.

The mistakes in this interface are obvious:
The normal path requires many actions from the part of the user. (Selecting, then pressing “add”, then pressing OK).
The interface is not intuitive. Both list boxes are multiple selection ones, i.e. the user had to select with the keyboard (shift key and then page down) or the mouse, by holding the shift key pressed when selected. It can be argued that this is a normal windows procedure in a normal windows control, and the user is supposed to know this, but I have often seen that that is not the case.
I decided to simplify this, in the following manner:



At the start, all obj files are selected by default. In the rare case where this is necessary, the user can still ignore some file by selecting it, then pressing the “ignore” button, but there is no need in most cases of any other action than just pressing return. This is close to the best interface. It doesn’t require a lot of work from the part of the user, and it is intuitive. No flexibility or important features are left out (the user can still change the starting directory, or ignore ceratin modules) but in most cases, nothing needs to be done. The default action is the best. 

Note that I changed the text in the buttons: from a cryptic “Browse dir” to a clearer “Change directory”, from a strange “Eliminate” (eliminate what?) to a clearer “Ignore selected module”. The text of the group box changed from “Objs” (big mistake: do NOT use cryptic acronyms!) to a clearer “Selected modules”. Text in buttons is very often considered an afterthought, but it isn’t. Keeping the text clear is very important.

Added benefits of this simplified interface are:
 
I can display more files in the same screen surface area.
A lot of code that was needed to get the names from one list box to the other wasn’t needed any more. The dialog function shrinked, and many possibilities for mistakes disappeared.
The built-in utilities
Grep (find in files)
This was the first utility I incorporated to the editor, back in 1990 or so... No big algorithms in here but an anecdote. I had a window with a « Cancel » button. You could use it to stop Grep. The problem is, that I looked at that button with a couple of Windows calls at each line... I discovered that 75% of the time spent by Grep was in those windows calls! Eliminating that button made me realize how expensive are calls to the OS...
The search itself is implemented using the strstr() library function. This isn't especially clever, but since the days of the Pentium-90 this program is anyway completely I/O bound. This means that no matter how fast we search through RAM, the speed of your hard disk determines completely the speed of your GREP. Rather than trying to speed it up, I concentrated instead in developing a stable module, with as much functionality as possible.

The code is in the file grep.c. Here is a detailed map of this module:

Function
Description
GrepLineHandler
Handles the double click in the output window containing the results of the search. It opens the file in question and sets the cursor at the line where a match was found.
StartGrepResults
Empties the output window and fills it with the results from the search. It sets the double click handler to the GrepLineHandler function.
GrepFile
Searches the given file for matches, and collects all matches in the CurrentGrepResults global variable. That variable points to a list of structures containing the file name, the line and the line number. This is used by StartGrepResults to fill the output window. This function handles the search flags. If the flags indicate to ignore the difference between lower and upper case text, both the line and the pattern are converted to uppercase before comparing. If the pattern is a regular expression , it will call the regular expression pattern matcher in regexp.c.
The resulting list will be freed when the next grep is started. Until then, the results remain available in case the user comes back to them.
StartGrep
Calls DoADir, a function that searches a directory for a special wild-card pattern (for instance *.c) and calls the GrepFile function for each file found. It can recurse on directories. The function DoADir lives in wproc.c.
GrepDlg
Dialog box for collecting the user input.
HandleGrepCommand
Main function of the module, that organizes all the search.
ReadGrepFlags
Reads the option flags from persisten storage (the project file)
WriteGrepFlags
Writes the option flags into persistent storage.

Diff
The fastest algorithm that I know of, is the one published by GNU, in their ‘diff’ program. I have adapted it to a windows environment, and for use with the data structures of the editor, instead of directly reading/writing to disk. Using this engine, Wedit achieves an amazing speed when comparing text files.

Displaying function slices
Many times, you are interested in viewing the uses of a symbol within a function. You want to see just the lines that use that symbol, to better see how its lifetime is spent within the function.
In the ‘Analysis->Show local variables’ I implemented a dialog box, that will only show the lines of the function that contain the given symbol. You can choose from three different classes of symbols, relative to the function: local symbols, arguments, and global symbols, i.e. everything that is not a local or an argument. Macros are not expanded and treated as globals. This way you can follow the usage of macros too.

It can be argued that ‘grep’ shows a similar view, but this dialog box is more powerful in the sense that:
Only one function will be used. Grep is file oriented, so you may have too many matches for the identifier ‘i’ for instance.
Comments and character strings do not provoke spurious matches.
Easy of usage improves when you just have to click in a symbol to see the relevant lines, instead of calling grep at each symbol.

This 'slice' view is very useful in most cases. A problem is when you use the identifier alone in a line or a long statement. In this case, displaying it has no effect. For instance if you are searching for the identifier 'balance', and you use it in a line like:

	if (AllAccountsClosed())
		DoCalculateBalance(inputData,
			OutputData,
			&balance);

Showing just the line

			&balance);

Is surely not very helpful. What would be needed in this case is a full blown parser that would recognize each statement, (and possibly the controlling if statement), and print you that. That would need a complete compile of all program text of course, something that would slow down everything. I have tried to eliminate this problem by showing the preceding line and the line after the one selected to indicate some context. This will work for most situations, and in any case you have the program text available at all times within the editor.

A fairly easy generalization of this would be to have the 'Search and Replace' tools replace an identifier within a given context, for instance replacing the global variable 'SomeGlobal' by some other name, leaving all other occurrences of 'SomeGlobal' untouched when they do NOT occur in a global context.

Showing the #ifdefs
The C language offers the programmer the “#ifdef … #endif” construct. This can be nested, and some programs use this feature “ad nauseaum”… making the resulting program very hard to read. The IDE can help here. The menu command will branch the program into the function HandleShowIfdefsCommand in make.c.

That function calls the browsegen utility with a special flag “-showifdeflines” that writes into a temporary file the lines that are active. Wedit will process that file and set a flag in the “TextLine” structure that makes the display show them grayed if they do not contribute code to the program. As far as I know Wedit is the only IDE to offer this feature.

Showing executable statistics
This option calls the “pedump” utility with the “/summary” option, and shows the output in the output window. Handling of this command is done in HandleExeStats, in menus.c. The output of pedump shows the size of the different sections (code size, data size).

Extracting the character strings from a source file.
To be able to translate a program into another (human) language, all character strings that are used for prompts, etc need to be extracted and translated. To easy this task,wedit has a “String” command, that allows the user to easily build a table of strings without a time-consuming editing process.
This functionality is handled in the function HandleShowStringsCommand, in the file command.c. This function calls a dialog box that returns in its argument a list of strings, and which generation method will be used. There are two supported methods, a string table, or a function call. For instance, if you have in your code:

	printf(“Please enter any key to continue\n”);

you have the choice of either replacing the string by:

	printf(StringTable[234]);
or
	printf(GetString(234));

This two methods are very similar, but the second one gives more flexibility, but is (of course) a bit slower.

The dialog box that handles this is called ShowStringsDlg, and resides in dialog.c. It receives in its argument the list of strings prepared by the function FindStrings, that resides in edit6.c. That function scans the current file and searches for strings, excluding of course any strings within a commentary or strings that are part of an #include statement. The strings found are collected into a list, and returned as a result. The dialog box displays the strings to enable the user to choose which strings need to go into the table and which are just things like “r”, that is an argument to the fopen function, and surely should not be translated!

The (possibly edited by the user) list of strings is written to a file, and then the function ModifySource in edit6.c is called, that will go through each line of the source file making the necessary modifications. To avoid making the sources incomprehensible, the editor adds automatically a comment near the modification, making the contents of the string explicit, so that instead of seeing just:

printf(StrTab[234]);

you will see:

printf(StrTab[234]); // <”Please enter any key to continue”

Searching for a function
The number of functions in a medium-big project can be quite high. It is easy to forget the exact name or the prototype of a function, so I added a search capability, implemented through a dialog box reachable from the main menu with ‘Search->Search function’.
This dialog box will show at its left, the list of all functions in all loaded files. When you click (once) over the name of one of those, its prototype and the file where it is defined will be shown. A double click will close the dialog box and put the cursor at the function’s definition.
Regular expressions can be used in the search, so you can easily find functions where you know the name approximately: was it doCreateView() ? or was it doCreate() ? You just type ‘doCreate.*’ and a list of all the functions that begin with ‘doCreate’ will be shown.
Formatting C programs
This is done in the file ind.c. 
The project maintenance
A project is described by the PROJECTINFO structure, defined in edit.h. The fields are65:

FieldName
Description
Next
This is currently not used, but it is reserved for having sub-projects in a project.
ProjectFiles
A list of file names, with their paths relative to the sources directory if possible.
ProjectPath
The current directory for this project.
Changed
Internal flag used by the configuration wizard.
ProjectFlags
PRJFLAGS_*: whether the project is an Eiffel, fortran, or C project, and whether it uses the versioning system.
CmsProjectPath
Path to the directory where the versioning system files are stored.
CurrentFile
The file that has the currently the focus in the editor.
MakeName
Name for the “make” utility. Normally this should be make.exe in the \lcc\bin directory, but this could be changed in later versions.
MakeDir
Directory where the object files are built and the build process starts. Normally this is the “lcc” directory under the project sources directory.
ObjList
Object file list.
IncludePath
Character string defining the different directories where the compiler should look for directories. Each one of this paths is separated by a coma or a space, and it will be transformed into a –Ipath argument to the compiler when generating the makefile.
Defines
Character string indicating the defines that will be passed to the preprocessor. Each comma separated symbol will be transformed when generating the makefile into a –Dname argument.
ErrorFile
Name of the file where errors and warning messages from the compiler will be stored.
SourcesDir
Directory where the source files are stored. The names of the files in the project list are relative to this directory, when possible. Absolute paths are supported obviously.
ExecutableName
Name of the file this project builds: can be a dll, a library or an executable.
CompilerFlags
Curently there are 25 of those flags defined. Each bit in this integer will be transformed into a corresponding command line argument. For instance the COMPFLAG_OPTIMIZE bit will be transformed into the “-O” string.
Libraries
Character string containing a space separated list of libraries that will be passed to the linker.
DependenciesTree
The list of dependencies (header files).
Breakpoints
A list of the active debugger breakpoints.
MakeStatus
The result of the last build.
MakeTime
The time that the last build took to complete in milliseconds.
EntryPoint
For Dlls, the name of an optional entry point.
LoadedFiles
A list of files currently loaded into the editor. This can contain files that are not part of the project at all.
x,y,cx,cy
Coordinates of the frame window.
FileProcessors
A descriptor of a special build executable to start to generate the target file instead of the compiler.
ReleasesList
A list of releases for the versioning system.
LinkerArguments
A character string with extra linker arguments that aren’t supported by the IDE
EiffelFlags
Compilation flags for the SmallEiffel compiler
FortranFlags
Compilation flags for the f2c compiler.
EiffelInfo
Parameters for the Eiffel build.

A project is basically a list of names that are maintained in an associative list in the file “projects.ini” in the lcc “lib” directory (\lcc\lib). I use the normal format of initialization files with the section name within brackets (“[Projects]”), followed by a list of project-name = path. The path  component points to a file where all project settings are stored.

This is the third design after the original one (that was more or less exactly like this under windows 3.1) then later a registry based approach, that led into this. The advantage of ascii files over the registry is that export and import are very easy.  The registry based approach forced me to include two specific options: export and import, that would convert the values in the registry into ascii files and from ascii files back into registry values.

Global options common to all projects are stored under “wedit.prj”, also in the \lcc\lib directory, where keywords and macros are stored. This global project will be loaded first, and contains an entry called “CurrentProject” that points to the projects that’s currently in use. Note that you can load .prj files with the editor, that will understand them as a project file after it makes a signature verification of course. The project is immediately added to the projects table projects.ini.66

To bootstrap the system, if the IDE doesn’t find the files in the \lcc\lib directory it will create them with their default values. There is a small utility that will transform the old format that uses the registry into the new one.

Project structure is displayed to the user using the traditional tree-view form. There is a new window that attaches itself to the left side of the main window of wedit. 67 It is not a “dockable” window, since the user interface of those windows is extremely unpleasant. You can move it around without any fears that will stick to some other window. The only thing that makes its behaviour slightly different is that maximizing it restores the default position, and minimizing it makes it invisible.

The “workspace” display

This window has become a standard in IDE design. A tree oriented control that displays the files used by the project, and displays different options when you right-click in an item. I decided to add this when several users asked for it.

The “workspace” window is displayed left of the wedit window. If the main window touches the screen, or there is no place left at the left, the main window will be resized, if not it will be just moved to make place for the workspace display68.  The command from the main menu of the editor leads straight into HandlePrjTreeCommand, a function that lives in prjoutline.c. This function will create the project display window, and the tree control that fills it up. Messages for this window are handled in the TreeViewProc function in the same file. 

After creating the window and the tree control, the tree control is filled in the BuildFullTree function. At this moment we have 5 main branches: 
1. Source Files. Here are all the C source files for the project in question.
2. Resource files. Here are displayed the .rc (or .res) files.
3. Libraries. All non-default libraries of the project.
4. Output. The executable or library that the project builds.
5. Header files. The included files. This list is just read from the dependencies file that is generated when the makefile is written.
Each item in the tree view control has a private pointer to a structure describing it, and a type numeric identifier. This allows the window procedure to determine which type of branch has been clicked, so that the appropiate right-click menus are brought up. Those menus are specific to the type of branch, for instance the actions to gather information about the executable that the project builds are different than the actions needed to gather information about a source file.

Most of the commands that are accessible in the workspace window are accessible using other options in the main menu. The advantage of putting them all in a single place is to make the user interface of the program easier to learn. For instance when you right-click in the “Source files” branch, you have the options
Open all (you can reach this with Project? open all files too)
Insert/delete files. (Project ? Add/delete files)
Statistics (Window ? statistics)

The user interface is easier to use if it offers several ways of doing the same things.
The configuration wizard of Wedit.

All configuration aspects for the compiler, the linker, the editor, etc. are handled in a wizard control. This wizard contains several dialogs, specialized for the task they are supposed to perform. Here is a table with the innards of the configuration wizard.


Dialog name
Function
Resource
Description
General
EditInfo
IDD_GENERALSETTINGS
Tab size, options for fonts, auto-saving, and others.
Help
SetWinHelpDlg
IDD_HELPNAME32
Configuration for the rtf generation.
Versions
CmsPreferencesDlg
IDD_CMSPREFERENCES
Versioning system.
Compiler
CompilerDlg
IDD_COMPILER
Compilation options
Macros
EditMacroDlg
IDD_MACROS
Definition of user defined macros
Debugger
DebuggerSettingsDlg
IDD_DEBUGSETTINGS
Debugger parameters
Librarian 
Linker
LinkerSettingsDlg
IDD_LINKER
Linker in all projects except for the building of a library.
Language
ChangeKeywordsDlg
IDD_KEYWORDS
Adding/removing keywords
Workspace
WorkspaceDlg
IDD_EDITORINFO32
Editor font, colors, keyboard accelerator
Utilities
WorkspaceDlg
IDD_CHANGEUTIL
User defined utilities
SmallEiffel
EiffelConfigDlgProc
IDD_EIFFEL
Eiffel compiler config
Fortran
FortranConfigDlgProc
IDD_FORTRAN
Fortran configuration (f2c)
System info
SysInfoDlg
IDD_SYSINFO
System characteristics

Not all dialog boxes are shown at all times. The Eiffel configuration is defined only for Eiffel projects, the same applies for fortran. The compiler dialog box doesn’t show if there is no project defined, etc. The construction of the wizard control is done in the function DoPropertySheet in config.c, and it is in this file that all other dialog procedures reside.

All the dialog boxes receive a WM_NOTIFY message from the wizard when the user presses the OK button at the bottom. It is here that the reading of the configuration data is done. Since some of the dialog boxes were developed under windows 3.1 and at that time there wasn’t any wizard, the OK handling has some relicts of that OK button that now has disappeared. The code is quite straightforward, and I hope not very difficult to read.

Adding files to the project
This is handled in the function ChooseProjectFiles, that lives in dialog.c. That function starts by changing the current directory to the one specified as the source directory. This is necessary to avoid complications when handling the relative paths specifications. Then it builds a file list of the project files, putting it in a global variable FileList. This isn’t a very good design, I know, global variables aren’t fashionable this days, but, bear with me.69 

This list then, is passed to AskPrjFiles, that displays a simple dialog box with the current file list, then calls the common dialog procedure if the “add”  button is pressed.  In any case, the ChooseProjectFiles procedure expects a list of files in the FileList global. It goes through that list, adding to the linker “libraries” parameter list the .lib files it finds. Each library found will be inserted as a character string to the project information structure. At the end, the contents of the global FileList are added to the project->ProjectFiles field, and the global is set to empty.
Building the executable

The objective here is to recompile all the necessary files, linking them, showing the user the results, and several « extras ». We will go one by one.
Generating a Makefile
I adapted a primitive, public domain ‘make’ utility to lcc. The makefiles that the IDE generates are tailored to that ‘make’, so they are so primitive that they should work with all other ‘makes’, like ‘nmake’ from Microsoft or gnu’s make utility. Those, feature a full fledged ‘make language’, with all the complexities and subtleties I would rather ignore.

The rules the IDE uses are fairly straightforward, and based in the suffix of the file name:
The executable depends on all the files that the user has indicated when the project was first specified, or later, using the ‘Project files’ menu option.
Those files are classified according to their suffixes: .obj files are not further processed, .c files are assumed source files, .h are ignored, .rc or .res are resource files, .asm are assembler files.
The C files are scanned for #include statements, to determine in which header files they depend on. This relies in a new compiler option: the -M option. I introduced that to the compiler specifically to solve this problem. For each C file, Wedit starts the pre-processor with a command line like: lcc -M -Fo$56455.tmp foo.c. The generated output file « $56455.tmp » contains in each line all include files for the file ‘foo.c’.
.rc files are given to the resource compiler lrc.
.asm files are given to lcc.
Binary files (.obj or .res files) are passed directly to the linker.

There is a lot of room for improvement here, and this will get more sophisticated as time permits. For starters, the current way to specify a special processor for a special kind of file is too complicated. Now, you use the ‘properties’ dialog box that appears when you right click somewhere in the text of your program. A more obvious way is necessary. I haven't done this since it will necessarily complexify the code for the other parts of the system, and this feature is seldom used. Basically, there could arise the need that you want another program than lcc to process some file (or maybe all of them) before the actual compiler runs, or afterwards. It could be too, that you want to replace lcc entirely by another compiler. There should be a more convenient way of specifying this within the IDE.

In the last versions, make.exe loads the lcc.dll once, and then compiles each source file without the overhead of starting another process. I thought that this would speed up compilation but the speed difference is minimal.

Another progress in this area has been the usage of symbolic macros, instead of generating hard coded paths to the files. This makes the generated makefiles more portable, since they can be used in other contexts than only in wedit.
Speeding up makefile generation
A recent improvement is the caching of the results of the dependencies analysis. This is a time-consuming process, since the compiler has to find out all the files that are #included either directly or indirectly from a given source file. This means necessarily scanning all the file, and the includes it contains. For big projects, this can take a long time.

Sometimes, a flag is changed in the configuration of the compiler, for instance the optimization level is changed. This provoked until this improvement the rescan of all the dependencies of all the files that are part of the project.

The first step for accelerating the make file rebuild is the caching of the results of a full scan. Wedit will generate a file with the project name, and the extension “.dep” in the compilation directory. This is a simple text file containg the name of the source file within square brackets (i.e. [example.c]), followed by a list of included files.70

When Wedit generates the makefile, it processes this file, and builds a list of valid dependencies. A dependency is assumed valid, when the date of the dependencies file is more recent than the date of the source file and all its dependencies. Normally, if an include file has changed, this means it could have added another include, so it has to be rescanned.

If the dependency is valid, it will be just copied to the makefile, if not, the file is rescanned. 

The sources for the build are in “make.c”, that generates the makefile, calles the make utility, and associates a source line with each error message. The association is done by the output window when it receives the double click in the displayed list.
For each functionality, the code flow is roughly as follows:
Make file generation. This is started with a menu command, so the HandleCommand function will call the GenerateDependencies function, that organizes all the make file generation. The handling of the dependencies file is done in the function CheckDependeciesFile, that builds the list of dependencies.
The “make” command (F9) is handled by HandleMakeCommand, that calls DoSpanMake, to start a new process where the compiler will run.
The association of a diagnostic message in the output window is done first in the function FillBuildResults71 that builds the list of diagnostic messages that is displayed in the lower part of the editor, the “output window”. When you double clik in one line of the list, the output window will receive a WM_COMMAND message, that will provoke the calling of the line handler for the currently selected functionality, i.e. the MakeLineHandler.72 That code looks in the list of erros for the selected one, and sets the cursor at the correct position.
Starting a build and displaying the results
When the user clicks the ‘Compile’ button, the IDE will span a new process, that herits a pipe where it writes it’s output. That pipe is associated with the stderr standard file handle. This is why all output for all utilities happens there. stdout is ignored, and will appear in the window where lcc is running. Only warnings and  errors will get redirected.

During this time, an auxiliary thread reads all characters from the pipe, and stuffs them away in a file. That file will be later processed by the utility functions in edit2.c that will display the message to the user, putting the cursor at the appropriate place in the code where the problem is located.

For all this to happen, a myriad of details has to work smoothly:
For redirection to work, it is necessary that the startup code of the child process honors this fact, i.e. that it uses its redirected handles. 
Wedit has no console window, since it is a GUI application. Before starting the make, a console has to be created its title set, etc.
To allow message circulation during the make, and avoiding a « freeze » of Wedit, a secondary thread started.
The pipe for the child process has to be created, with the inheritable flag set. Besides, the differences between Windows NT/ Windows 95 have to be taken into account what the security parameters concerns.
The resulting error file has to be parsed, and warnings/errors separated from other type of messages.
During the build, the make utility (that has been modified to detect the presence of Wedit), will send before starting the compilation of each module, a message to the editor with a character string to show in the output window. This isn't especially fast, because it’s implemented with the SendMessage primitive. Measurements done when compiling projects with a significant number of files indicate that this primitive can slow down compilation by a staggering 15-20% if used too much.  In the long term, the solution will be to map the compiler into the IDE's process space by building a compile DLL. This is not just a matter of adding a simple LibMain function to the compiler however. The compiler must be rewritten so that is restartable, i.e. that doesn't rely on any global initializations at startup.
A weakness of the current schema is the separate handling of stderr, where all warnings/errors are accumulated, and stdout that just displays informative messages. I have tried to unify those behaviors, but I found that windows will mix up completely characters from both output streams, so I had to resort to a separate handling of each one.

Finding out the missing libraries
A constant problem for the developer is to find out which libraries are needed for the executable to run. Normally, you just include the header files, and hope that the corresponding library will be in the default set. Lcc-win32 makes you this easy, since quite a few libraries are in the default set, so the most functions will be found by the linker anyway.

When a function is not in the default set however, it can be quite difficult to figure out which library must be included. Wedit has a dll called “apilist.dll”, that will figure this out, using the file “apilist.txt”73. This file contains a list of dlls and their exports. It is build at the installation of lcc-win32. Its format is quite simple: it starts with a number (the number of dlls processed), then a list of dll names, and then the exports, sorted alphabetically, with their names, followed by a number that refers to the dll list at the beginning of the file. To read this file you just read the number of dlls in the first line, then read this number of lines containing the dll table, and then, you have each export followed by its index.

Wedit will call the dll “apilist.dll” and obtain the name of the missing library, and add this automatically to the libraries needed for the link in the linker command line. This is done in the function GetUndefinedSymbols in make.c.

How is the this list generated?

At installation time, the installation program reads the list of dlls in the \lcc\buildlib\dlls.txt file. Using this list, it will scan all the exports file descriptions (the files that have a .exp suffix), sort the result, and write it to the apilist.txt file.
The application wizard


When you want to start a normal application in C, you have to type more than

int main() {  }

to get started... You have to register a class, create a window, setup your message loop, etc. Just to open a window you need to work for half an hour. This forces people to have a sort of template handy, where you cut and paste from one application to the other.

Well, that code can be automatically generated, since it is very repetitive and simple. This is the task of the ‘application wizard’.

The design is straightforward. In the directory \lcc\lib\wizard, there is a set of templates that will be used to build a complete working application from scratch just by pushing some buttons. This allows you to change the set of templates to whatever you choose, and to add or delete things as you wish.

Several types of output are possible:
Single window application with or without a status bar. The wizard will generate code for the WinMain, for the class registration, for creating the main window, and if necessary, code for a status bar and some additional stuff to resize it, and connect it to the menu. In the generated rc file there is a string table that contains an explanation for each menu item that is in the main menu. That explanatory sentence will be shown in the status bar by processing the WM_MENUSELECT message.

Multiple Document Interface application. This uses the well known MDI style of a frame window, with document windows inside it. The wizard will generate the code for the frame, and for the creation of the hidden mdichild window that manages the windows the user opens. The generated menu will be different, since it is more or less standard to have an Edit menu, etc. This code will be taken from the templates as the code for the single window application. A status bar can also be added to an MDI window, and the generated code will resize the mdichild window to avoid painting over the status bar. This is accomplished in the processing of the WM_SIZE message.

A DLL. This is very simple: the wizard will only generate code for the LibMain, and that is it. No windows will be created since we can’t safely assume every DLL wants to open an own window. Most of them will use the application window. The DLL skeleton doesn’t do anything useful per se, but for instance, can be used without adding a line of code to produce a resources DLL, i.e. a DLL that will contain only resources. You just add the resources to the link step, and there you go. You have a resource DLL that can be used with LoadResource or FindResource primitives to access the resources data base.

A dialog based application. This type of application has no main window and consists of just a dialog box that is shown without a background window.

A console application. This template will generate an application with the traditional argc, argv handling, with an Usage function, with argc checking, and other things.

The wizard can be used as a standalone 74program, or within Wedit. When you create a project, Wedit will ask you if you want to generate the application’s skeleton. If you answer yes, the wizard will be called, and pass the result of its activity to wedit, that will automatically build a project with that information, using default values. So, in a matter of a few minutes you are up and running, and can start writing the application you had in mind.

Wizard mechanics:
There is no wizardry here... The templates just contain keywords enclosed in special signs like « $@ », that will be substituted for the real keyword, i.e. bound, when the wizard has determined the user preferences for this template.
The templates are located in the \lcc\lib\wizard directory. You can modify any of them to add features you think are necessary, or to eliminate the ones you do not like.

The source distribution for the wizard
The sources are located in \lcc\src\wizard. They consist of just wizard.c, where all input for the user is done, and thez templates that the wizard uses are combined with the user’s input to generate the actual C code.

The debugger

75
After the dialog box editor was working (more or less, maybe less than more but anyway it edited the dialogs of Wedit) I started the final phase of this work. The problem was, to understand how I could start a program under debugger control, follow its execution, set/unset breakpoints, etc. 

I was lucky indeed, because I could start working under Win32, a modern system that offers a high-level debugger interface. The old and horrible times of Windows 3.1, with its unprotected memory model, its 16 bit limitations were (at last) well behind us. Under those conditions, building a debugger all by myself would have been utterly impossible.

Nevertheless, I had never written a debugger before. So I started playing with the idea of looking in gdb, GNU ‘s debugger, to see how a debugger works. That was impossible. Again, I was in front of tons of code that I couldn’t make any sense of. So I looked elsewhere. A good start was given to me in Windows/Dos Programmer’s Journal, with an article about debugger writing. In that seminal article I discovered how breakpoints are set/unset, how the basics of a debugger, the mechanics inside are built. Starting from there I wrote a bridge to the rest of Wedit, and embarked myself in yet another ‘project’.

I tried at the beginning, to keep the debugger separated from the rest of the code of Wedit. I designed an interface based in the SendMessage function, that make a bridge between the debugger code and the rest. The debugger sent messages to wedit to make it display a line in some file, and received messages of commands from the user interface.

This worked, but the problem with this approach, as I find out later, is that is too centered around user interface elements like windows, for instance. For many reasons, I decided later to get rid of that debugger window. The window become invisible, but of course, continued processing the messages I wanted. But now that the visual counterpart was gone, the appeal of an invisible window looked more and more artificial. I decided to get rid of that interface, and make wedit call directly the debugger routines and the other way around. This simplified greatly the code, eliminating many layers of indirection between the source of a command, and the actual function that would execute the command.

Let’s face it: the debugger can’t be dissociated from the rest of wedit: it would mean actually to rewrite it from scratch. Rather than maintain an artificial separation, it is better to reduce the amount of code involved.

Still, the debugger has two threads, and I have carefully avoided to call any of Wedit’s function directly from the debugger thread. Once, I did that by mistake, and it was the source of a bug that was very difficult to find: The text of the current window would repaint itself using the ugly system font, instead of the font that was selected with the device context!

I spent hours looking at it, and after an hour of two tinkering, I would leave that famous problem away, to restart several weeks later. I finally discovered that I was calling directly the update function from the debugger thread, and somehow, this produced the strange font selection.

Since then, I have seen all calls of the debugger thread to wedit, and use always PostMessage, to communicate something from the debugger thread.

Starting a program under debugger control.
The debugger starts by 
Creating 3 different events for notifying the debugging threads of certain events:
1. Event running: the debuggee is running
2. Event resume: to restart the debuggee after a breakpoint
3. Event Kill: to stop the debuggee.
Creates a secondary thread that will handle all the debugging chores.

The debugging thread first launches the debuggee under control of the debugger. This is done in the function ‘LaunchDebuggee’ in the file debug.c. This function is just a call to CreateProcess with the flags DEBUG_PROCESS set. 

The debugging thread then listens for any of the events created for it. using the WaitForMultipleObjects primitive of Win32. When one of the events is reset, WaitForMultipleObjects returns. I check which event was reset, and act accordingly. If it was the EVENT_RUNNING event, I start to listen for notifications from the debuggee using the function CheckForDebugEvent.

CheckForDebugEvent uses the primitive WaitForDebugEvent with a timeout of 100 ms. There are several notifications I can receive from the system:
The first one is the ‘CREATE_PROCESS_DEBUG_EVENT’ of course. Windows is kind enough to tell me that the debuggee has started. I use that information to do following chores:
Read all the debug information. This is done in the dbginfo.c file. I build several tables with the global symbols, the local symbols by module, the names of the functions, etc. If I do not find any debug information I quit. For the time being, the debugger is not able to do assembly only debugging. I found anyway that this is not particularly useful...
I find out the address of the WinMain or the main function, and set a breakpoint there.
I tell Wedit to load the source file that contains the main/WinMain function and show the first line in that function.
Other notifications are received with the EXCEPTION_DEBUG_EVENT notification. I handle those in the function DoExceptionEvent. There, I dispatch with a switch statement that handles all types of exceptions that Windows can send me. The main ones are:
EXCEPTION_BREAKPOINT. This means that nothing horrible has happened: The debuggee has just hit a breakpoint.
EXCEPTION_SINGLE_STEP. This means that I am single-stepping through the code, and an instruction has been executed.
EXCEPTION_ACCESS_VIOLATION is much more serious. The debuggee has crashed, I have to clean up the pieces of the shock and tell the user the bad news.
A DLL has been loaded. I look in the DLL to see if I find any debug information for it. If I do find it, I read all that into the debugger tables, so that the debugger can follow a function call into that DLL if the need arises, or show where exactly in the DLL a problem appeared.
A DLL has been unloaded. I have to clean up the debug information for that DLL.
A call to OutputDebugString was done by the debuggee. I get the address of the string to be displayed, and show it in the Events window. This can go un-noticed and I think it would be better a stronger warning to the user.
Other exceptions. For the time being I do not handle many of those. They are things like a user interrupt (Ctrl+C) division by zero, floating point overflow, etc.
Another notification worth mentioning is the EXIT_PROCESS_DEBUG_EVENT that informs me that the debuggee (or another process) has exited normally.
Preparing for debugging
You should compile a program with the ‘-g2’ option turned on, to force the compiler to emit the debug information. Normally, it is better to compile always with this option turned on, since you can tell the linker to ignore it with the ‘-s’ option. This allows you to generate an executable with all debug information just with a single link. If you compile without -g2, and suddenly you discover that a debugger would be useful... you have to recompile all modules.

The optimizer should be disabled when you want to debug a program. The problem with optimized code, is that, for instance, sometimes it will avoid constructing a stack frame for a function that doesn’t need it, and this can severely confuse the debugger. But in general, the optimizer of lcc doesn’t do any aggressive optimizations, so the optimized code can  be followed with the debugger without big problems.
Reading the debug information
Using the file handle given by the operating system, the debugger reads all the debug info into main memory. The data structures I use are still not very sophisticated, because I haven’t had the time to improve them.

When I wrote this part, I closed the circle I started when I wrote the assembler. There, I wrote the generation of the debug information supplied by the compiler. In the linker I wrote code to compress that information into two sections:. debug$S and .debug$T for types and symbols, and now, the debugger reads all that and puts it to work.

For the time being, I ignore all types of debug information that aren’t really relevant for the C language, like C++ class hierarchy information, or others. This limits the applicability of Wedit as a general purpose debugger, but makes it possible to have something that runs now, instead of several years from now.

It must be emphasized that reading all this information that can take more than 2-3MB in medium size programs, is a really complex task. To avoid wasting too much memory, the debugger maintains a set of pointers to the image of the executable that the OS gives it, instead of copying this information to some other place. This way, no more memory is needed than what is already used anyway.

The debugger uses the NB09 Microsoft style debug info; but uses too the COFF debug info, especially for the symbol table. This is redundant, and limits further the type of programs that Wedit can debug, so probably will be discontinued in the future.

When a DLL is loaded, Windows of this fact notifies the debugger. The debugger looks at the DLL to see if it finds debugging information within it, and, if this is the case, it will load that information into a linked list of loaded dlls. When the DLL is unloaded, the debugger discards that information.

Reading the imports table
I read the imports table mainly for future enhancements. If I get the time to do it, the debugger can be used as a checker for window functions, in a similar way as bounds checker from NuMega works. Having the import table available, the debugger can write a breakpoint at the function entry, and check all parameters. This will be of course time consuming, but when you are debugging, you are probably more concerned with finding bugs than with execution speed. The big problem is to generate automatically a description of the arguments from the windows header files so that the debugger could read that in automatically at startup.

In any case, one immediate use for the imports table, is to find out the address of the ExitProcess function, to be able to kill the debuggee in a controlled way. See below.
Another use of it, is to find out the names of all DLL functions, so the ‘Variables’ display can show the value of each function call with the name of the procedure, instead of a meaningless address. Since lcc-win32 uses CRTDLL.DLL as its runtime, there are quite a lot of functions that are imported from dlls. The information for each import is stored in a structure as follows:

typedef struct tagImports {
	struct tagImports *Next;
	char *Name;
	char *DllName;
	DWORD Addr;
	DWORD AddressOfCall;
} IMPORT;

The ‘Name’ field is filled in at load time, from the imports table. Note that there are two address fields, one for the position of the indirect jump in the user code, and another for the address of the DLL function.
Finding out where the real entry point is.
At startup the operating system gives an automatic breakpoint at the start of the startup code. Obviously, the user of the debugger is not very interested in this, but in the function main or WinMain if it a windows application. The very first task of the debugger is to find the address of that function, set a break there, and execute the startup code without stepping through it. 

This was the first task I did when starting writing my debugger, and it took me months of effort before I could get there. I had to read all debug info, position myself in that address, write a breakpoint, start the program and find and show correctly the corresponding source line. I was really happy when the program at last stopped at main, and the debugger found the corresponding source line in the file indicated by the debug information... The longest trip starts with one step.

The debugger receives two events, when the process starts. The first one, is a CREATE_PROCESS debug event, and the second is a breakpoint that gets automatically setup by the system. It is important that the debugger doesn’t treat that breakpoint in a normal way, since it is set by the system. It would be a really bad idea to attempt to erase the int 3 instruction that is not really there.

What took me more to realize, is that the system will send this two events for each process that the program under debug will start. So, my debugger was confused when it hit a breakpoint after the program under debug executed a ‘system(something)’ function call. It thought obviously that it had hit an unknown breakpoint, and all the break point handling logic was thoroughly confused.
Debugger mechanics
Debuggers work by setting/unsetting breakpoints into the opcodes of the debuggee. The opcode for doing this is 0xCC, an instruction that takes exactly a byte, so it can be inserted anywhere at the start of an instruction. 

Th debugger first reads the byte from the debuggee code, and saves it in the structure that describes the breakpoint. Then, it changes the protection flags for the corresponding code page, writes the 0xCC opcode, and restores the protections as before.

When the machine stops at the breakpoint, and we want to go over it, the debugger does the following:
1. Restores the byte that was at that location.
2.  Puts the machine in single step, so that it will execute exactly one instruction, and then return control to the debugger.
3. Then, the debugger decrements EIP that is pointing to the byte after the 0xCC opcode the breakpoint instruction the program under debug just executed.
4.  Executes one instruction, by resuming execution with the single step flag on.
5.  Restores the breakpoint afterwards if necessary: it puts again the 0xCC opcode in the location where it was.

This way we can go over a breakpoint without erasing it.

When you enter the ‘next line’ command (F4), the debugger will put the machine in single step, and at each instruction, it will try to see if we arrive at a line number different from the one it started with. This may seem very inefficient, and it probably is, but it goes quick enough for human input. The debugger will have reached the next line before your hand has had enough time to leave the F4 key!

At each instruction then, it will see if:

Is this instruction the start of a new line of source code?
Is this instruction still within the current function?
Is this a call instruction?

Let’s look into the three cases more in detail. Obviously, if we see that we have arrived to a new line of instructions we are done. This is the easy one, we end the single-step mode and return to the user interface with the debuggee stopped.

More complicated can be the case where we suddenly find ourselves within a wholly different function! This can happen because somewhere a longjmp() call was done. In this case we have to resynchronize the debugger with the current point using the debug information tables.

If the instruction is a call instruction, we have to see where it is going. If we are tracing in, we have to establish a breakpoint at the beginning of the function we are going to call, and stop the single step mode.
This is not always possible, or even desirable. If the call is going into the system itself, it is better for a debugger to avoid setting breakpoints in there. Under Windows 95 this could make the whole system crash76.  If the call is going into a library function, it would be a waste to go in single step through all that function since we do not have the source of that function anyway. We set a breakpoint at the next instruction after the call and get rid of it when it gets hit. This will be explained in more detail in the next paragraphs.

Other instructions that cause trouble are the instructions with a repeat prefix. We do not want to single step potentially several thousands of times without getting anywhere. We have to treat those instructions in the same manner as we treat calls: we set a breakpoint at the next instruction, and erase it when it gets hit.
Finding out where a call is going to go.
There are several ways for a program to specify a call. It can be an easy, direct call, as when you write in C:

	foo();

But it can be more sophisticated like:

int (_stdcall *pstockObj)(int);

and then later in the program:

	pstockObj = GetStockObject;
	(*pstockObj)(WHITE_PEN);

This will produce the following assembly instructions:

[0000029] 8d3d00000000     leal   0,%edi   (_GetStockObject@4)
[0000035] 897df8           movl   %edi,-8(%ebp)
[0000045] 6a06             pushl  $6
[0000047] ff55f8           call   *-8(%ebp)

The debugger then, as to detect that this is an indirect function call using a memory address. It has to read that memory address, and then see if that address is within its known modules.

All indirect calls have an opcode of 0xFF (for the x86), but not all instructions that have 0xFF in the first byte are call instructions. The debugger takes this into account. It will follow even more sophisticated calls like:

typedef void * (*vfn)(int);
vfn FnTab[225];

and then later in the program:

	FnTab[i+180] = p;
	(*FnTab[i+180])(6);

This will produce the following assembly code:

[0000047] 8934bdd0020000   movl   %esi,720(,%edi,4)   (_FnTab)
[0000054] 6a06             pushl  $6
[0000056] ff14bdd0020000   call   *720(,%edi,4)   (_FnTab)
[0000063] 83c404           addl   $4,%esp

The instruction starting at byte 56 means « call the address pointed by _FnTab+720 indexed by the contents of the EDI register multiplied by 4 ». The debugger has to do exactly the same thing as the CPU will do, to find out where that call is going to go. This forces the debugger to look at the sib byte (see the chapter about the assembler at the beginning of this book), scale the contents of the register, read the resulting address, etc.

To trace or not to trace
What happens when a call instructions going into some code section the debugger knows nothing about?

After many false attempts I got to the conclusion that I would put the machine in step mode, execute that call instruction, and see where I arrive. If I arrive at an import call, and I am in step mode I put a “breakpoint” in the whole program. The next instruction that touches the code pages will crash, and give control to the debugger. 

If it is not a system routine, i.e. a normal library call with no debug information, I just read the value of the stack pointer. Since it is pointing to the return address (remember we have just executed a call instruction), I set a breakpoint there, eliminate the single step, and let the program execute the function with no tracing. The breakpoint fires when the program executes the return instruction, I clean up, and continue as before.

When you write in your code:
	unsigned long long a = 5;
	…
	b = a >> 5;

lcc will generate a call to an intrinsic function where the 64 bit shift is implemented, since there is no such an instruction in the x86 architecture77. This function call has no debug info, and could confuse the debugger if those function calls weren’t skipped.

In any case it is a wise decision to skip calls with no debug information, since when each instruction is examined by the debugger before executing it, perormance would be terrible. Imagine you were using a database library, and the debugger would trace each instruction in a database update!

The different debugger displays
The ‘assembler view’ (code) display
This view was the first one that needed to be done. To debug the debugger there wasn’t any other choice. I had to see if I was setting/unsetting the breakpoints as I should, stepping correctly in single step, disassembling correctly the current function’s instructions, etc.

This window consists of a list box that maintains in the LB_DATA field78, the address of each displayed instruction. I display only the contents of the current function. I added several enhancements, like displaying the exact bytes that are generated by the compiler (useful if you are the author of the compiler of course...), or embedding the source lines to see the correspondence between the C code and the assembly code.

This display works with the disassembler, a piece of software I found in a Unix system, and was probably a part of gdb, Gnu’s debugger.

The 'events' display
Each time something happens, the debugger writes a text description of the event into the 'events' display. This may seem trivial, too trivial to be mentioned, but it was (and still is) one of the best ways of debugging the debugger. I have invested a lot of effort in showing a clear and concise description of each event, gathering all relevant information that I could. For instance, when I receive the OUTPUT_DEBUG_STRING event, I try to get to the text of the string. I receive a pointer to an address in the debugged program's address space. There I can find (most of the times) the text of the string, which sometimes comes in UNICODE form. I test of the process ID of the process emitting the debug string is the same as the main process I am debugging, and if its not the case, I open the foreign process (created by the user program with WinExec or CreateProcess or whatever), read the string and close it. Most of the times, those strings are just loader messages telling it relocated some DLL into another address or other trivia. But sometimes, a crucial message can appear in those debug strings, so this can be a big advantage in some situations. A debugger should try to give its user a maximum of concise information about what is going on.

It is here, when I analyze every event for display, that I detect the loading/unloading of dlls, and try to load the associated debug information if available.

The ‘Memory watch’ display
The specs for this window are simple in principle:
It should keep a pointer to an area in the debuggee’s memory that is watched at each interaction. If anything changes, this window should display it.

Easy said, not so easily done. The key is to how display the changes for each line. I decided to change the color of text to red. This means that the listbox that contains the data must be an owner draw list box, since there is no way to change the text color for a single line in windows. The message WM_CTLCOLORLISTBOX, that allows you to change the colors of things, is meant for the whole list box, and not for each line.

The solution is to create an owner draw list box, and in the drawing procedure, test which line is being drawn. If that line is marked as changed, it will be displayed in red color, if not in normal text color.

The list box has to be subclassed too, since we want to have a contextual menu attached to the right mouse button that allows you to change the format of the display. Since all windows in the debugger should have a contextual menu, this is done by default for all those list boxes.

The drawing procedure keeps memory for the strings in the list box, and keeps a buffer where up to 4Kworth of memory is buffered. At each interaction, the debugger reads the contents of that memory, and compares it with the old contents.
The stack display
This window follows the EBP chain up to the startup stack. Mostly it will display correct results, but this can be very tricky especially in the case of a callback procedure. Callbacks are (as their name implies) procedures the operating system calls, when certain events or messages should be handled. Mostly they are window procedures, but they can be timer procedures or other.

The problem with callbacks is that their upper level stack goes into the system that sometimes doesn’t establish a stack frame for each procedure for performance reasons. The debugger has to be aware of this, and stop.

The algorithm the debugger uses is as follows:

1. Read 8 bytes from the address pointed to by the EBP register.
2. Bytes 4..7 contain the return address. 
3. Find out in which module that address is.
4. Find out the name of the function with that address in the module.
5. Bytes 0..3 contain the saved EBP value. Set EBP to this value and restart from step 1.
This will be stopped when there is no information (i.e. the debugger doesn’t find a module for the given address), or when the address of main() is reached.

The Locals display
This is a simple (compared to the others) display. Just find out the name of the current function; and read in the associated debug information the list of all local variables. This done, loop through that list, calling the evaluator with each of the names, and that is all. A little sophistication is built in, concerning the updating of the list box. The new results of each evaluation are compared to the previous results for the same variable. If something has changed, this line will be the selected line, and will be highlighted automatically by the list box in inverse video.
Displaying structures
The different kinds of breakpoints
There are different kinds of breakpoints:
Normal breakpoints set by the user.
Temporary breakpoints set by the user. For instance, the function key F7 means: run the program until it arrives at this source line. The debugger then, sets a temporary breakpoint at the specified line, and runs the program. If execution passes through that line, the program will stop, and that breakpoint will be erased.
Temporary breakpoints set by the debugger when it needs to skip a function call, or the prologue of a function in ‘trace’ mode.
Hard coded breakpoints that are set in certain parts of the system to wake up the debugger when something potentially dangerous happens. When you hit one of those, look at the events window. There is probably the output from a OutputDebugString that is usually done before hitting the breakpoint.
Data breakpoints, i.e. breaks that will happen when the processor uses an address stored in one the four debug registers.

The breakpoint structure has a Flags field that allows the debugger to see which kind of breakpoint is it, when it discovers one.
The operation in ‘Trace’ or ‘Step’ mode
In this mode, the debugger goes from one line to the next, unless it encounters a function call. When it sees a function call it will go into the code of that function, unless is a system call or a call to a function where no debug information is available.

Trace mode and Step mode provoke always that the debugger executes the machine instructions one by one, and examines each machine instruction. This is maybe wasteful of machine resources, but the alternatives are just too complex.

Basically, the problem is, that within the execution of a source line, control can pass through a jump instruction to any point in the program. Since in ‘Trace’ mode we want to follow function calls, it is essential that we do not let the program being debugged run without ensuring that it will stop. In principle we could analyze the next instructions to determine if there are any jump/call instructions that can change the flow of control, and set a breakpoint or a series of breakpoints at each one of them, but that looked to me too expensive. So I decided to always execute in single step. 

This works well, even if there are dozens of instructions and each one of them provokes a debugger stop, with control being passed from windows to the debugger, the debugger analyzing the machine codes, etc. In a Pentium 133 this is not even noticeable by the user when pressing F8. It takes probably less time to the debugger to do all this than it takes the user to move his/her fingers away from the F8 key!

Basically then, the algorithm followed by the debugger looks like this:
Before doing anything, clean up, close any popup windows, and record the current source line as the last source line executed.
Put the machine in single step mode.
Execute instruction after instruction until the program counter matches exactly a source line again.
If the program counter doesn’t match exactly any source line, examine the instruction and test if it is a ‘call’ instruction. If it is, see if there is debug information for the function that will be called. If there isn’t, or if we are in ‘step’ mode, i.e. skipping calls, set a breakpoint at the return of the call instruction. Otherwise, if there is debug information and we are in trace mode, put a breakpoint at the first line of the function referenced in the call instruction and reset the single step mode. Execution will proceed until the breakpoint is reached.
If the program counter doesn’t match any known module, we have reached (through a return instruction probably) unknown terrain. In this situation, the debugger sets the access rights of all pages of the program to NO ACCESS, and lets the machine execute without any single stepping. The next code access will provoke a trap. More about this later.

Interactions
The different behaviors of the debugger and its reaction to the events the debuggee sends can provoke unforeseen complications. For instance, imagine the following scenario:

We are single stepping through a function, i.e. in single step mode. All goes well, but suddenly, a trap occurs. The debugger is notified with an exception event, with a flag indicating that this is the first chance. Normally, the debugger ignores always the first chance notification, to give the exception handlers the possibility of continuing. So we ignore this, and return with the primitive ContinueDebugEvent.

We were in single step mode however, and we get immediately a notification of a single step exception. We read all registers, as always, but the instruction pointer is not in the place we thought it should be but in lcccrt0.asm. Why ? Because we are single stepping through the code of the exception handler of course, that is invoked by windows to handle the trap. Since the startup code in lcccrt0.asm sets up an exception handler that will be always called when an exception occurs, this is normal.

The code that checks the instruction counter, EIP, sees that this address doesn’t correspond to any known address, and thinking it has gotten into a system function, sets all access to the code pages of the debuggee to NO_ACCESS, as we described above. It sets a flag indicating this has been done, sets the single step flag to zero, and returns with a call to  ContinueDebugEvent. The poor debuggee continues, and of course, since we have eliminated the single step flag, it arrives at the end of the exception handler, and the debugger receives its second notification, i.e. the dreaded second chance notification that can’t be continued.

The debugger reacts to this second notification sending the exception to the access violation handler. That code however, sees that the flag for all pages in no_access mode was set, and mistakenly thinks this trap happens because one of the code pages was hit, what is surely not the case here. It sets the page access to normal, and tries to continue. Windows receives a continue command from the debugger, but refuses, the debugger having received the second chance notification, continuing is impossible. So the debugger sits stuck, waiting for debug events that will never arrive. Windows doesn’t move an inch.

The solution to this problem is obviously to set the single step flag to zero at each first chance notification, so that we never attempt to single step through an exception handler. This is easy to see afterwards, but not so easy to understand when you try to see why the debugger gets stuck!

Implementing the ‘step out’ feature
This should take you at the next line after the current function exits. To implement this, I set a temporary breakpoint after the last line in the function. Lcc-win32 never returns in the middle of a function, so this method will work with code generated with the lcc compiler. If we were debugging a program where the function epilogue is reproduced elsewhere in the function, we would have to disassemble all the function and set a breakpoint in all those places. 

An alternative to this method would be to get the return value of the function in the stack, and set a breakpoint there. The problem in this case would be the case of a callback function, where the code that called the current function is not accessible to the debugger. This problem led me to the first solution.

When control reaches the temporary breakpoint, I set the machine in single step mode, and continue normally using all other primitives until I reach the next source line. If, when executing the return instruction, control reaches a place where the debugger has no access, I use the ‘fast breakpoint in all lines’ feature described below.

The breakpoint handling routine has to be aware of the special kind of breakpoint that has been reached. I set one of the breakpoint flags to signal this to the breakpoint routine. When that routine sees this kind of breakpoint, the current function will be set in single step, and no displays will be updated until control reaches a source line again.
Implementing a fast « breakpoint » in all lines

If we have gotten into unknown terrain, it is essential that we can stop at the first instruction that corresponds to the modules we have some source, and that we stop the single step machine mode. We could be in an expensive system call that would execute several hundreds thousand machine instructions before returning. This would take forever if we stay in single step. Imagine: at each machine instruction, the debugged program would stop, return control to the system that will have to find the debugger. Then the debugger has to test the next instruction to see if we have returned to user code. For each machine instruction we would be end up executing maybe several thousand instructions!

The solution is simple: Use VirtualQueryEx to find out the range of pages of the code segment, and use VirtualProtectEx to set the access mode to all code pages to PAGE_NOACCESS. This will provoke an exception the next time the program attempts to read any of the virtual memory pages that contain its own code. That exception will be passed by windows to the debugger, that will reset the access mode of the pages to what it was before, analyze the program counter, and show the next source line that was hit.

Of course this supposes that the program doesn’t access the code segments in read mode… Lcc never sets any data in the code segments, but other compilers, specifically gcc, do set data in the code segment: the literal strings of the program (those strings that you write within quotes in your program) are setup in the code segment by gcc. The technique still can be applied to it though, but setting the access to PAGE_READONLY, to avoid this problem. The exception will be provoked when the program attempts to execute a code section, and not when it is just accessing the code to read some data. A trivial example for this is the statement:
	strcmp(str,”String”);
The strcmp function resides in CRTDLL.DLL, and if we setup the code segment to no access, the program will stop with an exception when it tries to access the String data bytes.79

Implementing the error window
The windows system stores at the thread information block at the offset 0x38 the current error code for each thread. This is the same value that you get when you call the GetLastError() API. 

I decided to implement an “error window”, that would allow automatic displaying of that value at each step. Besides I added some logic to reformat the message and add some explanatory comments with the FormatMessage API, which would add some coments to each error description.

Actually the implementing of the error window display (a dialog box), the correct positioning of that window within the output window of the debugger, and the interface with the rest of the debugger took more time than the actual reading of the value. As always, the software needed to implement the look of the data takes more time than the software needed to get the data in the first place!

Here is the code for the FindLastError function. It starts by using an LDT_ENTRY structure to ask Windows for the decoding of the FS register, since this segment of RAM is accessed using the FS register. We ask then: “Dear windows, could you please tell me where in RAM is stored this segment”?

We then build with some effort the actual address using a bit combination given in the LDT_ENTRY structure. Once we get the address 90% of the work is done. We just read that address and return the integer stored in there.

int FindLastError(void)
{
	CONTEXT *pCtxt = &Debuggee.Context;
	LDT_ENTRY ldt_entry;
	unsigned long baseAddr;
	unsigned int lastError;
	HANDLE h = Debuggee.hThread;


	memset(&ldt_entry,0,sizeof(LDT_ENTRY));
	if (!GetThreadSelectorEntry(h, pCtxt->SegFs, &ldt_entry))
		return 0;
	baseAddr = ldt_entry.BaseLow |
		(ldt_entry.HighWord.Bytes.BaseMid << 16) |
		(ldt_entry.HighWord.Bytes.BaseHi << 24);
	/* The error code is stored at offset 0x34 */80
	if (!ReadProcessBytes(baseAddr+0x34,4,(PBYTE)&lastError))
		return 0;
	return lastError;
}
Implementing the data breakpoints.
The x86 architecture provides 4 debug registers for storing up to 4 linear addresses. The processor compares the addresses the program is using with all those registers at each instruction, and if any comparison is true, it will provoke a fault.

Wedit implements those breakpoints by letting the user set up to four addresses expressions in a dialog box in the ‘debug’ menu. Each expression should evaluate to an address that is stored in the debug registers. A size attribute and an access mode are also set up. The access can be either read mode or read/write mode. Wedit doesn’t implement this kind of breakpoints for execution access, since it would be much easier just to set a breakpoint at the desired address.81

When the user presses OK in that dialog box, the input data is parsed, and then stored in the corresponding registers. The procedure for doing this is WriteToDebugRegister that lives in debug.c.

Wedit keeps a data structure to record that data, that is parallel to the structure store in the hardware. It is a simple array of four structures like this:

typedef struct tagDebugReg {
	unsigned long Addr;		// The address to watch
	int Size;				// The size attribute
	int Access;			// The type of access
	int Flags;			// Whether active or not
	char *Expression;		// The associated expression, if any.
	unsigned long oldValue;	// The old value store at this address.
} DEBUGREG;

Using this array, the debug register data can be convenientely associated to an ASCII tag, that means something specific to the programmer, instead of just the bare bones hexadecimal address.

The workings of WriteToDebugRegister can’t be understood without a map of the debug registers of the machine:82



We have then, 6 debug registers, from which 4 are available for debugging. For each register that we write, we should set the corresponding bits in the debug control register 7. For instance, if we put a value into Dr2, we should fill bits 20 and 21 of that register (DR7) with the access type, and bits 22 and 23 with the length of the area we want to watch, either 1,2, or 4 bytes.

Besides, we should set the corresponding flag for the debug register, in our case bit 2, that sets the debug register 2 as a local debug register for the current process, and not a global one for all process running under the operating system.

We know which breakpoint fired by looking at the lower bits of the debug register 6. Each of the 4 lower bits of that register will tell us which of the four debug registers fired. After reading those bits, Wedit sets them to zero, since the processor doesn’t do this.

What to do when a data breakpoint fires.
Windows report debug registers exceptions as an EXCEPTION_SINGLE_STEP. Since Wedit uses that exception fairly often, we differentiate this situation from all other by checking that we are NOT in single step mode, and that the debug register Dr6 has one of the 4 lower bits set. 

We have then, to disable the breakpoint, since the processor will retry the same instruction, debug breakpoints are traps, and serviced after the instruction has done its work. This explains that field ‘OldValue’ in the structure above. Wedit saves the contents of the breakpoint address so that we can report to the user the old value, and the new value stored.

We set then the single step flag of the processor, so that we will execute the instruction again. When we receive the EXCEPTION_SINGLE_STEP notification and this flag is set, we re-enable the data breakpoint and continue execution as before.

Note that when you set a breakpoint in a data structure that is used by the operating system, for instance a FILE pointer, the trap will happen deep inside the system dlls, when the machine accesses the address being watched. Wedit then, has to recover from that hairy situation, and figure out where the last executed line of the user program was. This is not always possible, so use this feature with care. A hint as to what happened is given of course by the variable name associated with the breakpoint..
Implementing the ‘ToolTips’ window
‘Tool tips’ are small text windows with an explicative note about a button, or an action. They are displayed when the mouse approaches a ‘sensible’ zone in a window, a place where an explanation is maybe needed. I thought that the debugger would gain in user-friendliness by using the same interface but instead of watching buttons, I would watch identifiers. The idea is that if you place the mouse in an identifier, the debugger should understand that as a request for further information, and display the contents of the variable or expression.

The implementation is as follows:
A timer is started when the debugger starts. It has two modes: a ‘slow’ mode, where there isn’t any ToolTip displayed, and a ‘fast’ mode, where a ToolTip window is shown already in the screen. The reason for this is to react immediately to any mouse movement when the ToolTip is displayed, but to react very slowly to display one. Obviously it would be a bad idea to display hundreds of ToolTips a second when you are moving the mouse rapidly from one word to the other.
When a timer click is received, wedit scans the text under the cursor. It extracts an expression, and if the evaluation of that expression goes to completion, it will display a small informative text. Any mouse movement or other input either from the keyboard or the menu, will provoke the closing of the ToolTip window, and reverts the timer into slow mode.
Recovering after a program crash
The mechanism for finding out where the program crashed is fairly simple: the debugger will scan all the stack, looking for addresses to points in the program. The first one that it finds must be the function that provoked the crash. The whole problem is, that the program can crash deep inside the system dlls, and there is no hope of finding any normally constructed stack frames in there. The code in the system is highly optimized, and very often the frame pointer EBP doesn’t contain an address in the stack but is used as a normal register! So, in the general case we can’t use EBP.

But how can we determine that an integer in the stack is really a return address and not by chance a data item that happens to contain a number that is similar to a return address?

There are no type tags in RAM. All that exists in RAM is a sequence of bits that can be interpreted as you wish. The only way to ensure that the return address is really a return address, is to go to that place in the program, and see if the preceding instruction is actually a call. Since the address pushed into the stack by the call instruction points to the next instruction, and it is a 32 bit number, we subtract 4 bytes to get into the real instruction, and verify that one of the several forms of the CALL instruction is found.

Debugging a program that just crashed.
Wedit will be called when a program compiled with a debug level greater than 2 crashes. This feature needs a collaboration of the compiler, the runtime, and of course, wedit. The process goes roughly as follows:
The startup is activated by the operating system when a trap occurs. It tries to determine if you have used the signal() mechanism for redirecting the traps to some procedure in your own code. If you have done this, it will call the procedure that has been indicated by the signal() mechanism.
If traps aren’t handled, it will call the _lccstacktrace() function, that will show a message box showing the stack. The Message box interface is the simplest one, and the one I thought it will surely work, no matter what. Remember that we are dealing with an exceptional situation here. The environment of the program can’t be trusted, maybe there is no more memory left, or the memory is completely corrupted, so it would be unwise to make calls either explicitly or implicitly to memory allocating routines, to open windows, or whatever. Besides, the message box interface will work with text mode or windowed programs, what simplifies things...
After showing the stack, the _lccstacktrace function will show you the message box with two buttons: OK and Cancel. If you press OK, the program will be terminated. If you press Cancel, the function tries to find Wedit, and will pass it the program’s process ID in the command line.
Wedit starts, and when processing its command line, will see the arguments from the runtime, and will attach to the crashed process, that is waiting, still in the _lccstacktrace() function, that things go on. Once attached, Wedit will determine from the debug information where the crash happened, and will load the corresponding source file. The current line will be positioned at the point of the crash, and a normal debugging session continues. Wedit doesn’t load any project, so all settings aren’t saved.

This is roughly what happens, but the details are kind of a mess. First, the runtime should not interfere with a trapped exception with the _try { } _except mechanism. In that case, control should go to the _except part of your code.
Determining if signal() has been called is even more messy, since it is rather difficult to know that. In any case, the arguments that the runtime receives must be saved for the _lccstacktrace() function to work, since the context of the program has been already destroyed... Happily, the OS saves that context and passes it to the trap handler, that uses a global variable to store that information for the debugger and for the _lccstacktrace() function.

More problems arise with Wedit of course. Attaching to the running process is not very difficult (a Win32 primitive serves that purpose), but problems start later, when Wedit has to determine if it was called as the default debugger, or called from an ailing run time. This last point is rather obscure, so it is worth to explain it here in a little more detail.

When a program crashes, windows NT looks at the registry variable AEDEBUG, to see if there is a default debugger installed. If it is, it will call it with the same arguments as the runtime, but with an hidden ‘gotcha’: a second mysterious argument. It took me a long time to find out that that second argument was in fact a semaphore that the debugger should reset, to indicate to the system that the debugger has gained control! No wonder none of the debugger system calls worked.

This should be possible under windows 95 too, but I am sorry to tell that I didn’t find out how it is done in that system.

Evaluating expressions under the debugger
The expression evaluator should interpret a snippet of program text, and produce a sensible output for its value. It is severally limited in the type of expressions that you want to evaluate, and above all, should be safe, i.e. if an expression can’t be evaluated for a reason or another, it should provoke anything extraordinary, no error messages, just ignore silently the expression.

Its grammar is very simple:

An expression should start with an identifier. (I will add *expr and &expr later).
It can be followed by either a bracket ‘[‘, a dereference operator ‘->‘, or a point ‘.’.
A bracket introduces the evaluation of a table. The identifier should be then either a table or a pointer.
The dereference operator and the point introduce a structure access. The identifier at the left should be either a structure or a pointer to one.
Optionally the expression within the brackets can be the result of an addition/substraction, etc. Those operations are allowed only in brackets.
A table index can be followed by another expression.
A structure dereference can be followed by another expression .

The evaluator uses a modified version of lcc’s lexer. It has been modified to be re-entrant, i.e. to be able to be called more than once simultaneously. Programs that have this characteristic are called ‘re-entrant programs’.

The evaluator scans characters, grouping them into the operators enumerated above. It leaves its result in a data structure that is used later for evaluating those expressions. As soon as it founds a character that is not in the categories above, it assumes the expression is finished, and starts looking for a new one. This makes it rather dumb, but it makes it bullet proof against syntax errors or the like. We must remember that the text passed to the evaluator can be any partial expression that is found in the current line by the editor. This expression could have unbalanced parentheses, brackets or whatever.

Once the input has been separated into expressions, the expression evaluator uses this information to build the corresponding value. If it is an identifier, for instance, the evaluator will look up this identifier in the debugger’s symbol table. If it is found, its type is determined using the debugger’s type table. Armed with an address and a type the evaluator is then able to perform the dereferencing of  a structure member, indexing an array or other operations.

To dereference a structure member, the evaluator looks up the members list in the definition of the structure, stored in the debugger’s type table. When it finds the member in question, it arrives at a new address, where it starts anew.

All information for the current evaluation that proceeds from left to right, is stored in a data structure that is updated at each step. When we arrive at the end of the evaluation, and the final result is a simple type, its value is displayed. Otherwise a construction {...} is displayed to indicate a complex (composite) type.

Displaying simple types is not specially complicated. Strings and arrays are cut at an arbitrary position. Other types are displayed as such (doubles integers, etc). Complex types are displayed each member in a row.

An example
The user moves the mouse at leaves it over the expression:
	z1.realPart
Step 1: After 800 milliseconds,  the timer wakes up the procedure for watching the text under the mouse. The software notes that the last coordinate of the mouse is different from the one it had stored. It notes the new position and returns.

Step2: After another 800 milliseconds, the same procedure is called again. Now it notes that the mouse position is the same as the last time. First, the procedure tries to validate the position: if the mouse has left the debugger’s window, or another window is in the foreground, or other events, the event will be discarded.

Step3: If the window under the mouse is the debugger’s window, the editor is called to furnish the line and column where the mouse is positioned. If there is text under that position , the debugger asks the editor to send the characters under the mouse position until the end of the current line. The editor verifies that there are no commentaries in the text given back to the debugger.

Step 4: The debugger sends that text to the lexical analyzer that groups the characters it receives into tokens and builds the expression data stack. For our example above it would build a stack of:

	ID		z1				<<< TOS
	Dereference	.
	ID		realPart

Step 5: The debugger then calls the evaluator with a pointer to this stack. The evaluator begins with the ID z1, the top of the evaluation stack. It will first look in the local variables of the current procedure. Then, if it is not found, it will look in the global variables of the current module, i.e. the variables that were declared with ‘static’ at file scope. If the symbol is still not found, it will look in the global context. If still the symbol doesn’t appear, it will look in the constants table, that holds the identifiers defined with the C preprocessor.

Step 6: If the symbol z1 is found in some context, the debugger will put in the TOS its address and its type. For constant symbols there is no associated type. The debugger must take care that the variable can live in a register, so there is no address associated with it. The compiler passes this information using the debug type ‘register’ and associating it with the variable.

Step 7: 
The evaluator finds then the dereference symbol ..This is OK, since we have a structure type. The evaluator knows that at the right side must be an ID. It finds an ID, and calls the debugger to find out the offset of the realPart member. This offset will be added to the existing address in TOS. The type in TOS will be the type of the realPart member.

Step 8: The evaluation stops. The resulting type is a double, i.e. a simple type. The evaluator gives this type and the address to the display part that prints the type at the given address and puts its output in a string buffer. Obviously, to find out the value of the type at the given address, we must read the data from the stopped process memory. The type information give us the size of the data area to be read, in this case 8 bytes.

Step 9: Using the resulting string from the evaluator, the procedure for watching the mouse calls the routine for opening and displaying a small text window, giving it the character string to display. That routine opens the window, shows the text, and returns.

Step 10. The mouse responsiveness is increased during the time when the small display window is open. The window should disappear at the slightest mouse movement immediately. The timer is then set to 200 milliseconds instead of its normal 800.
Implementing conditional breakpoints
Bugs that occur in obvious places, or provoke a trap are relatively easy to find using breakpoints. If the location where the bug occurs is heavily visited by the debuggee the problem arises that the programmer has to press F5 a big number of times before the situation where the bug appears is finally there. This may be even impossible if the number of times the program passes through that point goes beyond a certain limit (say 100.000). Besides, there is the big risk that the user, just hits F5 when the breakpoint is reached because of an error provoked by tedium, and he has to restart again.

The conditional breakpoint with a count only is quite easy to implement. Each time the breakpoint is reached, the debugger decrements the count, and only stops when the count reaches zero. This can provoke a performance hit of  course, since many breakpoint stops are done, but in general this is not a problem, and this solution is of course better than no count at all. Performance considerations are less important in a debugging context.

I have planned to implement other types of conditions, for instance evaluating an expression and stopping when the value of the expression changes.

Breakpoint properties can be set only when the debugger is active, and will not be remembered from one debugging session to the next. The rationale behind this decision is that this properties are very specific to the context, and could cause problems if the context slightly changes. This could provoke quite unexpected behaviour if a breakpoint is suddenly unactive because of a forgotten count that was off by one.
Getting to the Thread Information Block
For each thread in the system, there is a Thread Information Block, containing things like the stack start and current limit. This information is read by a process using the FS register, that has been setup by the system to point to a segment descriptor containing that information.

The problem for me was how to get to that dammed address, of course. All I had in my debugger was a small number like 56, that seemed to point somewhere but surely wasn’t usable as a right address to pass to ReadProcessMemory !

Looking up several possible functions in the documentation, I got hold of a structure called suggestively NT_TIB, defined in the windows headers. This structure contained as a first member the famous exception handlers list… This led me to think that it must be in the segment pointed to by the segment register FS. But how do I get from the FS value to the right address ?

The solution was obvious if you go to the API documentation and read, and read and read : Just call GetThreadSelectorEntry() and be done with it ! That function, will take a thread ID, a segment descriptor value, and a pointer to an LDT_ENTRY, that is filled by this function with the information about the segment your segment descriptor is pointing to.

To clarify things, let’s look at LDT_ENTRY :

typedef struct _LDT_ENTRY {
    WORD    LimitLow;	// ? look
    WORD    BaseLow;
    union {
        struct {
            BYTE    BaseMid; // ? look
            BYTE    Flags1;     
            BYTE    Flags2;    
            BYTE    BaseHi;  // ? look
        } Bytes;
        struct {
            DWORD   BaseMid : 8;
            DWORD   Type : 5;
            DWORD   Dpl : 2;
            DWORD   Pres : 1;
            DWORD   LimitHi : 4;
            DWORD   Sys : 1;
            DWORD   Reserved_0 : 1;
            DWORD   Default_Big : 1;
            DWORD   Granularity : 1;
            DWORD   BaseHi : 8;
        } Bits;
    } HighWord;
} LDT_ENTRY, *PLDT_ENTRY;

The obvious thing to do then is to combine the lower 16 bits (the BaseLow member) with the next bits 16..24  (BaseMid member) and then with the BaseHi to get bits 24..32 of the address.

This gets you (at last) the desired linear address you can pass to ReadProcessMemory, to read the famous TIB.

This stack information is displayed when you use the ‘info ‘ option in the debugger menu. This tells you immediately if a stack based variable is a right address or not. It allows you to see the size of each thread stack in real memory, i.e. the committed pages of stack, not only the megabyte of virtual memory.
Stopping a program and cleaning up
The procedure for stopping a program runs roughly like this:
First all running threads of the program under debug have to be stopped with StopThread.
Then, using the imports table of the program, I find out the import table for kernel32.dll.
Using this table, I determine the exact location in the program where the import stub is.
I set EIP, the instruction counter, to that address.
I resume execution of the program that will immediately execute the function ExitProcess. I do not bother to set the stack to return to return something, so the ExitProcess function will receive whatever was at ESP+4 as argument.
The ExitProcess function will make the system send the debugger an EXIT_PROCESS debug event. The debugger then, should close all open handles that were passed to it when the CREATE_PROCESS debug event arrived. This is very important, because if some handles aren’t closed, the executable file will stay marked as read only. This means that it will be impossible to rebuild the program, since the linker will fail to open the executable file for writing.

Starting a debugging session with a given executable
Sometimes you want to start the debugger with a program to debug. You can give Wedit a command line argument in the form :

Wedit <executable name> <executable arguments>

A dialog box will open, asking for confirmation, and if OK, it will start the debugger with that executable as the executable to debug.

Implementing this is not specially complicated, just tedious: the many variables and project parameters should be set to their right values, and the debugger started. For instance the current directory should be the directory where the executable starts, etc. Small details like the possibility of restarting (implying that the values should be saved somewhere for that) are important. Another source of problems is the absence of a project, meaning that all compiler options should be disabled…

Luckily, lcc-win32 writes always absolute paths to the executable debug sources, so there is no need to specify anything more to the debugger. If the program has the right debug information, it will find all source files it needs.

This option however, has provoked a lot of problems. Most of them were due to the absence of correct initialization after setting the debugger parameters : the files opened within the debug session would get confused with the files in the current project, and, in general, the current project got always somehow screwed up. This was due to a missing zeroing of the structure that contained the project, as I later found out.

Other debug information formats : the ‘stabs ‘ format. (gcc)
The gcc compiler uses its own format for the debug information. This format is essentially composed of two parts : A four field numeric record, and a more or less free format string.

typedef struct tagStabData {
	int strx;
	char type;
	unsigned char other;
	unsigned short desc;
	int value;
} STAB_DATA;

You can see this information with our old workhorse : pedump. The command :
pedump /d prog.exe
will dump the stabs information if it finds any.

To parse the stabs, wedit reads two sections from the executable : the ‘.stab’ section, that contains the numeric values, and the « .stabstr » section, that contains the strings. The very first stab record contains in the desc field the number of stabs records, and in its value field the size of the strings in the .stabstr section.

The stabs section is conceptually a table of STAB_DATA structures as described above. The stabstr section is a list of zero terminated character strings.

The following records after the first one, used for internal purposes, describe the path and the file name for the source file. The type of this records is N_SO (0x64). Gcc names its files with two of this records, the first for the directory, and the second for the file name. The directory is written in a Unix like fashion under windows : //D/dir1/dir2 is equivalent to D:\dir1\dir2. Wedit fixes this in the second pass over the stabs info.

For most stabs, the bulk of the debugging information is in the string field. The overall format can be described as :
	name : symbol-descriptor type-information
There is a « name » field, followed by a colon, then a single letter describing what kind of symbol the « name » represents, then the type information, that can be in two formats, either a type number, referencing an already described type, or « type-number =  », that means that a new type number is being defined.
Here is an example : 

int:t(0,1)=r(0,1);0020000000000;0017777777777;

This stab defines the type named « int », that is a type description (see the letter t after the colon), that is the first type (1) of the first file(0). 83 This type is (« = ») a range (« r ») that goes from  0020000000000 to 0017777777777 in octal notation. (0x80000000 to 7FFFFFFF in hex).

Note that this is specific for gcc under windows end of 1999. This is quite different for gcc under linux, or even other compilers that use stabs. This can change at any moment, since there is no fixed standards here.

As you can see from the example, there are no predefined primitive types here, and the compiler emits debug records for each of them. This may be seen as a waste of space and time, or as an increased flexibility, depending from your point of view.
Another example is the following structure declaration :
struct processor_costs {
  int add;	
  int lea;		
  int shift_var;	
  int shift_const;	
  int mult_init;	
  int mult_bit;
  int divide;
 };

this will produce the following stab :
processor_costs:T(8,1)=s28add:(0,1),0,32;lea:(0,1),32,32;shift_var:(0,1),64,32;shift_const:(0,1),96,32;mult_init:(0,1),128,32;mult_bit:(0,1),160,32;divide:(0,1),192,32;;
This means :
The name field is « processor_costs »
This is a tagged type (letter T).
This is a type in the ninth file (8), number 1
The type is being defined here (=)
It is a structure (letter ‘s’)
The size of the structure is 28 bytes
The first field is named « add », and it is of type (0,1), as we have seen before, an integer.
This field starts at bit zero and it is 32 bits long.
The next field is called « lea »
The same type (0,1) integer.
It starts at bit 32 and is 32 bits long.
The next field is « shift_var »
Same type
Starting at bit 64, 32 bits long.
Etc etc.

Looking at the possible types of strings we can write down a classification as follows :84

Letter
Meaning
a
Reference parameter passed in a register.
f
File scope function
F
Global scope function.
G
Global variable
p
Parameter to function
R
Parameter which is in a register
s
Local variable.
S
File scope variable
t
Typedef. This record names a type.
T
Tagged type. It can be followed by a lowercase t, to indicate that this tag will be used as a typedef. If the language being debugged is C++, all tagged structures are set as typedefs to follow C++ specifications.
V
Static symbol of local scope.
v
Reference parameter. This is a C++ feature.

Using the letter after the colon, wedit dispatchs into specialized routines to read each different type string. In the case above for example, it is a structure, we parse the fields, and we record its size. Wedit adds this name to the global namespace.
In C++ we have to take care about the other information needed : base classes, methods, vptr base, and other things.
Type definitions then, can be quite complicated. Here is a table of possible values for the field after the type :
Letter
Meaning
*
Pointer type. Example
va_list:t(15,1)=(15,2)=*(0,2)
A « va_list » is a type (t), the first in the sixteenth file, that is equal to the second type in the same file, that is equal to a pointer to type (0,2) i.e. char *.
&
Reference type
f
Function returning another type. Example :
typedef rtx (*rtxfun)(rtx);
Produces the stab
rtxfun:t(46,11)=(46,12)=*(46,13)=f(33,15)
« rtx » is some user defined type.
k
Constant qualifier
B
Volatile qualifier
@
Offset. This is used as a based pointer, a pointer relative to another object.
#
Method
r
Range type
e
Enumeration type
s
Structure
u
Union
a
Array
S
Set

As you can see, type references are numbered consecutively for each file. It is essential that the debugger builds for each file a table of types in the correct order. This was one of the main difficulties of wedit when building the debug info database.

Wedit finds the address of each symbol using the COFF symbol table. A minor difficulty in this is that gcc adds an underscore to the symbol table names, but not to the debug information names. The addresses are emitted as relative to the beginning of the corresponding section. This leads to following code :
unsigned long FixAddress(PIMAGE_SYMBOL sym)
{
    PIMAGE_SECTION_HEADER section;

section = (PIMAGE_SECTION_HEADER)(Debuggee.pNTHeader + 1);
	return section[sym->SectionNumber-1].VirtualAddress +
                   sym->Value + (DWORD)Debuggee.pImageBase;
}
We get first the section table, and index that using the symbol’s section number. That gives the starting address of the section. We add to that the symbol value, i.e. the offset within that section, and then we add the image base offset.
Organization of the stabs information.
Each compilation unit can have several files, and each file corresponds to a certain portion of the code space for the executable, as in the Microsoft debug info. Unlike the NB09 standard, it is up to the debugger to see that it identifies the correct source file. The algorithm I developed is just looking up the given address within all source files and see if I find a function that corresponds to the given address. If I do not find a function, and the start address of the file is smaller than the searched for address, and the end address is bigger, the file has a hole in it, and I have to go on looking.
Holes in a file can appear when you do things like :

file f1.c
int f(int a)
{
…
}
#include « f2.c »
int f3(int a)
{
…
}

We will have a hole that starts right after the end of function f, and goes on till the beginning of the f3 function. This hole corresponds to the code in the included file f2.c.

Within a file, the debugger builds a hash table for globals, functions and other stuff to avoid lengthy searches when running. For each symbol, its address is found, and a cross reference to its corresponding unit is done.
Wedit organizes this into a unit-list, each unit having a structure like this :

typedef struct _Unit {
struct _Unit *next;
struct debug_file *files;	// List of files
int NumberOfFunctions;
struct debug_function **functions; // list of functions
struct debug_type *types;	// Types defined in this unit
unsigned int StartAddress; 	// Where this unit starts in memory
unsigned int EndAddress;		// Where this unit ends
struct debug_function *CurrentFunction;
struct debug_file *CurrentFile;
struct tagGlobalSymbol **GlobalsTable;
struct tagGlobalSymbol **LocalsTable;
} ;
When the debugger stops somewhere, it will make the unit that encompasses the current ordinal couter the current unit, and will update the fields of it, finding out the current file, and the current function. In the GlobalsTable are stored the globally visible symbols, in the LocalsTable are stored symbols that are global to the functions in the file but not visible from outside the unit.

Next in the hierarchy comes the file description. It looks in principle like this :

struct debug_file {
struct debug_file *next; 
char *filename;	
struct debug_namespace *globals; 
int NumberOfFunctions;
struct debug_name **FunctionTable;
unsigned int StartAddress;
unsigned int EndAddress;
void *Window;
};

This list, contains the processed filename with the directory information, then the global namespace of this file, the number of functions defined and a table of function descriptors, the starting address and the end address of this file. A HWND pointer is abstracted as a void pointer, to avoid including windows.h here. This pointer represents the window where the text of the file is loaded in the editor.

The next step in this hierarchy is the function descriptor.
struct debug_function {
debug_type return_type;
struct debug_parameter *parameters;
struct debug_block *blocks;
int NumberOfLines;
unsigned long Address;
unsigned long endAddress;
unsigned long EpilogueEnd;
Symbol *sym;
struct lineInfo *Lines;
struct debug_unit *Unit;
struct debug_name *Name;
int NumberOfLocals;
struct debug_local *LocalsList;
struct debug_file *SourceFile;
unsigned long ebp;
};

We record for a function the return type, the parameters (if any), the blocks (scopes) it has, the number of lines, and a table of line number structures, where each line has a line number and an offset in the code of the program. There is a back pointer to the unit where this function is defined, a pointer to a structure holding the name, the number of local variables, if any, and a table with the descriptors of each local variable. A back pointer to the file structure help us getting the file where this function is stored quickly, and then an EBP pointer, to build rapidly the stack when the program is stopped. Here, the debugger records where the last frame of the function is. This supposes of course, that the stack frame hasn’t been optimized away.

The debugger records too where exactly the first instruction of the code of the function starts, in the Address, field. The endAddress field records the position of the first instruction of the last line in the function, and the EpilogueEnd field records where the real end of the function is, i.e. the first byte after the last instruction of the function, that should be normally a return instruction.
Parameters are recorded in a linked list, and the value field is here the offset from the frame pointer. 
Accessing the data base

There are multiple functions for accessing the debug information, of course. They query the debug information with different motives : FindFunctionByName(char *name) is different than FindFunctionByAddress(unsigned long address), for instance.
I have tried to maintain the same name for this routines as the module that reads the NB09 debug info with the perspective of one day having the possibility of loading programs with one type of debug info dynamically, making the debugging of Microsoft compatible programs with gcc generated code possible.
Bibliography about debugging
I found this articles/books useful :
How debuggers work. Jonathan B. Rosenberg. Wiley Computer Publishing 1996
A survey of Support for implementing Debuggers. Vern Paxson. University of Washington Technical report 262 Year 1990.
Mark A. Linton. The Evolution of dbx. Proceedings of the 1990 Usenix Summer Conference, Anaheim CA, June 1990
Customizing the editor
Here are some short recipes to follow to add special features for a customized version of the editor.
Adding a new menu item
You have to add the following things:
Add a new command identifier to the edcmd.h commands table. Just pickup the next unused slot.
Add your command to menuen.rc, where the command menu is described
Add a new case to the switch in HandleCommands or add a new entry to the Commands table.
Add a new entry to the weditaccel table if your command will use some accelerator
Write the handler

Adding a new key handler
You would start in HandleWmChar if it is a normal key (not really recommended) or modify HandleKeyDown in edit5.c to test for your new key.

The source distribution of Wedit.
The source files of wedit are located in \lcc\src\wedit. They are  (in alphabetical order):

File (.c)
Purpose
banner
Draws the banner that is displayed when Wedit starts.
bineditor
Implements the binary file editor.
bookmark
Implements bookmark handling. Set bookmark, go to bookmark, deleting a bookmark.
cdiff
Implements the diff utility.
cmscore
Implements the versioning system.
command
Implements the menu commands. Basically, all the menu WM_COMMAND messages end up calling one of the routines in command.c, that implements the action associated with the menu. Typically, this means calling some dialog box, and then acting accordingly.
config
Implements the configuration tab and the wizard for the compiler configuration when creating a new project. All the dialog boxes of the configuration tab are here.
controls
Implements the controls needed for the watch window of the debugger. They are implemented as a tree control, enclosed in its own window, that processes the messages from the debugger and shows the values passed to it.
copyright
Text of the copyright message that is displayed in the about box.
dbgdisplay
This file hash all the basic types decoding/displaying logic. The overall design is that starting with a type and an address, the debugger should be able to display any data type.
dbginfo
Reads the debug information from the executable.This means a lot of things like setting up the global identifiers table, processing the executable symbol table, setting up the type debugging information lookup procedures, finding out where the user’ s entry point is, etc etc. In this module is the logic for adding the dll debug info to the current debug information database when a dll is loaded. It is here too, that the import table processing is done, building a list of all the imports of a program.
dbgintf
Debugger user interface implementation. The debugger commands end here. Here is the code to display the assembly window, the watch window, the CPU window, and others. In general here is the interface with the rest of wedit. All dialog boxes that the debugger shows are processed here, all debugger window logic is done here.
Here is the start of the debugger, and the cleanup functions after the debugger is done.
dbgtypes
The table of debug types Wedit supports.
debug
Basic debugger machinery :  setting breakpoints, catching exceptions, etc etc. The code for resynchronizing the editor after a crash is here, together with the single stepping logic when tracing the debuggee. All exceptions handling logic is here, together with the scanning of the current instruction and the logic for skipping function calls.
dialog
Most of the dialog boxes in the editor. This file, together with edit2.c and wcmsdlg.c contains all the logic for initializing, showing and processing the information the user enters in dialog boxes.
disasm
Disassembler for the disassembly window.
drawtree
Draws the function tree.
edit1
Basic editor cursor movement, page up/down, etc. The buffer management is here too (adding/erasing an editor buffer). Towards the end of it we have functions that implement the lexical scanner for finding out which routine to call for implementing the <Query> functionality of the editor.
edit2
Printing, and several dialog boxes, displaying the software metrics, and other unrelated stuff :
edit3
Character input to the editor. Here is the ground logic for handling lines of text, inserting or deleting lines, etc.
edit4
Writing the configuration to or from the registry is done here.
edit5
WinMain lives here. Most window procedures for the main MDI window and the child windows is here. All display for the editor is done here in the function UpdateScreen.
edit6
Parsing for comments, finding out the structures, the functions etc etc. All the syntax handling functions of Wedit are here (scanning the function’s list, etc)
eiffeldbg
Eiffel debugger for the Small Eiffel debugger.
fileio
File input/output. Opening and reading in a file, writing and closing when done.
filestoolbar
Implements the open files tool bar.
genhlp
Generates the .hlp files from the source code.
globals
Global variables of the editor.
grep
Implements the grep utility. The main function is GrepFile(). Other functions are the GrepLineHandler, that handles the double click in the grep window, and the dialog box procedure for the grep input dialog.
ind
Indents and formats a C source file. This must be one of the oldest pieces of software running here. The documentation for that program is :
Pretty-printer for C Programs
Swiped from the CIPG's UNIX system and modified to  run under BDS C by William C. Colley, III
Mods made July 1980
And it works like a charm, twenty years later ! This proves the stability of the C language.
make
Handling of make file generation and calling the C compiler. The main function for generating the makefile is ‘GenerateDependencies’. The function for calling the compiler is called DoSpanMakeInternal().
menus
Menu handling, pop-up menus, etc. The main function in this file is HandleCommand(), that handles the WM_COMMAND message for the frame window. Most commands are stored in a command table, that this function looks up before going to the exceptions. The function AddCompileCFile adds to the compiler menu the items ‘Compile <file name>’ and ‘Execute <executable name>.
metrics
Software metrics module is implemented here.
objxref
Object file cross reference module. Basically this module scans the given object files, building a cross reference information about the symbols in each one, that gets by scanning their symbol table.
outputwnd
Implements the auxiliary output window at the bottom of Wedit. The main function here is the OutputWndProc, that handles the messages for the output window. That windows is basically an enclosure for a list box, that is processed and displayed according to which button in the list at the bottom of Wedit is currently active. This window procedure dispatches the double click messages to the appropiate double click handling function, that is associated with each button. If you double click in a line and the « search » button is active, the procedure called will be obviously different than when the « build » button is active.
prjoutline
Project outline implementation. This involves creating the tree control of the project, filling it with the information about files and functions, etc.
profile
Profiler.
regexp
Regular expression module.
search
Search module for the editor. It handles forwards and backward searches, with regular expressions or not, ignoring case or not, etc.
strtaben
String table. Most strings in the editor are stored here, but unfortunately not all of them. Under windows 16 bits it was very important not to use the precious 64K of stack+data segment, so constant strings were stored in resource strings. I countinued that under Win32 with the perspective of translating that file into other languages than English, but I wasn’t consequent enough. I converted the resource strings into normal C strings when I noticed that string resources were stored in Unicode strings, using two bytes for each character. This small change reduced the size of the executable by 20K almost.
subexpr
Automatic variable parsing for the debugger. This file is an adaptation of the lexer in lcc’s lex.c, but made re-entrant for the debugger needs.
wcmsdlg
Dialog boxes for the cms module.
wproc
General utility functions. In principle I wanted to put in this file all non-portable features too tied up to windows, but then, the OS2 version of Wedit faded away, and the Unix version will be too different to use such a simple schema.
wundo
Undo feature.



Bugs
Consider this one, I have it fresh in my mind as it were yesterday.
I compile the ‘rcl’ resource compiler for lcc. I had done a modification to the Unix .y (yacc) grammar file, and recompiled rcl for the first time with lcc, after retrieving it from the Unix machine with ftp.

Just to test it, I type ‘rcl’ at the command line. The dreaded ‘Application error’ box appears, telling me that rcl crashed. After some useless staring in the grammar file, I get into the debugger. The program seems to crash in a simple
fprintf(stderr, »Usage:\n ...\n »);

What is this? 

Maybe a compiler bug? Well, I pull an older version of the compiler from the backups and try again.

Crash

Well, I was doing some modifications to the linker yesterday: I cleaned up the code a little, added support for the registry to avoid typing the startup full path at each command line and other apparently minor modifications.

Maybe I introduced a new bug?

I pull an older version from the linker and try again. The bug doesn’t go away. Well, I rebuilt (again) crtdll.lib two days ago, the import library for the C run time. Maybe I introduced a bug there. Strange.

I pull an older version of the import library from the backups and try again. Nothing, but this time a missing export name appears. Yes, obviously. I rebuilt that library because of a real reason: it was missing that export. But really, I am dreaming here, an export library has nothing to do with stderr, this is nonsense. But I do not have the new corrected version anymore. 

I rebuild that from the .exp source using the implib utility. I hope that implib is working OK. Well do not get paranoic jacob...

I decide to use my old wonderful test program. I write
#include <stdio.h>
main(){fprintf(stderr, »Hello\n »);}

and compile that.

Crash.

What? This is impossible! I have already built dozens of programs using stderr damm it. What is happening here?

And then panic sets in. Slowly, very slowly but surely. All this work, years of it, are absolutely useless if lcc-win32 is unable to compile a program of a few dozens of bytes... When did I introduce that bug?

I switch to MSVC. Follow the program in binary. For the startup code, where the initialization of ‘stderr’ is done, I have no debugging information since I wrote that in assembler. Surely, I have the source, so I can open a window with an editor besides the debugger window, to see what the program is doing. The initialization of stderr goes on without any problem. The returned values from the system calls are correct. What is this, what is this, I get more and more nervous. 
I step in into the ‘main’ function. And then, I compare the value pushed by the program to the fprintf function with the value returned from the system earlier. What is this, it is pushing a WRONG ADDRESS!!!! 

Well, I found why the program crashes, but this looks even worst than before. Using Windows’s ‘calc’ program, I substract the two addresses, the one being pushed, and stderr’s one: almost 8K difference. The panic sets in: this is a linker bug.

Linker bugs are not the ‘easy’ stuff. Even for a small program like ‘hello’ there are dozens of import libraries object files to link in, hundreds of symbols, following all the operations of a small link in the debugger can take at least 3-4 hours of enormous concentration. And then that voice back in my mind... ‘You are CRAZY jacob, Microsoft has dozens and dozens of bright young people working in their compiler. You will NEVER make it alone, it is just impossible, utterly impossible!’. I turn it off, as you do when you zap to other program in the TV.

Did I introduce that bug yesterday, when I changed that code, or is this an older bug, that surfaces now?

But... wait, I have already pulled an older linker from the backups! This is an older bug obviously, and has nothing to do with my changes yesterday. Where is it?

I spend some hours staring at the code, making modifications here and there. Nothing, the program will always crash.

But where is this wrong address coming from actually? I dump the object code and look at the disassembled code. What is this? It is pushing the address of _iob instead of the address of ‘stderr’. Well obviously this is the reason. But why is this _iob being pushed? I look at my include files. Nothing. ‘stderr’ is defined correctly as an extern FILE *. But there is obviously SOMETHING that is changing ‘stderr’ into ‘_iob’. The dumps shows clearly the relocation to an _iob symbol. Where does that come from? There is a bug in the preprocessor?

Well, it could be, I made the same modification to the preprocessor that I did to the linker: Lookup of the ‘include’ path in the registry. But this is nonsense. I didn’t touch any of the macro-expansion logic, I just added a routine to replace the ‘getenv’ call with that ‘INCLUDE’ environment variable that was somehow always pointing to the wrong MSVC header files. Replace it with a clean solution: lookup in the registry. This just can’t change the workings of the preprocessor...

But wait, maybe that _iob comes from the MSVC header files? Maybe this is not a linker bug after all. I start an editor with the contents of <stdio.h> of Microsoft’s compiler. And YES, look at this:
#define stderr (&_iob[2])
THERE IT IS!

I am using the wrong header files, that’s all!

But now I am in a general mess: I have done several modifications to the linker, maybe introducing more bugs, Oh dam it, I have to undo all that. And I did no backup of the new version since I considered it buggy!

The panic starts to fade. Well, I will undo those changes. I clean up the best that I can, because I do not want to rewrite the Registry functions: they were messy to write, they were working. Besides there were other bugs corrections I didn’t want to loose.

Half an hour later I have undone them. I recompile the linker, and compile my test program forcing it to choose lcc’s header files:
d:\wedit\lcc\bug26 > lcclnk -L d:\lcc\lib lcccrt0.obj hello.obj

Crash

Well obviously, I should recompile first... getting tired.

d:\wedit\lcc\bug26 > lcc -Id:\lcc\include d:\lcc\lib\lcccrt0.obj hello.obj
d:\wedit\lcc\bug26 > lcclnk -L d:\lcc\lib lcccrt0.obj hello.obj
d:\wedit\lcc\bug26 > hello
hello
d:\wedit\lcc\bug26 >

MMM this works. I was just using the wrong header files. But I had changed lcc to use the registry! What happened? I start regedit and look at the values in the registry. They are OK. Why it doesn’t use them then? 

I recompile lcc with MSVC. It looks correctly in the registry and generates the good code. I start getting nervous again. A bug in the optimizer? I have lost almost the whole day in this nonsense.

My wife tells me I promised to get away from the machine today. I am looking for this bug since 8:AM and is almost 4:PM now. I stop, take a break. It is cold outside, a chilling freezing cold: minus five C°. I eat something and go for a walk in Paris with Annie.

After dinner, I come back to the machine. I reboot, rebuild first the linker, then I recompile lcc from source, make two generations, and install it. I compile the test program. It works perfectly the first time. WHAT HAPPENED??? 

Then I realize it: Right at the start, when I saw the crash in rcl, I pulled an older version of the compiler. The one that DIDN’T use the registry. But in my mind, the ‘wrong headers’ bug was in the ‘corrected’ folder. Gone for good. So I expected that the older version used the registry in an infantile lapsus. Of course it didn’t, and just used the ‘INCLUDE’ environment variable that pointed to the MSVC’s header files... That led me astray in a chase for an inexistent linker bug. Well, I did the whole circle, let’s come back to rcl. It should work now.

Crash as in the morning

I look at the address of ‘stderr’. It is completely wrong. It is late. I will change the INCLUDE path, and force it to lcc’s. Well, nothing. Crash.

And then I see in the linker command line:
-subsystem windows
Well OF COURSE! Windows programs do not initialize the standard handles! In a haste I hurry up to change that to
-subsystem console

The error message of rcl appears in the screen. The ‘stderr’ variable is OK. It was just that: a wrong linker specification in a link...
 
A whole day of hard work is lost. For nothing. I am as advanced as I was in the morning. But I gained a good advice to put in the ‘Troubleshooting’ part of the doc...
Analyzing bugs
I decided to write a small, simple minded scanner that parses all files in \lcc\buildlib\*.exp and builds a table of two columns with: at the left the API name, and at the right the name of the DLL. This would allow Wedit to add automatically the missing library to the project when it would detect an undefined symbol error message from the linker.

This was, I thought, a simple program. I used a very straightforward design : the program calls the findfirst window API (FindFirstFile) and then FindNextFile to get all the names of the .exps. Then it will open in sequence each file, storing the DLL name (first line) and the API name in a linked list. At program's end this list is printed in stdout.

The problem was, the program trapped, and I couldn’t find out why it was trapping.

 To find a bug, the first thing to do is to gather as much information about the behavior of the program as it is possible. I do this almost without thinking now, and start to experimenting with the program, changing compilation options to see if it will change the behavior of the program or not. This is because when compiled with MSVC 4.2, the same program run perfectly, so I started suspecting a compiler bug.

The type of error I was getting was relatively easy to spot. The program would trap without the debugger. If run under the debugger, the program would stop opening any files after opening 14 of them. The 15th would not work any more.85

Changing compiler options lead me to turn optimizations ON. I was completely surprised when the bug disappeared as soon as I compiled with optimizations. This was the first time ever that turning the optimizer ON would solve a bug. The mystery deepened.

What could be the reason for a program crashing with NO optimizations and working when they are turned on ?
It took me a while to arrive at the heart of that difference. When you compile a program with lcc-win32 with no optimizations and with debug information ON, the compiler will generate code to set all local variables of each function to a known bad value that will make most programs crash if used : 0xFFFA5A5A. The compiler generates following assembly code :

_AddToOutput:
   pushl  %ebp       ;save old frame pointer
   movl   %esp,%ebp  ;move stack to new frame pointer
   subl   $1032,%esp ;make space for locals
   movl $258,%ecx    ;1032/4=258: number of 32 bit numbers in the stack
_$79:
   decl   %ecx       ;ecx runs from 257 to zero
   movl   $0xFFFA5A5A,(%esp,%ecx,4); set the local variables to a known value
   jne     _$79      ;loop as long as ecx > 0

In C, you can see this as :
	for (i = 257 ;i>= 0 ;i--)
		esp[i] = 0xFFFA5A5A ;
I stared and stared at the assembly code, and couldn’t find any error in it. But the fact was, when I erased those lines, the program would run.

Often in debugging, the culprit seems easy to spot, but often too, the first culprit is not the one you are looking for. This behavior pointed irresistibly to a compiler error. It was 4AM, I was exhausted. I went to sleep, and the next day, I re-examined the situation again, trying to grasp what could be wrong.
The function where all the problems were located looked like this :

int AddToOutput(char *FileName) // FileName contains the name of the .exp
{
        FILE *f;                // input file
        char buf[1024];         // line buffer
        int i=0;                // counter
        static int count;       // files opened counter

        f = fopen(FileName,"r"); // open the file for reading
        if (f == NULL) {
                printf("[%d] Impossible to open %s\n",count++,FileName);
                return 0;
        }
        count++;                // increment the number of files opened
        fgets(buf,sizeof(buf),f); // read a line
        ExtractFirstWord(buf);    // put a \0 at the end of the first word
        strcpy(DllName,buf);      // copy into DllName the first word
		… etc …

The function ‘ExtractFirstWord’ looked trivial enough. I never gave it a lot of importance. It was like this :

static void ExtractFirstWord(char *p)
{
        while (*p && (*p != ' ' && *p != '\t' && *p != '\n'))
                p++;
        *p = 0;
}

Simple :  look for end of string or one of the characters that end a word like the new line, the spaces or the tabs. When you find that character, cut the string at that position writing a zero. I wrote that in a few minutes. The problem was, however, that nowhere did I check that the pointer didn’t go beyond the end of the buffer that was passed to it. Why did I forget that ?

Exp files are special files generated by lcc-win32. They have all a strictly similar structure, and I assumed that they would be OK, i.e. I never contemplated the possibility of a badly formed input. And this, is always a bad mistake.

As bad luck would have it, I had somewhere in my \lcc\buildlib directory, a .exp file that was empty, i.e. it had a length of zero bytes. I do not know how it came there, but in any case that file was in there.

What happens then ? 

In the function ‘AddToOutput’, after opening the empty file, the fgets that read from the file would fail :

        fgets(buf,sizeof(buf),f); // read a line. Note : no test for errors !
        ExtractFirstWord(buf);    // put a \0 at the end of the first word
        strcpy(DllName,buf);      // copy into DllName the first word
The function would fail, but since its return value wasn’t tested, the program would continue as if nothing has happened. Now, the buffer was still uninitialized, i.e. containing the value 0xFFFA5A5A. This rubbish would go then into the ExtractFirstWord function that would start scanning those chars, looking for a word terminating char. But it would never find it, and would go without any problems beyond the end of the buffer, writing a zero somewhere in the stack !

Now, remember the order of the declarations of the local variables in that function:

        FILE *f;                // input file
        char buf[1024];         // line buffer
        int i=0;                // counter

This means that the next variable beyond the end of the buffer would be the file pointer ‘f’ that would get destroyed. The function would then call gain fgets, but this time with an invalid file pointer. As it seems, CRTDLL.DLL, the runtime of lcc-win32 doesn’t test for validity the file pointer it receives, and that bad pointer would destroy surely a lot of data structures and stuff in the run time file i/o module. It would then be impossible to open any more files, the whole i/o system would be completely screwed up.

Now, why this stuff worked with MSVC?

Because MSVC doesn’t set the stack to a known value, and a 1024 byte buffer will probably contain a zero somewhere. Since the contents of the stack are probably zeroed by the OS when it starts the program, the ExtractFirstWord function would find a zero well before the end of the buffer, and nothing serious would ever happen.

But the program would still contain the bug, only that the bug would be totally invisible and maybe it would go undetected for the lifetime of the program.
Or maybe not. The worst situation I can imagine is when a program has a bug of this kind that will appear only in very unusual circumstances, making the program crash at random, not very often to find the bug, but often enough to make the whole software unusable!

Finding this kinds of problems is very hard. I was very lucky to have had a trap. The situation would be much worse when this piece of code would be checked in into a much larger software project. The bug would go undetected, but several weeks later, the whole software would start crashing sometimes, at random. The crashes could be in another, completely unrelated part of the program, where a crash would be just a consequence of the bug, pointing the maintainers of the code into completely the wrong direction.

Debugging these things is even harder because the bugs you can ADD when trying to fix things. Imagine the maintainers of the code when they crash at the function xxx(). Obviously, they will try to see what in that function is wrong, and it will take a long time till they realize that the crash comes from a badly formed pointer that the function is receiving, a bad pointer coming from another function that has to be followed, etc. A lot of work for the maintenance people.

This kind of bugs is typical of the C language: a pointer that points somewhere in memory, and is incremented without any tests for bounds.

Debugging is an art, and there are no well-established algorithms that you can always apply without thinking. The best thing to do is to follow rules like:

Make yourself a set of tools specific for debugging, and even specific for the bug you are looking for. Do not hesitate to add printf statements to your code, but be aware that each added statement makes possible the introduction of a new bug.
Debuggers are nice, and can save you the writing of those printf statements, but they can’t match the flexibility of the printf when a complicated set of conditions must be tested. You can combine both methods (debugger and printf) if you set a complicated condition for the printf and just set a breakpoint in the statement. For instance :

if (descriptor->filename != NULL && 
    somefile != NULL &&
    !strcnmp(descriptor->filename, somefile ,6 ))
	printf(« kuku\n ») ;

You just set the breakpoint at that nonsense printf statement.
History of your software is essential. No serious software development can be done without a record of the changes you (or others) have done to the software. When looking for a bug in the compiler, for instance, I always try to find a previous version where this bug doesn’t appear. If I find it, this tells me a great deal about the bug, its origins, and maybe how to correct it.
Design your software to make it easier to debug it. Assertions (pre-conditions, post-conditions) are a good way to spot earlier the errors that may crop in. Build a debug and trace output for your software. For instance, in the compiler, the –z option, that prints the intermediate code output in a readable form has proven invaluable to debug the interaction between the front end and the code generator. Before I built that, I was forced to follow the intermediate code representation as a sequence of numbers in the debugger. Horrible. The possibility of reading a good formatted intermediate code listing has speeded up development greatly.
Remember that most of the development time is spent in debugging. The time you loose writing debugger aids is always gained later, when you can spot bugs rapidly.

Correcting bugs
Well, this is the easy part, you would say. Once the bug is found there are no problems any more. Well, I am not so sure. You can introduce new bugs when correcting a program. And this will nullify all the efforts you did, starting a loop ! Try to make sure that you correct the bug you found and that your correction doesn’t introduce new, unforeseen problems later on.

Sometimes, of course, the correction is trivial, as in the example in the preceding pages. But sometimes it is not. The bug can point to a flaw in your basic design, or just be one of a set of problems that you didn’t foresee when writing the software. Try to look at similar problems in related parts of the program. When correcting a bug, it is not a bad idea to correct all other ones of similar scope that could be in there just waiting to bite you.

I can say this from my own experience, especially with the compiler. Here is another case story:

How I introduced the bug 
In the earlier versions of lcc-win32, the code generated for the expression :

int r = (i - 6)/2;	// i is a static or global memory
				// location

introduced an unnecessary register move :

movl    _i,%edi	; uses %edi for nothing
movl    %edi,%eax	; moves %edi to %eax
subl    $6,%eax	; substracts 6 from %eax
movl    $2,%ecx	; puts 2 into ecx
cdq				; prepares division
idivl   %ecx		; division

The unnecessary move used up a register, a precious resource in a register starved architecture like the x86.

To correct this problem then, I added the following rule to the machine description:

reg: SUBI(mem32,con) 	movl	%0,%c
subl	%1,%c

This rule produced for the same code snippet above, the following :

movl    _i,%eax	; uses only %eax
subl    $6,%eax
movl    $2,%ecx
cdq
idivl   %ecx
MUCH better, I thought. 

I was happy with this for months, until Mr. Hamel, from CEA sent me this program snippet:

void bugsub(char *text)
{
    static int i, l;

    i = 4;
    l = 10;
    bugfn(text + (i - 1), l - (i - 1));
}


Note the common sub expression (i-1). This common sub-expression would get stored into EDI. The code generated looked like this :

movl    _$2,%edi	; put i into %edi
subl    $1,%edi	; substract one
movl    _$3,%edi	; BUG BUG : destroys the value stored
subl    %edi,%edi	; into edi, substracting it from
pushl   %edi		; itself, pushing zero ! ! !

How this bug came about?

It is obvious that the problem was that the register allocator thought that the register EDI was free and allocated it to a new variable.

It is obvious too, that Mr. Hamel had done a lot of previous work for me. Most of the time, in debugging problems like this, the bulk of debugging time is spent trying to find where the bug is. Here, I could get into the subject matter quite easily.

Well, then I applied my rule : Review the software history to find more about the bug. I discovered that the bug appeared after version 35 of the compiler. Older versions would generate correct code. This fact allowed me to come to the rule I explained above. Now, with 100% hindsight, things look clear and logical, but it wasn’t like that when I was trying to find out which piece of the software was wrong.

Then I started investigating why the register allocator thought that the register was free. I compared the two versions, running two versions of the debugger at the same time to see where they diverged. I added the equivalent of a printf statement just before each allocation, so that the compiler would show in the standard output what intermediate expression it was assigning a register for.

I discovered that version 35 showed as the first statement:
	INDIRI(ADDRGP(i))
The buggy version showed however:
SUBI(INDIRI(ADDRGP(i)),CNSTI(1))
The problem was, basically, that freeing the register edi was correct when the register was just an intermediate expression, but catastrophic when the expression was a common sub expression that would be used later! Note that the expression (i-1) was a common sub expression (cse).

Correcting the bug
This was the most difficult part.
After much brain storming, I decided to add a condition to the rule above: that rule should never be used when the memory location represented a common sub expression. I changed the empty optional C code to contain a call to a small routine that would test if the first argument was a cse, and in that case would return the maximum cost for this rule, avoiding effectively its use.

Is this correction enough?

I changed all similar rules in win32.md too, but I fear that this story doesn’t finish by a happy end, and that this problem will come again. There are several issues here, especially in the construction of the register allocator, a software part that has always been a hard problem to use, and is, in my opinion, a very weak part of the lcc system. This is an example of a bug that points to a weakness in the software system, it is not just a typing mistake.

Classifying bugs
The origins of bugs can be classified according to their ‘position’ within the software system: 
Internal bugs, i.e. bugs that are caused by internal inconsistencies/errors
External bugs, i.e. bugs that are introduced into the program by other programs.

Normally, we always speak about the first ones, but this is often not the case: as a compiler writer I am painfully aware of the problems I have introduced into my user’s programs. The compiler can be a source of bugs within your program, and it is better for compiler writers and for compiler users to be really aware of this fact. It sad to say it, but most compilers contains bugs. This is because perfect systems are beyond what software can guarantee today.

I have tried as much as I could to get out a tested and well performing system, but the set of all possible C programs is infinite,  so there is no hope of testing the compiler for all possible code generation circumstances. Take for instance the pre-processor of lcc, written by Dennis Ritchie. It has been running for years and years, and the total number of gigabytes that has passed through it must be enormous. Yet, myself, I have cleared several errors within it. This is not to say that Dennis is a bad programmer, or a careless engineer. It is just the mechanics of it that make perfect software impossible, as it stands today.

Other programs that can introduce bugs within your program are the operating system components. We all know the sad history of COMCTRL32.DLL, and its many updated/upgrades/versions/features that make the maintenance of windows programs so difficult. A new version of that DLL (or from other dlls) can be a source of new problems in your software.

Internal bugs are more interesting, from a debugging standpoint, and by far the ones you will find the most. We have several origins for these things. Here is a tentative list in increasing order of difficulty:
Typing/misspelling errors.86 These bugs aren’t just a matter of a ‘syntax error’ report when compiling. It means that you mistakenly close one file instead of closing the good one because they had variables with similar names, and when you wrote that you were tired. This can be VERY difficult to find later, several months later say, when your program passes by chance by those lines your wrote at 2: 00 AM.
Accessing write only memory. Write only memory is uninitialized memory. All memory locations not previously assigned can contain anything. Using those bit patterns as data can provoke memory corruption or a crash. These errors can be difficult to spot when the variable is passed around to other procedures before being used, so that the error manifests itself far away from the real source of it.
Unrestricted pointer usage. This is a common problem in the C language. I gave a case study above, and this problem is very old. A pointer is incremented or decremented along a buffer without having code to check that the bounds of the buffer aren’t exceeded. This can result in memory corruption or in a crash. Obviously the case of a simple crash is much easier to spot than the case of memory corruption ! I would say this is more a ‘language’ bug than really a user bug. The C language is very prone to those kinds of errors.
Memory allocation/deallocation problems87. This ranges from allocating the wrong amount of memory, freeing a variable twice, and using freed memory and other chores. This bugs can be hard to find if the consequences of freeing a range of memory locations is felt when another module, completely unrelated to the module that freed it tries to use the data it supposes its there.
Not coping for bad input conditions88. In general a program makes several assumptions about its input data, assumptions that can prove wrong when the program is confronted to real world conditions. Take that famous bug in the Ariane 5 rocket, for instance. That bug was a consequence of the program of the Ariane 4 rocket, that had a much slower speed than Ariane 5, being just copied to the Ariane 5 software without checking that the input data still failed within the original specifications of the program. Consequence, the program had an arithmetic overflow when trying to convert a double precision number to a 16 bit number and crashed, making the rocket crash literally several seconds later.
Not coping with the consequences of a change to other parts of the system. Software is soft, i.e. easily changed. The introduction of a change however, is an endless source of problems. The difficulty here is that in general it is just impossible to foresee all consequences of a change, however small, in a software structure that has attained a certain degree of complexity. This can range from simple mistakes like adding a field to a structure and not recompiling all other modules (and dlls !) that use it, to much more subtle problems like the one with the new rule I added in the example from lcc-win32 above.
Pre processor bugs. The C pre processor can introduce a whole new set of interesting problems. Here is a short list, important, because those bugs are quite difficult to detect:
Missing braces in multiple statement macros. When you define something as a multiple statement definition, you should take care to avoid constructs like this:
#define f(x)    print(x); error(x);
If your define is used within a conditional, the expanded source text will look like:
if (…)
     print(x);
error(x);
Side effects in macro calls. You should ensure that each expression within a macro is evaluated once. For instance:
#define sqr(x) (x*x)

When called with 

sqr(i++);

the variable i will be increased twice.
Operator precedence errors. Consider the following macros:
#define twice(x) x+x
Now, when used in
Y = 3*twice(x);
The resulting expression becomes:
Y = 3*x+x;
What is different than what the programmer intended, since it is equivalent to (3*x)+x.
Reporting bugs in lcc-win32
As any other software construct, lcc-win32 is surely not exempt of bugs. You can report them to me by writing to :
jacob@jacob.remcomp.fr

But, before you hurry to send me messages like : « My program crashes ! Please tell me what’s wrong ! » consider the following points :
If your program crashes somewhere, it is highly unlikely that the compiler is wrong. Program crashes are fairly common, specially if you are beginning to learn the C language.
If your program crashes when you change the optimizer settings, it might be an optimizer problem, but it could be another thing too. Please try to isolate the problem in a short (at most a few lines of C) example so that I can work on it. It doesn’t make sense to send me several megabytes of dumps and several megabytes of C source with the vague hint : « This doesn’t work ». I would never find the time to wade through all that to find where the problem is in the first place.
Link errors are solved by adding the right libraries to the linker command line. Obviously, if a function is entirely missing but is mentioned in the documentation you should report that.
Header file errors are easier to spot : if possible send me just the correction, what in most cases is easy to find.
Try to report the exact compiler settings used when compiling : debug information generation (g2,or g4 for instance), etc.
Describe exactly the symptoms, and give as much information about the crash as possible. Please note that the processor type is NOT important, but the type of OS (Windows 98 or windows 95, which service pack, etc) should be included in the bug report.
Memory management

Since quite a long time, the data processing field is in the search of a “silver bullet”, a magical remedy against many (if not all) problems that plague software develoment. If you put hype aside, what is an extremely difficult thing to do in a field where hype is so engrained in the habits of people, all those magical solutions reveal themselves as half-solutions, or worst, no solutions at all.

Take the problem of the management of memory: avoiding memory leaks, and disposing of objects no longuer needed. The C language relies in the programmer. It is up to you to acquire storage, and to release it when it is no longuer needed. The programmer has plenty of occcasions to go wrong, of course, and memory management can take a lot of the total software development time.

The solution in languages like Java89, for instance, is to install a ‘garbage collector’, i.e, an automatic system for reclaiming objects that are no longuer needed. This should in theory be the silver bullet: no messing around with garbage collection, all is automatic.

But, as you may imagine, things are not so simple. Objects are allocated on the heap using the new operator of the language, something roughly equivalent to our old ‘malloc’, and accessed via references. The heap forms a directed graph, where objects are the nodes and the references between objects are the edges of the graph, i.e. the connections in this network. The garbage collector at least, sees the memory this way, as a connected network of objects and references. The purpose of the garbage  collector is to remove from memory objects that are no longer needed.

The GC mechanism finds out when an object is no longuer needed by searching for a path from the roots to each object. If it doesn’t find it, the object can’t be reached by the program, and can be safely deleted.

The problems arise when we realize that even if the garbage collector will identify and delete all objects that aren’t reachable from the roots, it will never find out the objects that aren’t actually needed by the program but can’t be deleted because some other object has a reference to them. 

In Java, the programmer doesn’t directly manipulate the heap, as in C. In C you have to manage the nodes (i.e. allocate the object with malloc or a similar function) and manage the edges (connections) of the network, by explicitely managing pointers. If you delete an object that is referenced somewhere else, you leave a dangling pointer, i.e. a pointer that points to nowhere. In the other side, if you delete all references to an object without deleting the object itself you make a memory leak, i.e. you create a portion of RAM that can’t be accessed.

In Java, when you have a memory leak, it is often the case that a large set of objects is leaked: an object will contain references to other objects, making a large portion of RAM be considered reachable when it isn’t any longuer useful to the program.

There are several kinds of this objects in the Java language:
Objects that are added to a collection but never taken out of it. If the collection is used to listen for certain events, many such objects slow down the program, without adding anything to it.90 In a concrete example of this problem, instances of an internal class were being kept if a menu bar had been added to it. Why? It came out after a long and fastidiuous search that the hashtable that keeps track of all keystrokes registered for menu shortcuts was holding onto a  reference to the menu, which was holding onto the internal frame, preventing any of these objects from being garbage collected, even after all the references from inside the program were removed. It's surprisingly easy to create this kind of problem. This is rarely the case in C. The memory would have probably been released, leaving a dangling pointer. See the discussion below about the advantages/disadvantages of this approach.
Objects that normally would have a very short life span can be made to last a lot longuer than needed if a long lived object contains a reference to them. For instance classes that are singletons, i.e. objects that are created only once, may hold references to very short lived objects. By the fact of that reference, the short lived object is not garbage collected and it can remain in RAM indefinitely. The solution is, of course, not to forget to remove the references to those objects, what is very tedious and reminds me awfully of the ‘do not forget to call free’ sentence…
Another kind of problem is when an object changes state, but still keeps references to its old state, references that will be definitely cleaned up when the new state is used, but not until then. The objects referenced aren’t going to be garbage collected until the (hopefully cyclic) new state is used.
Objects can be retained because a reference exists from the local scope of the method running, but they aren’t longuer useful to the program. For instance you read a whole table of the database into memory, search for some information, then you process it. When the information you are looking for is already found, you do not need the memory for holding the table, but the table will not be garbage collected because a reference exists from the local scope of your method;

The problem with all this, as you can guess, is that in C at least, you get a GPF, a General Protection Fault when you use a dangling pointer, what is something quite easy to correct and in most cases the debugger will pinpoint exactly to where the problem is. In Java, the only thing that the programmer can do is to ensure that no references to the object exist somewhere, something quite more difficult to do, in my opinion, much more difficult than just keeping track of memory with malloc and free. A dangling pointer that is never used in C is completely harmless. In Java it is the source of a potentially big memory leak.

The conclusion of this short analysis is clear: there is NO silver bullet. No magic, memory management is a hard problem in ANY language. True, a garbage collector can help keep track of memory leaks, but it can create memory leaks of its own. It can be great for some applications, a nightmare for others.

Practical applications of lcc-win32: C as an universal assembler

You can use the lcc-win32 system as it is, i.e. as a C language development system, or you can use it as a ‘back-end’ for another language. Many people/companies have chosen lcc-win32 as a back-end, to implement higher level languages. Myself, I have adapted the well-known ‘F2C’ FORTRAN compiler to be used as a FORTRAN front end for the lcc-win32 system. David Stes has implemented the object-oriented language ‘Objective C’, using lcc-win32 as a back end. Geoff Eldrige has adapted the public domain ‘Small-Eiffel’ system to use lcc-win32 as a back-end.
Besides there are companies like ‘ML4’ in Germany, that have built their languages using C as an universal assembler for their ML4 business language.

What make the idea of using the C language as a universal assembler highly interesting are the following points:
It’s great availability. There is no machine/operating system that doesn’t have a C compiler. The C language has been implemented in 8 bit micro controllers to super computers running enormously expensive hardware. This wide range of hardware where the C language runs makes it an ideal target language.
Stable and fairly well standardized semantics and run time library. There are few surprises when recompiling C source programs with another C compiler.
It is much easier to generate C code than to generate directly assembly.
Portability. The Portable Object Compiler (Objective C) runs in a wide variety of systems and machines, always using the native C compilers available. The Eiffel language has used this approach too. They have proved beyond any reasonable doubt that C can be used as a portable transport medium for higher level languages.
Good performance. C is quite close to the machine, and its abstractions only make for a thin wrapper around the machine instructions. C compilers are known for generating highly efficient machine code.
The lcc-win32 system can be made invisible to the whole system that pilots it. Users do not need to be confronted to the machine code generation phase at all. The whole code generator can be adapted to the specific compilation, for instance to receive input from ‘in-memory’ files, write its output to special files, etc.
Other tools of the system like the resource compiler, the debugger, the IDE, etc, can be adapted to fill the gaps of the higher level language, making the users concentrate in their language rather than spending development effort building all those tools.
The startup code can be modified to start language-specific programs before the ‘main’ procedure is called, for instance code can be run to initialize the static objects in an object oriented language, or to establish error trapping code. The numerical environment where the target program will be run can be modified, for instance to detect overflows, or other special computational situations.
When using lcc-win32 as a back end, you are not limited to the operations of C. You can modify the compiler (or ask the lcc-win32 team to do it for you), and have special semantics for any operation you wish. For instance, if you want to trap overflow in the integer addition operation, you would just have to modify the ‘ADDI’ rules in the win32.md machine description file, to test for overflow, and if an overflow occurred, they would branch into an error handler. This, of course, will make your generated C code non-portable to other compilers.
Appendix 1: Summary of the assembler syntax.
Pseudo-instructions
.align <abs-expr> , <abs-expr>
Pad the location counter to a storage boundary. The first expression is the number of low-order zero bits the location counter must have after advancement. For example .align 3 advances the location counter until it a multiple of 8. If the location counter is already a multiple of 8, no change is needed. The second expression gives the value to be stored in the padding bytes. It (and the comma) may be omitted. If it is omitted, the padding bytes are zero.
.byte <expressions>
.byte expects zero or more expressions, separated by commas. Each expression is assembled into the next byte.
.bss
Sets the current section to the bss section.
.comm <symbol' , <length> 
‘. comm’ declares a named common area in the bss section. The linker will reserve space for it at link time.
.data
.data' tells the assembler to assemble the following statements onto the end of the data section.
.extern <symbol>
This pseudo instruction tells the assembler to declare the given symbol as extern to the module being assembled.
.globl<symbol>
The indicated symbol will be declared as globally visible.
.lcomm<symbol>
This reserves space for a local symbol (not visible by other modules) in the .bss section.
.line<number>
This indicates that the current offset in the text section will be assigned to the program source line given by <number>. This ends up in the debugging information.
.long <number>
Initializes a 4 byte location to the given number.
.text
Sets the current section to the text section.

Syntax
1. Immediate operands are preceded by `$'; (Intel `push 4' is « pushl $4»).
2. Register operands are preceded by `%'.
3. Absolute (as opposed to PC relative) jump/call operands are prefixed by `*'.
4. Intel syntax use the opposite order for source and destination operands. Intel `add eax, 4' is addl $4, %eax.
5. The size of memory operands is determined from the last character of the opcode name. Opcode suffixes of `b', `w', and `l' specify byte (8-bit), word (16-bit), and long (32-bit) memory references. Intel syntax accomplishes this by prefixes memory operands (NOT the opcodes themselves) with `byte ptr', `word ptr', and `dword ptr'. Thus, Intel assembler mov al, byte ptr <foo> is movb <foo>, %al.
Opcode naming
Opcode names are suffixed with one-character modifiers, which specify the size of operands. The letters `b', `w', and `l' specify byte, word, and long operands. If no suffix is specified by an instruction and it contains no memory operands then lcc’s assembler tries to fill in the missing suffix based on the destination register operand (the last one by convention). 

Thus, 
	mov %ax, %bx 
is equivalent to 
	movw %ax, %bx 
also, 
	mov $1, %bx 
is equivalent to 
	movw $1, %bx

Almost all opcodes have the same names than Intel format. There are a few exceptions. The sign extend and zero extend instructions need two sizes to specify them. They need a size to sign/zero extend FROM and a size to zero extend TO. This is accomplished by using two opcode suffixes.

Base names for sign extend and zero extend are `movs...' and `movz...' (`movsx' and `movzx' in Intel syntax). The opcode suffixes are tacked on to this base name, the FROM suffix before the TO suffix. Thus, 
	movsbl %al, %edx
is:
	move sign extend FROM %al TO %edx. 

Possible suffixes, thus, are `bl' (from byte to long), `bw' (from byte to word), and `wl' (from word to long).

Memory references
An Intel syntax indirect memory reference of the form 
<section>:[<base> + <index>*<scale> + <disp>]
  is translated into the syntax
<section>:<disp>(<base>, <index>, <scale>)
where 
<base> and <index> are the optional 32-bit base and index registers, <disp> is the optional displacement, and <scale>, taking the values 1, 2, 4, and 8, multiplies <index> to calculate the address of the operand. 
If no <scale> is specified, <scale> is taken to be 1. <section> specifies the optional section register for the memory operand, and may override the default section register (see a Pentium manual for section register defaults). 
Note that section overrides in MUST have be preceded by a `%'.

Here are some examples of Intel and lcc style memory references:

lcc:	-4(%ebp), 		  Intel:  [ebp - 4]'
<base> is %ebp; <disp> is -4. <section> is missing, and the default section is used (`%ss' for addressing with `%ebp' as the base register). <index>, <scale> are both missing.
lcc:	foo(,%eax,4)	 	Intel: [foo + eax*4]
<index> is `%eax' (scaled by a <scale> 4); <disp> is `foo'. All other fields are missing. The section register here defaults to `%ds'.

lcc:	foo(,1);		Intel [foo]
This uses the value pointed to by foo as a memory operand. Note that <base> and <index> are both missing, but there is only ONE ,. This is a syntactic exception.

lcc:	%gs:foo;		Intel gs:foo
This selects the contents of the variable `foo' with section register <section> being `%gs'.
Absolute (as opposed to PC relative) call and jump operands must be prefixed with `*'. If no `*' is specified, lcc always chooses PC relative addressing for jump/call labels. Any instruction that has a memory operand MUST specify its size (byte, word, or long) with an opcode suffix (`b', `w', or `l', respectively).
Appendix 2 : The mmx intrinsics
Introduction
The objective of this proposal is to provide a high level interface for programmers using lcc-win32 for accessing all new MMX instructions.

The MMX instruction set is accessible through intrinsic functions that are recognized and inlined by the compiler.

The data type used by all MMX intrinsics is an 8 byte union, described in ‘mmx.h’. The interface is designed to work at maximum speed when vectors of this data type are used. The internal loop necessary to apply the given operation to all elements of the data vectors is generated in-line. The dimensions of both arrays should be identical.

Scalar extension is provided, i.e. one of the inputs to the MMX intrinsics can be a scalar, that will be automatically extended by the compiler to apply the mmx operation to all elements of the input vector.

Since the MMX instructions and floating point instructions are incompatible, it is assumed that a function does not mix floating point and mmx. An emms instruction will be issued in the function epilogue if the mmx instruction set is used.

Obviously, the assembler interface is still available, and assembler instructions can be used directly. In this case, it is the programmer’s responsibility to issue the ‘emms’ instruction.

Instruction Syntax
Instructions vary by: 

Data type: packed bytes, packed words, packed double words or quad words
Signed - Unsigned numbers
Wraparound - Saturate arithmetic
Scalar/Vector data
A typical MMX instruction has this syntax: 

Prefix: 
‘_’ to indicate that this is a compiler reserved word.
‘p’ for Packed, as Intel suggests.91
Instruction operation: for example - ADD, CMP, or XOR
Suffix: 
US for Unsigned Saturation 
S for Signed saturation 
B, W, D, Q for the data type: packed byte, packed word, packed double word, or quad word.
‘i’ for ‘immediate’ (scalar) data. If this suffix is not present, the function operates over two arrays.

Description of the interface
Pack with signed saturation
The pack operation operates with words (packed to bytes) or with DWORDs (packed to words).

void _stdcall _packsswb(_mmxdata *array1,_mmxdata *array2,int n);

Description

Each element of array1 will be packed with the corresponding element of array2. The result is written to array1. The number of elements of both arrays is given by ‘n’.

Mode of operation:

while (n-- > 0) {
    array1[n](7..0)   = SaturateSignedWordToSignedByte array1[n](15..0);
    array1[n](15..8)  = SaturateSignedWordToSignedByte array1[n](31..16);
    array1[n](23..16) = SaturateSignedWordToSignedByte array1[n](47..32);
    array1[n](31..24) = SaturateSignedWordToSignedByte array1[n](63..48);
    array1[n](39..32) = SaturateSignedWordToSignedByte array2[n](15..0);
    array1[n](47..40) = SaturateSignedWordToSignedByte array2[n](31..16);
    array1[n](55..48) = SaturateSignedWordToSignedByte array2[n](47..32);
    array1[n](63..56) = SaturateSignedWordToSignedByte array2[n](63..48);
}

void _stdcall _packsswbi(_mmxdata *array,_mmxdata *imm,int n);

Description

Each element of array1 will be packed with imm. The result is written to array1. The number of elements of array1 is given by ‘n’.

Mode of operation:


while (n-- > 0) {
    array[n](7..0)   = SaturateSignedWordToSignedByte array[n](15..0);
    array[n](15..8)  = SaturateSignedWordToSignedByte array[n](31..16);
    array[n](23..16) = SaturateSignedWordToSignedByte array[n](47..32);
    array[n](31..24) = SaturateSignedWordToSignedByte array[n](63..48);
    array[n](39..32) = SaturateSignedWordToSignedByte imm(15..0);
    array[n](47..40) = SaturateSignedWordToSignedByte imm[n](31..16);
    array[n](55..48) = SaturateSignedWordToSignedByte imm[n](47..32);
    array[n](63..56) = SaturateSignedWordToSignedByte imm[n](63..48);
}


void _stdcall _packssdw(_mmxdata *array1,_mmxdata *array2,int n);

Description

Each element of array1 will be packed with the corresponding element of array2. The result is written to array1. The number of elements of both arrays is given by ‘n’.

Mode of operation:


while (n-- > 0) {
    array1[n](15..0)  = SaturateSignedDwordToSignedWord array1[n](31..0);
    array1[n](31..16) = SaturateSignedDwordToSignedWord array1[n](63..32);
    array1[n](47..32) = SaturateSignedDwordToSignedWord array2[n](31..0);
    array1[n](63..48) = SaturateSignedDwordToSignedWord array2[n](63..32);
}

void _stdcall _packssdwi(_mmxdata *array,_mmxdata *imm,int n);

Description

Each element of array1 will be packed with the corresponding element of array2. The result is written to array1. The number of elements of both arrays is given by ‘n’.

Mode of operation:


while (n-- > 0) {
    array1[n](15..0)  = SaturateSignedDwordToSignedWord array1[n](31..0);
    array1[n](31..16) = SaturateSignedDwordToSignedWord array1[n](63..32);
    array1[n](47..32) = SaturateSignedDwordToSignedWord imm(31..0);
    array1[n](63..48) = SaturateSignedDwordToSignedWord imm(63..32);
}
Pack with unsigned saturation
void _stdcall _packuswb(_mmxdata *array1,_mmxdata *array2,int n);
Description

Each element of array1 will be packed with the corresponding element of array2. The result is written to array1. The number of elements of both arrays is given by ‘n’.

Mode of operation:




while (n-- > 0) {
    array1[n](7..0)   = SaturateSignedWordToUnsignedByte array1[n](15..0);
    array1[n](15..8)  = SaturateSignedWordToUnsignedByte array1[n](31..15);
    array1[n](23..16) = SaturateSignedWordToUnsignedByte array1[n](47..32);
    array1[n](31..24) = SaturateSignedWordToUnsignedByte array1[n](63..48);
    array1[n](39..32) = SaturateSignedWordToUnsignedByte array2[n](15..0);
    array1[n](47..40) = SaturateSignedWordToUnsignedByte array2[n](31..16);
    array1[n](55..48) = SaturateSignedWordToUnsignedByte array2[n](47..32);
    array1[n](63..56) = SaturateSignedWordToUnsignedByte array2[n](63..48);
}

void _stdcall _packuswbi(_mmxdata *array,_mmxdata *imm,int n);
Description

Each element of array1 will be packed with imm. The result is written to array1. The number of elements of array is given by ‘n’.

Mode of operation:


while (n-- > 0) {
    array[n](7..0)   = SaturateSignedWordToUnsignedByte array[n](15..0);
    array[n](15..8)  = SaturateSignedWordToUnsignedByte array[n](31..15);
    array[n](23..16) = SaturateSignedWordToUnsignedByte array[n](47..32);
    array[n](31..24) = SaturateSignedWordToUnsignedByte array[n](63..48);
    array[n](39..32) = SaturateSignedWordToUnsignedByte imm[n](15..0);
    array[n](47..40) = SaturateSignedWordToUnsignedByte imm[n](31..16);
    array[n](55..48) = SaturateSignedWordToUnsignedByte imm[n](47..32);
    array[n](63..56) = SaturateSignedWordToUnsignedByte imm[n](63..48);
}
Packed Add
Packed add byte
void _stdcall _paddb(_mmxdata *array1,_mmxdata *array2,int n);
Description

Each element of array1 will be added with each corresponding element of array2. The result is written to array1. The number of elements of both arrays is given by ‘n’.

Mode of operation:


while (n-- > 0) {
    array1[n](7..0)   = array1[n](7..0) + array2[n](7..0);
    array1[n](15..8)  = array1[n](15..8) + array2[n](15..8);
    array1[n](23..16) = array1[n](23..16)+ array2[n](23..16);
    array1[n](31..24) = array1[n](31..24) + array2[n](31..24);
    array1[n](39..32) = array1[n](39..32) + array2[n](39..32);
    array1[n](47..40) = array1[n](47..40)+ array2[n](47..40);
    array1[n](55..48) = array1[n](55..48) + array2[n](55..48);
    array1[n](63..56) = array1[n](63..56) + array2[n](63..56);
}
void _stdcall _paddbi(_mmxdata *array1,_mmxdata *imm,int n);
Description

Each element of array1 will be added with imm. The result is written to array1. The number of elements of array is given by ‘n’.

Mode of operation:


while (n-- > 0) {
    array[n](7..0)  =  array[n](7..0)   + imm[n](7..0);
    array[n](15..8) =  array[n](15..8)  + imm[n](15..8);
    array[n](23..16) = array[n](23..16) + imm[n](23..16);
    array[n](31..24) = array[n](31..24) + imm[n](31..24);
    array[n](39..32) = array[n](39..32) + imm[n](39..32);
    array[n](47..40) = array[n](47..40) + imm[n](47..40);
    array[n](55..48) = array[n](55..48) + imm[n](55..48);
    array[n](63..56) = array[n](63..56) + imm[n](63..56);
}

Packed add word
void _stdcall _paddw(_mmxdata *array1,_mmxdata *array2,int n);
Description

Each element of array1 will be added with each corresponding element of array2. The result is written to array1. The number of elements of both arrays is given by ‘n’.

Mode of operation:


while (n-- > 0) {
    array1[n](15..0)<--array1[n](15..0) + array2[n](15..0);
    array1[n](31..16)<--array1[n](31..16) + array2[n](31..16);
    array1[n](47..32)<--array1[n](47..32) + array2[n](47..32);
    array1[n](63..48)<--array1[n](63..48) + array2[n](63..48);
}

void _stdcall _paddwi(_mmxdata *array1,_mmxdata *imm,int n);
Description

Each element of array1 will be added with imm. The result is written to array1. The number of elements of array is given by ‘n’.

Mode of operation:


while (n-- > 0) {
    array[n](15..0)<--array[n](15..0) + imm(15..0);
    array[n](31..16)<--array[n](31..16) + imm(31..16);
    array[n](47..32)<--array[n](47..32) + imm(47..32);
    array[n](63..48)<--array[n](63..48) + imm[n](63..48);
}

Packed add double word
void _stdcall _paddd(_mmxdata *array1,_mmxdata *array2,int n);
Description

Each element of array1 will be added with each corresponding element of array2. The result is written to array1. The number of elements of both arrays is given by ‘n’.

Mode of operation:


while (n-- > 0) {
    array1[n](31..0)<--array1[n](31..0) + array1[n](31..0);
    array1[n](63..32)<--array1[n](63..32) + array1[n](63..32);
}

void _stdcall _padddi(_mmxdata *array,_mmxdata *imm,int n);

Each element of array1 will be added with imm. The result is written to array1. The number of elements of array is given by ‘n’.

Mode of operation:


while (n-- > 0) {
    array[n](31..0)<--array1[n](31..0) + imm(31..0);
    array[n](63..32)<--array1[n](63..32) + imm(63..32);
}

Packed Add with saturation
Packed add byte with saturation
a) Signed variants
void _stdcall _paddsb(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _paddsbi(_mmxdata *array1,_mmxdata *array2,int n);
b) Unsigned variant
void _stdcall _paddusb(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _paddusbi(_mmxdata *array1,_mmxdata *array2,int n);
Description

Each element of array1 will be added with each corresponding element of array2. The result is written to array1. The number of elements of both arrays is given by ‘n’. 
For the signed operation, if the result of the add is saturated to 0x7f or to 0x80 in case of overflow/underflow respectively.
For the unsigned operation, the saturation values are 0xFF and 0x00 in case of overflow/underflow.

Packed add word with saturation
void _stdcall _paddsw(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _paddswi(_mmxdata *array1,_mmxdata *imm,int n);
Description

Same operation as in paddsb above. The saturation values are 0x7FFF and 0x8000 for the signed operation, and 0xFFFF and 0x00 for signed / unsigned operations.

Packed And.
void _stdcall _pand(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _pandi(_mmxdata *array1,_mmxdata *imm,int n);
The bitwise logical AND operation is done between each 64 bit element of the arrays. The result is written to the array1.

Packed And. Not
void _stdcall _pandn(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _pandni(_mmxdata *array1,_mmxdata *imm,int n);

First a bitwise logical NOT on the 64 bits of each element is performed, inverting each bit of the source operand(array2). Then, the bitwise logical AND operation is done between each 64 bit element of the arrays. The result is written to the array1.
Packed compare for equal
The pcmeq instruction compares the data elements of the second argument with those of the first. If they are equal the corresponding element of the first argument becomes one, if they are not, the element becomes zero.
Example (for word comparison)



pcmeqb
Byte comparison
void _stdcall _pcmpeqb(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _pcmeqbi(_mmxdata *array1,_mmxdata *imm,int n);
pcmeqw
Word comparison (16 bits)
void _stdcall _pcmpeqw(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _pcmpeqwi(_mmxdata *array1,_mmxdata *imm,int n);
pcmeqd
double word (32 bits) comparison
void _stdcall _pcmpeqd(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _pcmpeqdi(_mmxdata *array1,_mmxdata *imm,int n);

Packed compare for greater than
pcmgtb
void _stdcall _pcmpgtb(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _pcmpgtbi(_mmxdata *array1,_mmxdata *imm,int n);
pcmgtw
void _stdcall _pcmpgtw(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _pcmpgtwi(_mmxdata *array1,_mmxdata *imm,int n);
pcmgtd
void _stdcall _pcmpgtd(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _pcmpgtdi(_mmxdata *array1,_mmxdata *imm,int n);

Packed multiply and add
void _stdcall _pmaddwd(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _pmaddwdi(_mmxdata *array1,_mmxdata *imm,int n);



Packed multiply high
For each vector element this instruction multiplies the four signed words of the destination operand with the four signed words of the source operand. The high order 16 bits of the 32-bit intermediate results are written to the destination operand.



void _stdcall _pmulhw(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _pmulhwi(_mmxdata *array1,_mmxdata *array2,int n);

Packed multiply low
For each vector element of 64 bits this instruction multiplies the four signed words of the destination operand with the four signed words of the source operand. The low order 16 bits of the 32 bit intermediate result are written to the destination vector element.



void _stdcall _pmullw(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _pmullwi(_mmxdata *array1,_mmxdata *imm,int n);
Packed or
This instruction performs the bitwise logical or of the two given vectors.
void _stdcall _por(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _pori(_mmxdata *array1,_mmxdata *array2,int n);

Packed shift left logical
This instruction shifts the bits of each element of the first operand to the left by the amount specified by the corresponding element of the second operand. The result of the operation is written to the destination vector.
void _stdcall _psllw(_mmxdata *array1,_mmxdata *imm,int n);
void _stdcall _psllwi(_mmxdata *array,unsigned char int8,int n);
void _stdcall _pslld(_mmxdata *array,_mmxdata *imm,int n);
void _stdcall _pslldi(_mmxdata *array,unsigned char int8,int n);
void _stdcall _psllq(_mmxdata *array,_mmxdata *imm,int n);
void _stdcall _psllqi(_mmxdata *array,unsigned char int8,int n);

Packed shift right arithmetic
This instruction shifts the bits of each element of the first operand to the right by the amount specified by the corresponding element of the second operand. The result of the operation is written to the destination vector.
void _stdcall _psrlw(_mmxdata *array,_mmxdata *imm,int n);
void _stdcall _psrlwi(_mmxdata *array,unsigned char int8,int n);
void _stdcall _psrld(_mmxdata *array,_mmxdata *imm,int n);
void _stdcall _psrldi(_mmxdata *array,unsigned char int8,int n);
void _stdcall _psrlq(_mmxdata *array,_mmxdata *imm,int n);
void _stdcall _psrlqi(_mmxdata *array,unsigned char int8,int n);

Packed Substract
This instructions are very similar to the corresponding ‘add’ routines.
void _stdcall _psubb(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _psubbi(_mmxdata *array1,_mmxdata *imm,int n);
void _stdcall _psubw(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _psubwi(_mmxdata *array1,_mmxdata *imm,int n);
void _stdcall _psubd(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _psubdi(_mmxdata *array1,_mmxdata *imm,int n);
void _stdcall _psubsb(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _psubsbi(_mmxdata *array1,_mmxdata *imm,int n);
void _stdcall _psubsw(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _psubswi(_mmxdata *array1,_mmxdata *imm,int n);
void _stdcall _psubsb(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _psubsbi(_mmxdata *array1,_mmxdata *imm,int n);
void _stdcall _psubsw(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _psubswi(_mmxdata *array1,_mmxdata *imm,int n);
void _stdcall _psubusb(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _psubusbi(_mmxdata *array1,_mmxdata *imm,int n);
void _stdcall _psubusw(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _psubuswi(_mmxdata *array1,_mmxdata *imm,int n);

Unpack high packed data
This instruction unpacks and interleaves the high-order data elements of each element of the array1 and 2.

void _stdcall _punpckhbw(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _punpckhbwi(_mmxdata *array1,_mmxdata *imm,int n);
void _stdcall _punpckhwd(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _punpckhwdi(_mmxdata *array1,_mmxdata *imm,int n);
void _stdcall _punpckhdq(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _punpckhdqi(_mmxdata *array1,_mmxdata *imm,int n);

Unpack low packed data
This instruction unpacks and interleaves the low-order data elements of the destination and source operands into the destination operand.

void _stdcall _punpcklbw(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _punpcklbwi(_mmxdata *array1,_mmxdata *imm,int n);
void _stdcall _punpcklwd(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _punpcklwdi(_mmxdata *array1,_mmxdata *imm,int n);
void _stdcall _punpckldq(_mmxdata *array1,_mmxdata *array2,int n);
void _stdcall _punpckldqi(_mmxdata *array1,_mmxdata *imm,int n);

Pxor
This instruction performs a logical exclusive or operation for all bits of the source and destination vectors.
void _stdcall _pxor(_mmxdata *array1,_mmxdata *array2,int n);

The problem with the mmx instructions
All this instructions mentioned above, have several caveats that you should be aware of: 
Since these new registers are just aliases for the floating-point registers, they can’t be used together. Moreover, at each transition from the MMX-state to the normal state, you have to add an EMMS instruction. This instruction can be quite expensive, so it should be used with care.
All this instructions do not set any flags. This means that making tests based on the results of comparisons for instance is quite awkward. You have to move the results or part of the results to the integer unit then test again the data to set the flags register accordingly.
When transferring data from an integer register to a mmx register, the upper 32 bits of the mmx register are cleared to zero. This means that it is necessary to use two mmx registers to transfer 64 bits to the mmx unit. There isn’t the possibility of just loading the two halves into the same mmx register.
There is no provision for transferring the 64 bits of each mmx register into a destination register pair. This means that data transfers use much more registers than would be necessary. In a register-starved architecture as the x86 series, this means surely trouble.
For the compiler the problem is even more complex. I have tried many times to use the MMX registers as a store for local variables, but it has been impossible. What is an MMX register? It is not an address, since many operations that are possible with addresses are not possible with MMX registers, like, for instance, adding a number to it. It is not a register either since they can’t do indexed addressing (i.e. that can’t be used as pointers). They are 64 bits wide but can be loaded from other registers 32 bits at a time. The necessity of emitting an emms instruction makes their use even harder. It is not a surprise then, that no compiler offers real support for MMX instructions several years after their initial implementation.
Appendix 3: Overview of the machine description and the rules
This table is not complete. I give here more explanations about the rules making the machine description. You should read the chapters concerning the intermediate language and the machine description first.

Op
Arguments
Assembler
Result
Description
Addition
ADDI
reg
memory,reg,constant
movl %0,%c
addl %1,%c
reg
32 bit add from reg to memory, register or constant
ADDD
ADDF
0: freg
1:flt
fadd %1
freg
Adds top of stack to memory address
Pointer addition
ADDP
ADDI(
       LSHI(reg,icon), reg),
        acon)
leal %3(%2,%0,%1),%c
reg
Add two registers and an immediate constant with one instruction. “icon” can be 1,2,4,or 8. There are many other variations of this rule for the different arguments order.

reg,
ADDP(reg,acon)
leal %2(%0,%1),%c



reg
ADDP(acon,reg)
leal
%1(%0,%2),%c


Assignment
ASGNC
0: address
1:register or constant
movb %1,%0
void
Moves a register or an immediate byte constant to the given address
ASGNI
ASGNP
0: address
1: register or constant
movl %1,%0
void
Moves a 32 bit integer or immediate constant to the specified address.
ASGNI
0: address
1: ADDI(mem32,rc)
addl %2,%0
void
This executes an operation directly between a memory location and an immediate constant or a register. The argument %2 is the register/constant value, and %0 is the address. Note that this is valid only if address is the same as mem32. The function incrmem() will verify this.

0: address
1: ADDU(mem32,rc)




0: address
1: SUBI(mem32,rc)
subl %2,%0



0: address
1: SUBU(mem32,rc)




0: address
1: BANDU(mem32,rc)
andl %2,%0



0: address
1: BORU(mem32,rc)
orl %2,%0



0: address
1: LSHI(mem32,con)
sall %2,%0



0: address
1: LSHU(mem32,rc)
shll %2,%0



0: address
1: RSHI(mem32,rc)
sarl %2,%0



0: address
1: RSHU(mem32,rc)
shrl %2,%0


ASGNS
0: address
1: 16 bit register or constant
movw %1,%0
void
Moves a 16 bit register or immediate constant to the specified address
ASGNB
0: register
1: INDIRB(reg)
movl $%a,%ecx
rep movsb
void
Moves a block of data. Count will be written to ecx, supposes address of source is in ESI, destination in EDI.
ASGNB
0: register
1: INDIRB(LOADP(addr))
leal %1,%%esi
movl $%a,%ecx
rep movsb
void
Moves a block of data. Argum?ents are the source address that is loaded into esi, and the size in symb[0]
ASGND
0: addr
1: freg
fstpl %0
void
Moves top of floating point stack to a 64 bit memory location
Argument pushing
ARGI
ARGP
0: memory, register, constant or  address
pushl %0
void
Pushes an argument to a function.
ARGB
0: INDIRB(reg)
subl $%a,%esp
movl %%esp,%%edi
movl $%b,%ecx
rep movsb
void
Pushes a structure as values into the stack. Note that this could leave the stack unaligned. Code in the compiler should watch for this.
ARGF
CVDF(freg)
subl $4,%esp
fstps (%esp)
void

CALLI

address

call %0
reg
Call void or _stdcall function


call %0
addl %a,%esp
reg
Call function and adjust the stack.
CALLD

address 

call %0
addl %a,%esp
freg
Calls a procedure that returns a floating point number in the stack top. Adjust the stack after the call.


call %0
freg
Calls a procedure that returns a double result without adjusting the stack


call %0
fstp st(0)
freg
Call a procedure that returns a double, but cleanup the FPU stack afterwards because the result is not used in the calling code.


call %0
fstp st(0)
addl %a,%esp
freg
Same as above but adjust the stack to account for the function arguments.
XOR
BXORU
reg
mrc
movl %0,%c
xorl %1,%c
reg
XOR 32 bits
Conversions of floating point or 64 bit data
CVFD
INDIRF(addr)
s %0
freg
Conversion from 32 bit to 80 bit internal pointer in st(0)
CVDF
freg
sub $4,%esp
fstps (%esp)
flds (%esp)
addl  $4,%esp
freg
Conversion from 64 bit precision to 32 bit precision. This goes through memory.
CVDF
CVID(mrc)
push %0
fildl (%esp)
addl $4,%esp
freg
Conversion from 32 bit integer to 32 bit float.
CVDI
freg
movl %eax,%c
.extern __ftol
call __ftol
xchgl %eax,%c
reg
Conversion from floating point stack top into integer using intrinsic function. Note that eax is saved into the register that will hold the result, then the function call is done, then eax is restored. This is to avoid clobbering the contents of eax. The register where the result should appear is represented by %c (sym[2])
CVID
mem32
fildl %0
freg
Load 32 bit number from memory location into the stack top.
CVID
reg
pushl %0
fildl (%esp)
addl $4,%esp
freg
Convert 32 bit integer in a register into floating point number in the stack top
CVIUL
rc
movl %0,%%eax
xorl %edx,%edx
rpair
Transform a 32 bit unsigned into a 64 bit integer with zero extend.
CVIL
mem32
movl %0,%eax
cdq
rpair
Conversion of a signed 32 bit integer into a 64 bit one with sign  extend.
CVIL
mem32
movl %0,%eax
cdq
push %edx
push %eax
argl
Convert a 32 bit signed integer into a 64 bit one with sign extend.
CVUD




CVUD
mem32



reg
push $0
push %0
fildq (%esp)
addl $8,%esp
freg
Conversion of 32 bit unsigned number into floating point number in stack top. A 64 bit load is generated. The high part of the 64 bit integer pushed in the stack is zero. The rule is the same when the argument is in a register.
Character conversions
CVCI
INDIRC(addr)
movsbl %0,%c
reg
Sign extend the character at the given address into a register.
CVCI
CVIC(mem32)
movsbl %0,%c
reg
Avoid redundant conversions: from integer to character, then from character to integer.. This rules is useful with the C code:
int a,b;
a = (char)b;
CVCU
INDIRC(addr)
movzbl %0,%c
reg
Extend the character at the given address into a register without sign extension
16 bit integers conversions
CVSI
INDIRS(addr)
movswl %0,%c
reg
Sign extend the 16 bit integer at the given address into a 32 bit register. The result is left in %c (sym[2])
CVSU
INDIRS(addr)
movzwl %0,%c
reg
Extend 16 bit integer in memory to a 32 bit register without sign extension.
Division
DIVI
reg,
reg
cdq
idivl %1
reg
Signed division
DIVU
reg
reg
xorl %edx,%edx
divl %1
reg
Unsigned division
DIVD
DIVF
freg
memf
fdiv%1
freg
64 bit floating point division.
DIVD
memf
freg
fdivr%0
freg
64 bit floating point division
DIVD
DIVF
freg
freg
fdivrp%0st,st(1)
freg
64 bit floating point division with both arguments in the FPU stack
DIVL
mem64
rpair
pushl %edx
pushl %%eax
leal %0,%eax
pushl 4(%eax)
pushl (%eax)
call __alldiv
rpair

64 bit signed division. The two 64 bit integers are pushed as arguments to the intrinsic function __alldiv.

rpair
mem64
leal %1,%ecx
pushl 4(%ecx)
pushl (%ecx)
pushl %edx
pushl %eax
call __alldiv


DIVL
argl
mem64
popl %eax
popl %edx
leal %1,%ecx
pushl 4(%ecx)
pushl (%ecx)
push %edx
pushl %eax
call __alldiv
rpair
64 bit division. Must inverse the order of the arguments
DIVL
argl
argl
call __alldiv
rpair
64 bit division. The two 64 bit integers are already in the stack.
DIVL
mem64
mem64
leal %1,%ecx
pushl 4(%ecx)
pushl (%ecx)
leal %0,%ecx
pushl 4(%ecx)
pushl (%ecx)
call __alldiv
rpair
64 bit division of two memory locations.
Equals instruction
EQI
mem
rc
cmpl %1,%0
je %a
void
Compare 32 bits between a register or an immediate constant to memory
EQD
cmpf
freg
fcomp%0
fstsw %ax
sahf
je %a
void
Compare memory with FPU stack, then store the FPU flags in ax, then store ah into the  eflags register. Use that to jump or not.
EQD
freg
CVID(INDIRI(addr))
ficompl %1
fstsw %ax
sahf
je %a
void
Compare 32 bit memory integer with the top of FPU stack without any conversions. Then use the flags as in the other floating point instructions.
EQD
freg
freg
fucompip st(1)
fstp st(0)
je %a
void
New P6 instruction avoids the mess with the flags above. Note that both operands must be in the FPU stack, hence the freg,freg condition.
EQLO
rpair
mem64
leal %1,%ecx
cmpl edx,4(%ecx)
jne %l
cmpl eax,(%ecx)
je %a
%L:
void
Comparison of two 64 bit numbers, one in the register pair EDX:EAX, the other in memory. Note the label %L. Two integers comparisons are done.
Fetch data from memory
INDIRD
INDIRF
address
l %0
s %0
freg
This rule will expand to either fldl or flds, to load either 64 or 32 bits.
Division
DIVD
freg
memf
div%1
freg
Floating point divide stack top by memory location 
DIVD
memf
freg
fdivr %0
freg
Floating point divide memory location by stack top
DIVD
freg
freg
fdivrp st,st(1)
freg
Divide stack top by st(1)
DIVF
freg
freg
fdivrp st,st(1)
freg
Divide stack top by 32 bit memory location
DIVF
freg
memf
fdiv%1
freg
Divide stack top by 32 bit float in memory location
LOADC
reg
movb %0,%c
reg
8 bit load
LOADS
reg
movw %0,%c
reg
16 bit load
LOADI
reg
movl %0,%c
reg
32 bit load
LOADP
address



Multiplication
MULD
freg
flt
fmul%1
freg
multiply stack top by 64 bit memory location
MULF
freg
flt
fmul%1
freg
Multiply stack top by 32 bit float
Negation
NEGD
NEGF
freg
fchs
freg
Change sign of floating point stack top
Return statement
RETI
CVLI(argl)
pop %eax
addl $4,%esp
lretstmt
Transform a 64 bit temporary in the stack into a normal integer return in EAX.
RETI
LOADI(reg)
? movl %0,%eax
stmt
Load into EAX the result value in another register.

LOADP(reg)



RETI
ADDI(reg,acon)
leal %1(%0),%eax

Set return value with a constant addition.
RETL
argl
popl %eax
popl %edx
lretstmt
Transform a 64 bit temporary in the stack into a 64 bit register value in EDX:EAX.
RETL
freg
call __ftoll
lretstmt
Transform a floating point number in the FPU to a 64 bit integer in EDX:EAX
Shift right
RSHI
reg
rc5
movl %0,%c
sarl %1,%c
reg
Shift right signed
RSHU
reg
rc5
movl %0,%c
shrl %1,%c
reg
Shift right unsigned
Subtraction
SUBD
freg
memf
fsub%1
freg
Substract memf from stack top
SUBD
freg
memf
fsub%1
freg
Substract stack top from memf
SUBD
freg
freg
fsubr st,st(1)
freg
Substract st(1) from stack top
SUBD
memf
freg
fsubr%0
freg
Substract floating point number in memory from stack top
SUBF
freg
memf
fsub%1
freg


Epilogue

The circuit was connected to carbon-nitrogen hardware. There were millions of those, connected in a place they called Paris.

There were a lot of cables, to drive the hardware. Recently, one of those was damaged, because the main connector of the circuit’s central unit to the upper actuators was strained after 49 years of use. The central unit perceived that the muscles of its arm were somehow "sleeping", a weird sensation. The doctor said that those symptoms in the neck were natural after all this time. Planned obsolescence was nothing new. Circuits were born to be thrown away. Only some of the developed software survived, copied into the next generation.

The room was quiet.

Recently, the circuit of the space telescope sent a photograph to its builders: Hubble Deep Field was called that image.

And it showed something that seemed to go on forever. The farther that the telescope could see, the more galaxies that appeared in an incredible view. 

This, coupled with the recent planet discoveries in many nearby stars, led to a confirmation that software could very well be the rule, and not the exception. No, software didn’t start only here on this small planet. Software must be all over the place, all over the place. Running under different hardware surely, but still the same thing: a stored program with associated read/write machinery that implements the instructions written in it.

Nothing moved.

The circuit was only different from the other species of circuits that populated the surface of the small planet in the knowledge it had. Knowledge of the end of its destiny, knowledge of how to write circuits, knowledge about the code it was written in.

And it dreamed.

If a circuit gains knowledge about its own code, and is able to modify the bugs in it, is able to write new instructions into its own code, can that circuit at last be considered free?

Isn’t that the very essence of freedom? The freedom to write yourself as you consider right, the freedom to change your own program as you want, the freedom to live millennia if you wish so, or a just a second if you wish so. The freedom to write new input processors, different actuators, to shape the internal and external essence of the circuit without any limits other than what code can express.

And not even that. Software knows no limits.

The cables in its neck were damaged because a cushioning tissue wasn’t being produced as it should. Probably it was the clock that sent some signals to that part of the maintenance system. Or maybe it was just the planned obsolescence. But recently, that part of the circuit’s code was coming into light, as many others. The precise location in the instruction set where the maintenance system was controlled came into closer scrutiny. Even the clock, that elusive master of time, had started to reveal its secrets to the unending curiosity of the circuits that wanted to know, know how to read their own code at last, after all those billion years of waiting.

The circuit knew that this was happening. 

Recently, a new meta-circuit came up, connecting many others circuits across all continents with nerves running under the oceans and in fixed points of space. Software means interconnections, and this big circuit was just a normal evolutionary step, as were all other steps before.

This circuit connected to it, and tried to add its own insignificant contribution. That’s all.

INDEX

#ifdef (displaying in wedit), 185
__func__, 52
accelerators, 142
ADD (vm operation), 30
ADDRF (vm operation), 30
ADDRG (vm operation), 30
ADDRL (vm operation), 30
alloc.c, 62
AllocDialogResource, 151
analysis.c, 20, 30, 62, 91
AnalyzeFn, 178
apilist.dll, 194
apilist.txt, 194
APL, 155
ARG (vm operation), 29
ASGN (vm operation), 29
AskPrjFiles, 191
asm.c, 20, 63
Asm386Instruction, 66
autosaving, 159
BAND (vm operation), 30
banner.c, 226
basic block, 77
BCOM (vm operation), 30
bind.c, 62
bineditor.c, 226
block move (improving), 81
bookmark.c, 226
BOR (vm operation), 30
breakpoints (conditional), 216
breakpoints (data), 210
breakpoints (kinds of), 206
browse file format, 55
browsegen, 53
bsf, 100
bsr, 100
bswap, 99
bug (in lburg rules), 27
bugs (analyzing), 232
bugs (classifying), 238
bugs (correcting), 238
bugs (general), 229
bugs (introducing them), 236
BuildEdataSection, 117
BXOR (vm operation), 30
c++, 102, 107
C99, 101
CalculateMetrics, 178
CALL (vm operation), 30
call instruction, 16
calling convention, 38
carry, 99
cdiff.c, 226
ChangeKeywordsDlg, 161, 190
CheckFunctionNameChange, 167
ChooseProjectFiles, 190
Chris Fraser, 23, 34, 77, 85
clobbering, 82
cmscore.c, 226
CmsPreferencesDlg, 190
CNST (vm operation), 29
COFF symbol table, 121
com.c, 109
command.c, 226
comments (displaying in editor), 160
common.c, 109
CompilerDlg, 190
complexity, 107
config.c, 226
configuration wizard, 189
console application, 195
const, 92
constant, 91
constant (dividing by), 91
constant folding, 90
constants (eliminating), 79
controls.c, 226
copyright.c, 226
crash (debugging), 213
crash (recovering from), 213
CreateTestDialog, 151
cross loads, 78
crtdll.dll, 200
cse, 89
cv.c, 62
CVC (vm operation), 29
CVD (vm operation), 29
CVI (vm operation), 29
CVL (vm operation), 30
cvpack, 110
CVS (vm operation), 29
cvtres, 116
CVU (vm operation), 30
CVULL (vm operation), 30
dag.c, 62, 89
dangling pointer, 171
Dave Hanson, 23, 34, 77, 85, 120
dbgdisplay.c, 226
dbginfo.c, 226
dbgintf.c, 226
dbgtypes.c, 226
debug information, 72
debug levels, 58
debug.c, 109, 226
debugger evaluation, 214
DebuggerSettingsDlg, 190
debugging (optimizer), 83
debugging (preparing for), 199
decl.c, 62, 95
declspec, 40
def files, 116
Dennis Ritchie, 22, 63
dialog, 137, 195
dialog (testing in editor), 151
dialog.c, 170, 190, 226
dialogs, 170
disasm.c, 109, 227
DIV (vm operation), 30
dlg files, 152
dlgio.c, 149, 152
dll, 22, 195, 200
dll exports, 116
dos stub, 111
DrawOneLine, 167
DrawProgramText, 161
DrawSelectedRegion, 168
drawtree.c, 227
DumpExeCodeViewInfo, 76
edit1.c, 227
edit2.c, 193
edit3.c, 166, 227
edit4.c, 160, 227
edit5.c, 161, 225, 227
edit6.c, 160, 161, 186, 227
EditInfo, 190
EditMacroDlg, 190
EiffelConfigDlgProc, 190
eiffeldbg, 227
elf.c, 109
emitasm, 34, 35
enode.c, 62, 95
EQ (vm operation), 30
error.c, 62
escape instruction, 34
executable file header, 112
executable optional header, 112
executable sections, 114
exedump.c, 109
expr.c, 62
fcos, 99
fileio.c, 227
FileList (variable), 191
filestoolbar.c, 227
FillBuildResults, 193
FindCComments, 161
FindStrings, 185
fistp, 99
fldl2e, 99
fldlg2, 99
fldln2, 99
fldpi, 99
floating point performance, 89
FortranConfigDlgProc, 190
front-end, 20
fsin, 99
fsincos, 99
function prologue, 17, 60
function tree, 178
garbage collector, 241
gcc, 98
GE (vm operation), 30
gen.c, 31, 62
genasm, 23
gencode, 88
genhlp.c, 227
GetLastError display, 209
GetListboxCount, 171
globals.c, 227
gnu, 48, 96, 197
GREP, 183
grep.c, 227
GT (vm operation), 30
Halstead, 177
HandleDeafultMessages, 170
HandleKeyDown, 225
HandlePrjTreeCommand, 189
HandleShowStringsCommand, 185
HandleWmChar, 166, 225
history (of visited functions), 180
import, 46
ImportClipboard, 168
imports table (reading), 200
ind.c, 227
init.c, 63, 95
inlining, 81
input.c, 63
instruction binary format, 65
instruction set, 16
instructions patterns, 78
intermediate registers (eliminating), 79
intrin.c, 63
intrinsics, 98
IsKeyword, 161
java, 101
JUMP (vm operation), 30
LABEL (vm operation), 30
lburg, 23, 29, 90
lburg rules, 24, 85
lcclib, 145
lcclnk.c, 117
LE (vm operation), 30
lex.c, 62
lil files, 95
line numbers, 122
LineInsertChar, 166
LinkerSettingsDlg, 190
linking (building export table), 117
list.c, 63
listnodes, 23, 61
LOAD (vm operation), 30
long long, 56
LSH (vm operation), 30
LT (vm operation), 30
machine description file, 24
main.c, 63
mainCRTStartup, 43
make.c, 192, 227
Matt Pietreck, 109
MDI, 195
memory management, 241
menus.c, 227
message tables, 142
metrics.c, 178, 227
mmx, 248, 259
MOD (vm operation), 30
Montgomery, Peter L, 91
MoveCaret, 167
msg.c, 63
msvc, 109, 110, 162
MUL (vm operation), 30
namespaces, 105
nb09, 52
NB09, 72
ncpp.c, 63
NE (vm operation), 30
NEG (vm operation), 30
Nelson Beebe, 48
new instructions, 80
NewPrjDlg, 156
objdump.c, 109
object file (cross referencing), 180
object file (identifying), 179
object files, 68
objective-c, 244
objxref.c, 227
operator redefinition, 101
operators.c, 101
optim.c, 20, 63
optimize.c, 83
output.c, 63, 83
outputwnd.c, 228
parse tree, 23
pe executable format, 111
pedump, 75, 109, 185
pedump.c, 109
peephole optimizer rules, 77
pragmas, 42
pre-processor, 20, 51, 61
preprocessor bugs, 240
prjoutline.c, 189, 228
prof.c, 62
profile.c, 228
profio.c, 62
program loader, 19
projects.ini, 188
ralloc, 31
rc files, 22, 153
rdtsc, 99
ReDraw, 167
regexp.c, 228
register allocation, 30, 87
register allocator, 20, 31, 90
register usage, 87
relocation, 67
relocations, 69, 121, 122, 123
reporting bugs, 240
res files, 152
resdump.c, 109
resource compiler, 20, 135
RET (vm operation), 30
rint, 100
RSH (vm operation), 30
Save (function), 152
SaveClipboard, 168
search.c, 228
seh.c, 62
SendToOptimizer, 83
SetRegisterMasks, 30
SetupRegisterVariables, 30
SetWinHelpDlg, 190
shadow stack, 58
ShowStringsDlg, 185
signal function, 214
simp.c, 62
single step, 201, 207, 208, 212
speeding up compilation, 37, 45, 83
spill, 95
spills, 88
sructure arguments, 93
stabs.c, 109
stackprobe, 43
startup code, 42
stdcall, 38
stmt.c, 63
string table, 140
string.c, 62
Stroustrup, 106
strtaben.c, 228
styles.c, 151
SUB (vm operation), 30
subexpr.c, 228
sym.c, 63
symbol record in obj, 72
SysInfoDlg, 190
TestDlgProc, 152
TestInitDlg, 152
TIB (thread information block), 217
tooltips window, 212
trace.c, 62
tree.c, 62
TreeViewProc, 189
truncation of floating point, 33
types (supported by lcc-win32), 29
types.c, 63
unix, 145
unix (executable file format), 109
unnecessary move instructions, 78
UpdateLine, 167
UpdatePos, 167
UpdateScreen, 167
variable aliasing, 90
VirtualQueryEx, 209
w32incl.c, 62
wcmsdlg.c, 228
wedit.prj, 188
win32.c, 20, 39, 63
win32.md, 29, 63
windows headers, 44
wizard.c, 195
workspace window, 189
WorkspaceDlg, 190
wproc.c, 228
WriteDlg, 152
WriteRc, 152
WriteRes, 152
WriteTheFile, 152
wundo.c, 228
x86 instruction (binary format), 65

